{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Run Distributed",
            "type": "python3",
            "request": "launch",
            "module": "torch.distributed.run",
            "console": "integratedTerminal",
            "args": [
                "--nproc_per_node=4",  // Set this to the number of GPUs you want to use
                "src/run_exp.py"
            ],
            "env": {
                "MASTER_ADDR": "localhost",
                "MASTER_PORT": "12355"
            }
        }
    ]
}
