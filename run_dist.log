nohup: ignoring input
/home/neusha/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(

(run_dist.py:626408): Gdk-CRITICAL **: 03:49:19.546: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed

(run_dist.py:626657): Gdk-CRITICAL **: 03:49:23.094: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed

(run_dist.py:626659): Gdk-CRITICAL **: 03:49:23.101: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed

(run_dist.py:626658): Gdk-CRITICAL **: 03:49:23.113: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed

(run_dist.py:626660): Gdk-CRITICAL **: 03:49:23.127: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
start to prepare for device
start to initialize process
start to train
Found 17 files. Start experiments
dealing G4.txt
device 0 start to train
[n] 200 [C] 1243 weight 800
con_list_range [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200]
average_loss tensor(-2370.5803, device='cuda:0', grad_fn=<DivBackward0>) best_loss inf
Epoch 0 Epoch time:  8.769302606582642 current loss tensor(-2381.2373, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2370.9702, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2370.5803, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1 Epoch time:  8.742742538452148 current loss tensor(-2381.6426, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2371.3572, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2370.9702, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2 Epoch time:  8.92190933227539 current loss tensor(-2382.0444, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2371.7410, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2371.3572, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3 Epoch time:  8.798166990280151 current loss tensor(-2382.4434, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2372.1218, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2371.7410, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4 Epoch time:  8.668252229690552 current loss tensor(-2382.8394, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2372.4998, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2372.1218, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5 Epoch time:  8.822190761566162 current loss tensor(-2383.2322, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2372.8743, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2372.4998, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6 Epoch time:  8.861087322235107 current loss tensor(-2383.6218, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2373.2454, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2372.8743, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7 Epoch time:  8.789306640625 current loss tensor(-2384.0078, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2373.6133, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2373.2454, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8 Epoch time:  8.836054563522339 current loss tensor(-2384.3906, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2373.9778, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2373.6133, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9 Epoch time:  8.54668140411377 current loss tensor(-2384.7695, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2374.3389, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2373.9778, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10 Epoch time:  8.703727006912231 current loss tensor(-2385.1453, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2374.6965, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2374.3389, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11 Epoch time:  8.624224662780762 current loss tensor(-2385.5173, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2375.0508, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2374.6965, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12 Epoch time:  8.874915838241577 current loss tensor(-2385.8862, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2375.4019, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.0508, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13 Epoch time:  8.921098709106445 current loss tensor(-2386.2515, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2375.7490, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.4019, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14 Epoch time:  8.530173778533936 current loss tensor(-2386.6128, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.0925, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.7490, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15 Epoch time:  8.673875331878662 current loss tensor(-2386.9707, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.4326, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.0925, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16 Epoch time:  8.693915128707886 current loss tensor(-2387.3247, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.7690, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.4326, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17 Epoch time:  8.848005533218384 current loss tensor(-2387.6753, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.1018, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.7690, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18 Epoch time:  8.785645723342896 current loss tensor(-2388.0225, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.4312, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.1018, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19 Epoch time:  9.071909666061401 current loss tensor(-2388.3657, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.7568, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.4312, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20 Epoch time:  8.745408535003662 current loss tensor(-2388.7053, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.0786, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.7568, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21 Epoch time:  8.782932996749878 current loss tensor(-2389.0410, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.3970, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.0786, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22 Epoch time:  8.66529130935669 current loss tensor(-2389.3735, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.7112, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.3970, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23 Epoch time:  7.695872783660889 current loss tensor(-2389.7014, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.0217, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.7112, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24 Epoch time:  8.577775955200195 current loss tensor(-2390.0259, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.3289, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.0217, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25 Epoch time:  8.915274381637573 current loss tensor(-2390.3467, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.6321, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.3289, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26 Epoch time:  9.029529094696045 current loss tensor(-2390.6636, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.9319, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.6321, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27 Epoch time:  8.645911693572998 current loss tensor(-2390.9771, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.2280, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.9319, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28 Epoch time:  8.946533679962158 current loss tensor(-2391.2866, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.5205, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.2280, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29 Epoch time:  8.722072839736938 current loss tensor(-2391.5928, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.8093, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.5205, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30 Epoch time:  8.676875114440918 current loss tensor(-2391.8953, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.0947, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.8093, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31 Epoch time:  8.523003339767456 current loss tensor(-2392.1938, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.3762, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.0947, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32 Epoch time:  8.549554347991943 current loss tensor(-2392.4890, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.6541, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.3762, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33 Epoch time:  8.618075847625732 current loss tensor(-2392.7803, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.9285, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.6541, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34 Epoch time:  8.734448909759521 current loss tensor(-2393.0679, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.1992, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.9285, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35 Epoch time:  8.822990655899048 current loss tensor(-2393.3516, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.4661, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.1992, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36 Epoch time:  8.976278066635132 current loss tensor(-2393.6318, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.7295, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.4661, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37 Epoch time:  8.365012884140015 current loss tensor(-2393.9082, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.9895, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.7295, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38 Epoch time:  8.569658517837524 current loss tensor(-2394.1812, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.2458, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.9895, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39 Epoch time:  8.88973331451416 current loss tensor(-2394.4507, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.4988, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.2458, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40 Epoch time:  8.74827790260315 current loss tensor(-2394.7163, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.7480, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.4988, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41 Epoch time:  8.329162359237671 current loss tensor(-2394.9783, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.9937, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.7480, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42 Epoch time:  8.718022108078003 current loss tensor(-2395.2368, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.2361, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.9937, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43 Epoch time:  8.585024118423462 current loss tensor(-2395.4917, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.4746, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.2361, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44 Epoch time:  8.730861902236938 current loss tensor(-2395.7432, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.7100, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.4746, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45 Epoch time:  8.228878259658813 current loss tensor(-2395.9907, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.9414, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.7100, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46 Epoch time:  8.581382989883423 current loss tensor(-2396.2346, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.1699, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.9414, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47 Epoch time:  8.69303297996521 current loss tensor(-2396.4751, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.3948, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.1699, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48 Epoch time:  8.510203123092651 current loss tensor(-2396.7119, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.6167, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.3948, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49 Epoch time:  8.64255976676941 current loss tensor(-2396.9458, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.8350, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.6167, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 50 Epoch time:  8.76533842086792 current loss tensor(-2397.1758, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.0500, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.8350, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 51 Epoch time:  8.926769256591797 current loss tensor(-2397.4031, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.2617, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.0500, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 52 Epoch time:  8.820065259933472 current loss tensor(-2397.6265, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.4702, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.2617, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 53 Epoch time:  8.236346960067749 current loss tensor(-2397.8469, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.6753, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.4702, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 54 Epoch time:  8.40141487121582 current loss tensor(-2398.0640, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.8779, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.6753, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 55 Epoch time:  8.689752101898193 current loss tensor(-2398.2778, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.0771, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.8779, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 56 Epoch time:  8.600019931793213 current loss tensor(-2398.4888, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.2734, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.0771, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 57 Epoch time:  8.589192867279053 current loss tensor(-2398.6965, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.4663, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.2734, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 58 Epoch time:  8.750633955001831 current loss tensor(-2398.9009, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.6567, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.4663, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 59 Epoch time:  8.867979288101196 current loss tensor(-2399.1025, device='cuda:0', grad_fn=<SumBackward0>)
average_loss start to prepare for device
start to initialize process
start to train
Found 17 files. Start experiments
dealing G4.txt
device 2 start to train
[n] 200 [C] 1218 weight 800
con_list_range [401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600]
Epoch 0 Epoch time:  8.702268123626709 current loss tensor(-2374.4116, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.3727235794067383 current loss tensor(-2374.7925, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.628474712371826 current loss tensor(-2375.1704, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.6349363327026367 current loss tensor(-2375.5452, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.777623414993286 current loss tensor(-2375.9170, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.532043218612671 current loss tensor(-2376.2864, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.536367416381836 current loss tensor(-2376.6523, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.641866445541382 current loss tensor(-2377.0151, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.5832912921905518 current loss tensor(-2377.3750, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.612962007522583 current loss tensor(-2377.7314, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.5002377033233643 current loss tensor(-2378.0847, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.4579992294311523 current loss tensor(-2378.4341, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.7705814838409424 current loss tensor(-2378.7803, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.705357551574707 current loss tensor(-2379.1230, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.592517614364624 current loss tensor(-2379.4624, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.799628973007202 current loss tensor(-2379.7981, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.6335723400115967 current loss tensor(-2380.1304, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.571805715560913 current loss tensor(-2380.4590, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.5694997310638428 current loss tensor(-2380.7844, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.5819859504699707 current loss tensor(-2381.1060, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.5680413246154785 current loss tensor(-2381.4243, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.470872163772583 current loss tensor(-2381.7383, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.636488914489746 current loss tensor(-2382.0486, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.7070696353912354 current loss tensor(-2382.3552, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.721480131149292 current loss tensor(-2382.6582, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.535491466522217 current loss tensor(-2382.9578, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.584177255630493 current loss tensor(-2383.2537, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.606220006942749 current loss tensor(-2383.5459, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.667379140853882 current loss tensor(-2383.8345, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.5982117652893066 current loss tensor(-2384.1196, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.5646145343780518 current loss tensor(-2384.4009, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.5898096561431885 current loss tensor(-2384.6792, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.6409804821014404 current loss tensor(-2384.9534, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.554748058319092 current loss tensor(-2385.2244, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.5517783164978027 current loss tensor(-2385.4917, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.715894937515259 current loss tensor(-2385.7556, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.923208236694336 current loss tensor(-2386.0156, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.6779158115386963 current loss tensor(-2386.2725, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.561361789703369 current loss tensor(-2386.5259, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.545670509338379 current loss tensor(-2386.7754, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.5640580654144287 current loss tensor(-2387.0220, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.539456367492676 current loss tensor(-2387.2646, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.5847747325897217 current loss tensor(-2387.5037, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.5495362281799316 current loss tensor(-2387.7397, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.6899561882019043 current loss tensor(-2387.9717, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.5930769443511963 current loss tensor(-2388.2007, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.4942586421966553 current loss tensor(-2388.4263, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.9038655757904053 current loss tensor(-2388.6487, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.591120719909668 current loss tensor(-2388.8679, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.738466739654541 current loss tensor(-2389.0840, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.5704596042633057 current loss tensor(-2389.2966, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.5351481437683105 current loss tensor(-2389.5066, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.601834535598755 current loss tensor(-2389.7129, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.6065614223480225 current loss tensor(-2389.9165, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.689218282699585 current loss tensor(-2390.1167, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.6178016662597656 current loss tensor(-2390.3140, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.524174928665161 current loss tensor(-2390.5083, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.5136845111846924 current loss tensor(-2390.6997, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.64616060256958 current loss tensor(-2390.8879, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.5647385120391846 current loss tensor(-2391.0732, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.656813621520996 current loss tensor(-2391.2561, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.54487681388855 current loss start to prepare for device
start to initialize process
start to train
Found 17 files. Start experiments
dealing G4.txt
device 3 start to train
[n] 200 [C] 1197 weight 800
con_list_range [601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800]
Epoch 0 Epoch time:  8.704524278640747 current loss tensor(-2355.8735, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.3637993335723877 current loss tensor(-2356.2280, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.498594284057617 current loss tensor(-2356.5786, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.5669591426849365 current loss tensor(-2356.9268, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.4962878227233887 current loss tensor(-2357.2720, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.5738017559051514 current loss tensor(-2357.6140, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.7019166946411133 current loss tensor(-2357.9531, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.512047290802002 current loss tensor(-2358.2891, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.475142002105713 current loss tensor(-2358.6216, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.661393165588379 current loss tensor(-2358.9507, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.5389466285705566 current loss tensor(-2359.2769, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.536159038543701 current loss tensor(-2359.5991, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.636192798614502 current loss tensor(-2359.9185, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.5495293140411377 current loss tensor(-2360.2344, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.48559832572937 current loss tensor(-2360.5471, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.9215431213378906 current loss tensor(-2360.8562, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.529059886932373 current loss tensor(-2361.1616, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.648054838180542 current loss tensor(-2361.4641, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.58223557472229 current loss tensor(-2361.7629, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.652493953704834 current loss tensor(-2362.0586, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.5917439460754395 current loss tensor(-2362.3506, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.4344725608825684 current loss tensor(-2362.6392, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.5360355377197266 current loss tensor(-2362.9238, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.515005588531494 current loss tensor(-2363.2056, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.679056167602539 current loss tensor(-2363.4834, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.705827474594116 current loss tensor(-2363.7578, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.5128350257873535 current loss tensor(-2364.0288, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.901080846786499 current loss tensor(-2364.2964, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.5132110118865967 current loss tensor(-2364.5605, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.5215413570404053 current loss tensor(-2364.8213, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.5309038162231445 current loss tensor(-2365.0784, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.5385711193084717 current loss tensor(-2365.3320, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.524811267852783 current loss tensor(-2365.5825, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.6578805446624756 current loss tensor(-2365.8293, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.5304665565490723 current loss tensor(-2366.0728, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.6868398189544678 current loss tensor(-2366.3130, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.581331968307495 current loss tensor(-2366.5493, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.4829976558685303 current loss tensor(-2366.7827, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.460822105407715 current loss tensor(-2367.0127, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.486410140991211 current loss tensor(-2367.2393, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.503659248352051 current loss tensor(-2367.4624, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.4947669506073 current loss tensor(-2367.6826, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.7069320678710938 current loss tensor(-2367.8992, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.5579774379730225 current loss tensor(-2368.1128, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.5166308879852295 current loss tensor(-2368.3228, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.530226707458496 current loss tensor(-2368.5291, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.5112247467041016 current loss tensor(-2368.7327, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.5937139987945557 current loss tensor(-2368.9331, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.47941517829895 current loss tensor(-2369.1301, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.4453394412994385 current loss tensor(-2369.3242, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.488827705383301 current loss tensor(-2369.5151, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.513353109359741 current loss tensor(-2369.7029, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.7282896041870117 current loss tensor(-2369.8875, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.436990976333618 current loss tensor(-2370.0693, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.5617077350616455 current loss tensor(-2370.2483, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.5461974143981934 current loss tensor(-2370.4243, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.5306830406188965 current loss tensor(-2370.5972, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.451920747756958 current loss tensor(-2370.7676, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.5326132774353027 current loss tensor(-2370.9351, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.510363817214966 current loss tensor(-2371.0996, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.5441668033599854 current loss tensor(-2371.2617, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.544182300567627 current loss start to prepare for device
start to initialize process
start to train
Found 17 files. Start experiments
dealing G4.txt
device 1 start to train
[n] 200 [C] 1206 weight 800
con_list_range [201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400]
Epoch 0 Epoch time:  8.729586124420166 current loss tensor(-2370.7988, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.41195011138916 current loss tensor(-2371.2185, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.6402406692504883 current loss tensor(-2371.6350, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.5337843894958496 current loss tensor(-2372.0483, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.605746030807495 current loss tensor(-2372.4587, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  4.013077974319458 current loss tensor(-2372.8657, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.5862832069396973 current loss tensor(-2373.2693, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.5744881629943848 current loss tensor(-2373.6694, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.6690142154693604 current loss tensor(-2374.0659, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.5415446758270264 current loss tensor(-2374.4595, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.496039628982544 current loss tensor(-2374.8491, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.4482274055480957 current loss tensor(-2375.2358, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.7555549144744873 current loss tensor(-2375.6187, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.5794029235839844 current loss tensor(-2375.9980, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.5599048137664795 current loss tensor(-2376.3733, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.666872024536133 current loss tensor(-2376.7451, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.5852370262145996 current loss tensor(-2377.1133, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.7093193531036377 current loss tensor(-2377.4773, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.5812764167785645 current loss tensor(-2377.8374, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.686936855316162 current loss tensor(-2378.1943, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.6427512168884277 current loss tensor(-2378.5474, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.4385392665863037 current loss tensor(-2378.8965, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.6262643337249756 current loss tensor(-2379.2412, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.538823127746582 current loss tensor(-2379.5823, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.7688801288604736 current loss tensor(-2379.9194, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.725878953933716 current loss tensor(-2380.2529, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.5652923583984375 current loss tensor(-2380.5825, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.656259298324585 current loss tensor(-2380.9082, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.5849950313568115 current loss tensor(-2381.2302, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.651500701904297 current loss tensor(-2381.5483, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.500986337661743 current loss tensor(-2381.8628, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.5064432621002197 current loss tensor(-2382.1733, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.7266581058502197 current loss tensor(-2382.4800, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.611574649810791 current loss tensor(-2382.7827, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.55745005607605 current loss tensor(-2383.0815, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.5354580879211426 current loss tensor(-2383.3765, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.6005818843841553 current loss tensor(-2383.6675, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.593747854232788 current loss tensor(-2383.9548, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.5025441646575928 current loss tensor(-2384.2383, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.54968523979187 current loss tensor(-2384.5181, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.635481595993042 current loss tensor(-2384.7942, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.523005485534668 current loss tensor(-2385.0667, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.560467481613159 current loss tensor(-2385.3354, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.542417049407959 current loss tensor(-2385.6001, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.827455759048462 current loss tensor(-2385.8616, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.5590548515319824 current loss tensor(-2386.1187, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.4898462295532227 current loss tensor(-2386.3726, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.7558794021606445 current loss tensor(-2386.6226, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.6831648349761963 current loss tensor(-2386.8691, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.513010263442993 current loss tensor(-2387.1121, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.521120309829712 current loss tensor(-2387.3516, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.5744235515594482 current loss tensor(-2387.5869, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.6436662673950195 current loss tensor(-2387.8191, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.6279256343841553 current loss tensor(-2388.0479, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.6385200023651123 current loss tensor(-2388.2729, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.7975475788116455 current loss tensor(-2388.4951, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.5858936309814453 current loss tensor(-2388.7139, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.510312080383301 current loss tensor(-2388.9297, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.5844950675964355 current loss tensor(-2389.1418, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.5114474296569824 current loss tensor(-2389.3511, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.7677996158599854 current loss tensor(-2389.5571, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.5116770267486572 current loss tensor(-2387.8442, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.6567, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 60 Epoch time:  8.674437999725342 current loss tensor(-2399.3013, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.0286, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.8442, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 61 Epoch time:  8.536783456802368 current loss tensor(-2399.4966, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.2100, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.0286, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 62 Epoch time:  8.893226146697998 current loss tensor(-2399.6895, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.3887, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.2100, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 63 Epoch time:  8.671674966812134 current loss tensor(-2399.8789, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.5645, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.3887, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 64 Epoch time:  9.152369737625122 current loss tensor(-2400.0659, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.7375, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.5645, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 65 Epoch time:  8.659419059753418 current loss tensor(-2400.2495, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.9080, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.7375, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 66 Epoch time:  4.028992414474487 current loss tensor(-2400.4307, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.0752, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.9080, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 67 Epoch time:  2.9200117588043213 current loss tensor(-2400.6089, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.2400, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.0752, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 68 Epoch time:  2.807101011276245 current loss tensor(-2400.7842, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.4021, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.2400, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 69 Epoch time:  2.819777250289917 current loss tensor(-2400.9568, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.5615, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.4021, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 70 Epoch time:  2.79412841796875 current loss tensor(-2401.1265, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.7183, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.5615, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 71 Epoch time:  2.820378065109253 current loss tensor(-2401.2937, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.8721, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.7183, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 72 Epoch time:  3.2581653594970703 current loss tensor(-2401.4578, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.0234, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.8721, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 73 Epoch time:  3.4150798320770264 current loss tensor(-2401.6194, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.1724, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.0234, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 74 Epoch time:  2.8101181983947754 current loss tensor(-2401.7783, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.3188, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.1724, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 75 Epoch time:  2.9417827129364014 current loss tensor(-2401.9346, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.4624, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.3188, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 76 Epoch time:  2.879985809326172 current loss tensor(-2402.0884, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.6040, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.4624, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 77 Epoch time:  2.8026559352874756 current loss tensor(-2402.2397, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.7427, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.6040, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 78 Epoch time:  2.8025245666503906 current loss tensor(-2402.3887, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.8789, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.7427, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 79 Epoch time:  2.807790756225586 current loss tensor(-2402.5347, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.0132, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.8789, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 80 Epoch time:  2.8508715629577637 current loss tensor(-2402.6787, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.1448, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.0132, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 81 Epoch time:  2.8061046600341797 current loss tensor(-2402.8201, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.2742, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.1448, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 82 Epoch time:  2.956465721130371 current loss tensor(-2402.9590, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.4011, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.2742, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 83 Epoch time:  2.810342311859131 current loss tensor(-2403.0957, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.5259, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.4011, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 84 Epoch time:  2.9253246784210205 current loss tensor(-2403.2300, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.6484, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.5259, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 85 Epoch time:  2.9267187118530273 current loss tensor(-2403.3618, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.7686, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.6484, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 86 Epoch time:  2.8444926738739014 current loss tensor(-2403.4915, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.8867, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.7686, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 87 Epoch time:  2.8113510608673096 current loss tensor(-2403.6189, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.0027, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.8867, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 88 Epoch time:  2.8140220642089844 current loss tensor(-2403.7439, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.1167, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.0027, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 89 Epoch time:  2.8111095428466797 current loss tensor(-2403.8669, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.2285, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.1167, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 90 Epoch time:  2.8088316917419434 current loss tensor(-2403.9878, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.3381, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.2285, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 91 Epoch time:  2.9244308471679688 current loss tensor(-2404.1064, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.4456, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.3381, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 92 Epoch time:  2.8488311767578125 current loss tensor(-2404.2229, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.5513, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.4456, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 93 Epoch time:  3.3125534057617188 current loss tensor(-2404.3374, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.6553, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.5513, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 94 Epoch time:  2.904038429260254 current loss tensor(-2404.4497, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.7568, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.6553, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 95 Epoch time:  2.808732271194458 current loss tensor(-2404.5601, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.8564, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.7568, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 96 Epoch time:  2.820657253265381 current loss tensor(-2404.6685, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.9546, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.8564, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 97 Epoch time:  2.818354845046997 current loss tensor(-2404.7749, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.0503, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.9546, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 98 Epoch time:  2.8166866302490234 current loss tensor(-2404.8792, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.1445, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.0503, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 99 Epoch time:  2.81223201751709 current loss tensor(-2404.9819, device='cuda:0', grad_fn=<SumBackward0>)
best_out [0.485393   0.5339689  0.42254418 0.4249392  0.44051227 0.43386486
 0.49828476 0.50200564 0.45588478 0.5139936  0.5033709  0.43810588
 0.50320005 0.42919993 0.48450187 0.4625389  0.49043322 0.44635698
 0.5362928  0.44960895 0.4474456  0.496463   0.44703567 0.45670232
 0.50751275 0.43801177 0.48486087 0.45169705 0.4923032  0.4696808
 0.5404169  0.5413854  0.51629144 0.5252948  0.4357987  0.3883226
 0.4182473  0.50235504 0.42959672 0.49444178 0.44351622 0.5145363
 0.47467315 0.48169398 0.4629764  0.47653    0.43724397 0.5101571
 0.55193645 0.43874004 0.47971037 0.5015638  0.38167864 0.49194288
 0.49343744 0.48577243 0.47646448 0.4743324  0.5353876  0.5186024
 0.45155045 0.5341816  0.445099   0.5657291  0.45541018 0.5016823
 0.4228177  0.4400247  0.4791543  0.4464368  0.4780118  0.4897876
 0.513923   0.47325653 0.4645853  0.49533132 0.4973058  0.48783082
 0.4220912  0.45405617 0.4912143  0.4877699  0.4628979  0.4680145
 0.4714034  0.4772109  0.4848496  0.44050467 0.5071697  0.5191972
 0.4603257  0.4766209  0.44967505 0.44964445 0.442062   0.4715901
 0.46260902 0.45814863 0.49543878 0.4671694  0.45687595 0.43459252
 0.5293497  0.49268672 0.47669783 0.5307036  0.45389834 0.4576139
 0.4918546  0.47660813 0.46284264 0.46427438 0.4375076  0.45127916
 0.5212514  0.5037719  0.5115109  0.4744341  0.50170964 0.48206446
 0.44789976 0.44479722 0.45194888 0.44094193 0.38283694 0.4260892
 0.47938058 0.40681794 0.5055323  0.5339697  0.49483013 0.4344277
 0.5136075  0.50469023 0.4315339  0.49309146 0.5363898  0.5031933
 0.3881482  0.4709706  0.4937089  0.4953932  0.5247953  0.43926543
 0.50694966 0.5112017  0.4832845  0.49123603 0.4684897  0.41349065
 0.4936114  0.4383691  0.447669   0.5231579  0.47812286 0.4668145
 0.44664872 0.5177551  0.51244724 0.5179913  0.526017   0.5239894
 0.50401825 0.42941737 0.45827082 0.47872683 0.4729838  0.52431494
 0.41037098 0.50935894 0.51306814 0.41668382 0.48526302 0.49614093
 0.4987965  0.4616271  0.4977677  0.44957557 0.5394444  0.46294987
 0.44896936 0.42141727 0.53110194 0.51628697 0.38499168 0.556829
 0.4326912  0.4211423  0.4576977  0.47688308 0.47224197 0.48586872
 0.49151674 0.50750494 0.4942424  0.4688776  0.48787662 0.42681924
 0.5146642  0.5427607  0.50631505 0.51454073 0.44104755 0.46315
 0.46292466 0.44642192 0.50782955 0.48556638 0.5279283  0.50435203
 0.4192063  0.44658753 0.44685486 0.51387465 0.48428681 0.45086858
 0.48700926 0.4441521  0.5011918  0.485393   0.46428075 0.49710724
 0.4077806  0.4066763  0.46545237 0.45248955 0.4318122  0.45848316
 0.47705308 0.4621354  0.5280117  0.52047265 0.485261   0.4327829
 0.43358165 0.46069902 0.45220798 0.48016697 0.49970955 0.4465287
 0.4178088  0.45083824 0.5026381  0.4983648  0.46602046 0.46626732
 0.4671567  0.49995786 0.3747783  0.44998896 0.4597372  0.4783847
 0.5079914  0.54892015 0.498522   0.5002959  0.44159907 0.36225054
 0.49922395 0.5353354  0.4764865  0.48211586 0.46114412 0.5339579
 0.46342716 0.46918792 0.42977774 0.46152773 0.50310725 0.4730988
 0.493958   0.52604604 0.5114756  0.43784338 0.47760704 0.50632113
 0.5018312  0.50620437 0.4895914  0.46856856 0.44911435 0.5213644
 0.5013834  0.48831528 0.56367487 0.5300668  0.48712113 0.46223697
 0.4512324  0.45323542 0.47711828 0.47881362 0.36633414 0.47131747
 0.4502245  0.46828854 0.54292786 0.46786833 0.5326396  0.50542045
 0.4278751  0.40260586 0.5086886  0.49112687 0.53861094 0.47886655
 0.46809903 0.4995777  0.52160335 0.51066047 0.4951552  0.36493763
 0.46961048 0.4555378  0.44983724 0.48629808 0.519686   0.5305714
 0.54006207 0.41913748 0.46677023 0.48030117 0.4929811  0.40548426
 0.4059394  0.4801592  0.46971592 0.36644435 0.50655353 0.46579704
 0.48197892 0.46032068 0.47296107 0.45976272 0.45103806 0.41025677
 0.5011458  0.5004379  0.4416462  0.497623   0.51110387 0.51748055
 0.44999632 0.4572808  0.5369498  0.4889441  0.4969784  0.5093213
 0.46567956 0.41941583 0.5301449  0.47282982 0.47114444 0.4550864
 0.44768438 0.42686954 0.4719085  0.49070415 0.4921783  0.5165636
 0.50882673 0.5079321  0.5134726  0.4039036  0.47603154 0.5041823
 0.45015132 0.47897077 0.45814332 0.5022427  0.50728244 0.43487188
 0.49606842 0.44208634 0.48013762 0.42470807 0.44736552 0.452253
 0.5374056  0.51876855 0.40683094 0.47517225 0.5149355  0.48043102
 0.46855396 0.4657864  0.42009062 0.44387034 0.44033718 0.53668875
 0.5224251  0.45195332 0.4629293  0.52002007 0.45151225 0.45639473
 0.5004645  0.49315673 0.49795353 0.4817471  0.4667931  0.5170185
 0.4029835  0.43447745 0.5164528  0.41379812 0.55258954 0.49221122
 0.4408866  0.5281999  0.47024867 0.43852583 0.47608063 0.53491455
 0.5357111  0.45987573 0.526431   0.45173025 0.48722944 0.46920392
 0.47371203 0.48300597 0.38270417 0.41401044 0.53829664 0.46518558
 0.52253526 0.56534183 0.53032416 0.49848458 0.55094963 0.4960568
 0.5258745  0.47840774 0.4417703  0.49138442 0.45255664 0.46638906
 0.51227975 0.45104045 0.46275777 0.44278333 0.46435735 0.47753146
 0.42804438 0.47077104 0.4750838  0.50463617 0.48919338 0.4428915
 0.49500698 0.49248746 0.4522089  0.51741695 0.46258864 0.44118896
 0.4507421  0.38213485 0.5216294  0.48266402 0.5049248  0.49225056
 0.47217318 0.53139067 0.4455457  0.5524163  0.44378835 0.47817028
 0.52165866 0.48084244 0.4659436  0.47045332 0.46993524 0.4374332
 0.5117671  0.49988213 0.4989357  0.47272792 0.5352756  0.44788554
 0.5108577  0.4575817  0.5221666  0.5036654  0.5336161  0.45969483
 0.4650381  0.45307058 0.48106536 0.52569765 0.41177157 0.49256855
 0.47125027 0.4086037  0.5445505  0.56727284 0.5024632  0.44914022
 0.48855826 0.48929715 0.4302478  0.4253511  0.47206163 0.4870367
 0.4957375  0.5198464  0.44864902 0.43221852 0.5693318  0.40819255
 0.48019066 0.4736129  0.5093516  0.41785824 0.4679598  0.45202905
 0.52468514 0.48828402 0.55558395 0.5081012  0.49266598 0.43912172
 0.47866866 0.4558471  0.48320556 0.4887048  0.48236483 0.4532451
 0.4531409  0.47274208 0.4849441  0.44196048 0.49340853 0.49734554
 0.49726832 0.56491363 0.5137994  0.50202274 0.47364736 0.51918525
 0.5492083  0.49805045 0.5333384  0.4351204  0.503207   0.48892578
 0.47392687 0.45799464 0.47181603 0.48238337 0.47079048 0.4615721
 0.4231339  0.49488124 0.49320546 0.4377054  0.45110005 0.5062571
 0.4836729  0.4991469  0.5198483  0.5300431  0.5019629  0.42069703
 0.46220782 0.4870311  0.45245358 0.48077884 0.45756167 0.5416207
 0.5009884  0.47569937 0.53692377 0.4860357  0.5033286  0.43617085
 0.44898784 0.5017894  0.5177392  0.4952471  0.47705373 0.44808823
 0.44603252 0.47941965 0.4493897  0.47552732 0.43224216 0.46587956
 0.4359353  0.5170556  0.5169905  0.46553245 0.45816654 0.4841356
 0.47439978 0.501142   0.5052351  0.47390598 0.48515907 0.5560133
 0.49133784 0.50382876 0.40273762 0.39988497 0.42048067 0.43808493
 0.50023663 0.5790885  0.50608945 0.5335037  0.50189817 0.49032274
 0.45007607 0.5125807  0.50313866 0.45976806 0.50842756 0.5101169
 0.51659214 0.46230504 0.4387117  0.5201732  0.43410155 0.4177893
 0.5786677  0.45691755 0.48940858 0.48559797 0.49499044 0.47193444
 0.5290939  0.45509255 0.5259172  0.4727227  0.46258593 0.44220996
 0.5081212  0.5030402  0.48771748 0.48402432 0.47046125 0.542198
 0.48795328 0.48473105 0.45762557 0.4948487  0.49544844 0.52772397
 0.46985886 0.44197991 0.52849996 0.55926293 0.5343652  0.4654797
 0.45279422 0.506481   0.47002196 0.41510263 0.50198644 0.54084015
 0.48603448 0.50173366 0.50409067 0.504931   0.4649009  0.54414904
 0.40994236 0.5019484  0.4240019  0.4401795  0.45941925 0.462874
 0.4776067  0.4631325  0.5050472  0.57352877 0.5274913  0.5066267
 0.5394467  0.4896764  0.45955738 0.48981345 0.48778045 0.52135485
 0.46332097 0.48700243 0.5271921  0.46206164 0.5359624  0.4728328
 0.49581647 0.44023767 0.4432307  0.45032263 0.49238965 0.5049677
 0.530854   0.5503793  0.48116902 0.45781934 0.44889906 0.37177032
 0.5014374  0.5073212  0.489016   0.5719377  0.41844425 0.49141526
 0.49062294 0.4711148  0.4637364  0.47416335 0.53760785 0.45683903
 0.4404209  0.48706084 0.5198188  0.4982728  0.51388717 0.44643566
 0.4436755  0.45769677 0.46518946 0.47307867 0.45372295 0.42114243
 0.49085626 0.49789864 0.48827225 0.4846001  0.5344635  0.49252224
 0.47012007 0.5373818  0.46017438 0.5239377  0.53509665 0.52770305
 0.41570172 0.5353291  0.5128179  0.49730587 0.4901663  0.48288473
 0.4972725  0.48560384 0.47435823 0.45865434 0.4763933  0.5087645
 0.5426255  0.48040393 0.4489397  0.5127774  0.47533163 0.5201811
 0.48723704 0.53514576 0.5669798  0.5076186  0.5205641  0.5179066
 0.51876736 0.42167905 0.49630544 0.44406322 0.49802077 0.48303023
 0.44176915 0.5080043  0.5125508  0.42602795 0.50500804 0.50291497
 0.48209527 0.50116396 0.5363611  0.43932277 0.5164684  0.5329425
 0.45069715 0.47124952 0.51075745 0.4636293  0.47219124 0.5090031
 0.40892273 0.47911856 0.43182182 0.5297626  0.5235748  0.5095463
 0.48562142 0.48058668 0.44540405 0.49001476 0.501928   0.46285468
 0.47662848 0.5074625 ]
info_input_total 800 weights 800 total_C 19176
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
-9647
res {1: 1, 2: 1, 3: 1, 4: 0, 5: 0, 6: 1, 7: 0, 8: 0, 9: 1, 10: 1, 11: 0, 12: 0, 13: 0, 14: 1, 15: 0, 16: 1, 17: 1, 18: 0, 19: 0, 20: 0, 21: 1, 22: 0, 23: 0, 24: 0, 25: 1, 26: 1, 27: 0, 28: 0, 29: 1, 30: 0, 31: 0, 32: 1, 33: 0, 34: 1, 35: 1, 36: 1, 37: 1, 38: 0, 39: 1, 40: 1, 41: 1, 42: 1, 43: 0, 44: 1, 45: 1, 46: 0, 47: 1, 48: 1, 49: 1, 50: 1, 51: 0, 52: 1, 53: 0, 54: 0, 55: 1, 56: 0, 57: 0, 58: 1, 59: 1, 60: 1, 61: 1, 62: 1, 63: 1, 64: 0, 65: 0, 66: 0, 67: 1, 68: 1, 69: 0, 70: 0, 71: 0, 72: 0, 73: 1, 74: 1, 75: 1, 76: 0, 77: 0, 78: 0, 79: 0, 80: 1, 81: 1, 82: 1, 83: 1, 84: 0, 85: 1, 86: 0, 87: 0, 88: 0, 89: 0, 90: 1, 91: 1, 92: 0, 93: 1, 94: 1, 95: 0, 96: 1, 97: 1, 98: 0, 99: 1, 100: 0, 101: 1, 102: 1, 103: 1, 104: 1, 105: 1, 106: 1, 107: 1, 108: 0, 109: 1, 110: 0, 111: 0, 112: 0, 113: 1, 114: 1, 115: 0, 116: 0, 117: 0, 118: 1, 119: 0, 120: 0, 121: 0, 122: 0, 123: 0, 124: 0, 125: 1, 126: 1, 127: 0, 128: 1, 129: 0, 130: 1, 131: 0, 132: 0, 133: 0, 134: 0, 135: 0, 136: 1, 137: 0, 138: 0, 139: 0, 140: 1, 141: 1, 142: 0, 143: 1, 144: 1, 145: 1, 146: 1, 147: 0, 148: 0, 149: 1, 150: 0, 151: 1, 152: 0, 153: 1, 154: 1, 155: 1, 156: 0, 157: 0, 158: 1, 159: 1, 160: 0, 161: 1, 162: 0, 163: 0, 164: 0, 165: 1, 166: 0, 167: 1, 168: 1, 169: 0, 170: 1, 171: 0, 172: 0, 173: 0, 174: 1, 175: 1, 176: 1, 177: 0, 178: 0, 179: 1, 180: 0, 181: 1, 182: 0, 183: 1, 184: 0, 185: 1, 186: 0, 187: 1, 188: 1, 189: 1, 190: 0, 191: 1, 192: 1, 193: 0, 194: 0, 195: 0, 196: 1, 197: 0, 198: 0, 199: 1, 200: 1, 201: 0, 202: 1, 203: 0, 204: 1, 205: 1, 206: 0, 207: 0, 208: 1, 209: 0, 210: 0, 211: 1, 212: 1, 213: 0, 214: 1, 215: 0, 216: 1, 217: 1, 218: 0, 219: 0, 220: 0, 221: 0, 222: 1, 223: 0, 224: 1, 225: 1, 226: 1, 227: 1, 228: 0, 229: 0, 230: 1, 231: 0, 232: 0, 233: 1, 234: 0, 235: 1, 236: 0, 237: 0, 238: 0, 239: 0, 240: 0, 241: 0, 242: 1, 243: 0, 244: 1, 245: 0, 246: 0, 247: 1, 248: 1, 249: 0, 250: 1, 251: 1, 252: 1, 253: 1, 254: 1, 255: 1, 256: 0, 257: 1, 258: 0, 259: 1, 260: 0, 261: 0, 262: 1, 263: 0, 264: 1, 265: 1, 266: 0, 267: 0, 268: 1, 269: 0, 270: 1, 271: 1, 272: 1, 273: 0, 274: 1, 275: 1, 276: 0, 277: 0, 278: 1, 279: 0, 280: 1, 281: 1, 282: 0, 283: 1, 284: 0, 285: 0, 286: 1, 287: 1, 288: 1, 289: 1, 290: 0, 291: 0, 292: 0, 293: 0, 294: 0, 295: 1, 296: 1, 297: 0, 298: 0, 299: 0, 300: 0, 301: 0, 302: 1, 303: 0, 304: 1, 305: 0, 306: 0, 307: 0, 308: 0, 309: 1, 310: 0, 311: 0, 312: 0, 313: 1, 314: 1, 315: 0, 316: 0, 317: 1, 318: 0, 319: 0, 320: 0, 321: 0, 322: 0, 323: 1, 324: 1, 325: 0, 326: 1, 327: 0, 328: 1, 329: 0, 330: 0, 331: 0, 332: 1, 333: 1, 334: 0, 335: 0, 336: 1, 337: 1, 338: 1, 339: 1, 340: 0, 341: 0, 342: 1, 343: 1, 344: 0, 345: 0, 346: 1, 347: 1, 348: 1, 349: 0, 350: 1, 351: 1, 352: 0, 353: 0, 354: 0, 355: 0, 356: 0, 357: 1, 358: 0, 359: 1, 360: 1, 361: 0, 362: 1, 363: 1, 364: 1, 365: 1, 366: 1, 367: 0, 368: 0, 369: 1, 370: 0, 371: 1, 372: 0, 373: 1, 374: 0, 375: 1, 376: 1, 377: 0, 378: 0, 379: 0, 380: 0, 381: 1, 382: 0, 383: 0, 384: 0, 385: 0, 386: 1, 387: 0, 388: 1, 389: 0, 390: 1, 391: 0, 392: 1, 393: 0, 394: 0, 395: 0, 396: 0, 397: 1, 398: 0, 399: 0, 400: 0, 401: 0, 402: 1, 403: 1, 404: 1, 405: 0, 406: 1, 407: 0, 408: 1, 409: 1, 410: 1, 411: 1, 412: 1, 413: 0, 414: 1, 415: 1, 416: 1, 417: 1, 418: 0, 419: 1, 420: 0, 421: 1, 422: 0, 423: 0, 424: 1, 425: 1, 426: 0, 427: 1, 428: 0, 429: 0, 430: 1, 431: 1, 432: 0, 433: 0, 434: 1, 435: 0, 436: 1, 437: 0, 438: 0, 439: 1, 440: 0, 441: 0, 442: 0, 443: 1, 444: 0, 445: 0, 446: 0, 447: 1, 448: 1, 449: 0, 450: 1, 451: 0, 452: 1, 453: 0, 454: 0, 455: 1, 456: 1, 457: 1, 458: 1, 459: 0, 460: 0, 461: 0, 462: 0, 463: 1, 464: 1, 465: 0, 466: 0, 467: 0, 468: 0, 469: 0, 470: 1, 471: 0, 472: 0, 473: 0, 474: 1, 475: 0, 476: 1, 477: 1, 478: 0, 479: 0, 480: 1, 481: 1, 482: 0, 483: 0, 484: 0, 485: 0, 486: 0, 487: 1, 488: 1, 489: 0, 490: 1, 491: 1, 492: 1, 493: 1, 494: 0, 495: 1, 496: 0, 497: 1, 498: 0, 499: 0, 500: 0, 501: 0, 502: 0, 503: 1, 504: 0, 505: 0, 506: 1, 507: 0, 508: 1, 509: 1, 510: 0, 511: 0, 512: 0, 513: 1, 514: 0, 515: 0, 516: 1, 517: 1, 518: 0, 519: 0, 520: 0, 521: 0, 522: 0, 523: 1, 524: 1, 525: 1, 526: 0, 527: 0, 528: 0, 529: 0, 530: 1, 531: 0, 532: 0, 533: 0, 534: 1, 535: 1, 536: 0, 537: 1, 538: 0, 539: 0, 540: 0, 541: 0, 542: 0, 543: 0, 544: 0, 545: 0, 546: 1, 547: 1, 548: 1, 549: 0, 550: 1, 551: 0, 552: 1, 553: 1, 554: 0, 555: 1, 556: 0, 557: 1, 558: 1, 559: 0, 560: 0, 561: 1, 562: 0, 563: 1, 564: 1, 565: 0, 566: 0, 567: 0, 568: 0, 569: 0, 570: 1, 571: 0, 572: 0, 573: 1, 574: 0, 575: 0, 576: 1, 577: 0, 578: 1, 579: 0, 580: 0, 581: 0, 582: 0, 583: 0, 584: 1, 585: 0, 586: 0, 587: 1, 588: 1, 589: 0, 590: 0, 591: 1, 592: 0, 593: 0, 594: 1, 595: 1, 596: 1, 597: 0, 598: 1, 599: 1, 600: 1, 601: 0, 602: 0, 603: 1, 604: 0, 605: 1, 606: 1, 607: 1, 608: 1, 609: 0, 610: 0, 611: 1, 612: 1, 613: 0, 614: 1, 615: 0, 616: 1, 617: 0, 618: 0, 619: 1, 620: 1, 621: 1, 622: 1, 623: 0, 624: 1, 625: 0, 626: 0, 627: 0, 628: 1, 629: 0, 630: 1, 631: 0, 632: 0, 633: 0, 634: 0, 635: 1, 636: 1, 637: 1, 638: 0, 639: 1, 640: 0, 641: 1, 642: 0, 643: 0, 644: 1, 645: 1, 646: 1, 647: 1, 648: 1, 649: 1, 650: 0, 651: 1, 652: 0, 653: 1, 654: 0, 655: 1, 656: 1, 657: 0, 658: 1, 659: 0, 660: 1, 661: 0, 662: 1, 663: 1, 664: 1, 665: 0, 666: 1, 667: 1, 668: 1, 669: 1, 670: 1, 671: 0, 672: 1, 673: 0, 674: 1, 675: 1, 676: 1, 677: 1, 678: 0, 679: 0, 680: 1, 681: 0, 682: 0, 683: 0, 684: 1, 685: 0, 686: 0, 687: 1, 688: 1, 689: 0, 690: 1, 691: 1, 692: 0, 693: 1, 694: 0, 695: 1, 696: 0, 697: 1, 698: 0, 699: 1, 700: 0, 701: 0, 702: 1, 703: 0, 704: 0, 705: 1, 706: 1, 707: 0, 708: 0, 709: 1, 710: 1, 711: 1, 712: 0, 713: 1, 714: 1, 715: 1, 716: 0, 717: 1, 718: 1, 719: 0, 720: 0, 721: 0, 722: 0, 723: 1, 724: 0, 725: 0, 726: 0, 727: 1, 728: 0, 729: 1, 730: 1, 731: 1, 732: 1, 733: 0, 734: 1, 735: 0, 736: 1, 737: 1, 738: 0, 739: 1, 740: 1, 741: 1, 742: 1, 743: 1, 744: 0, 745: 1, 746: 0, 747: 1, 748: 0, 749: 0, 750: 0, 751: 1, 752: 0, 753: 1, 754: 0, 755: 1, 756: 0, 757: 0, 758: 1, 759: 0, 760: 0, 761: 1, 762: 1, 763: 1, 764: 1, 765: 1, 766: 0, 767: 1, 768: 0, 769: 1, 770: 0, 771: 0, 772: 0, 773: 0, 774: 0, 775: 1, 776: 0, 777: 1, 778: 1, 779: 0, 780: 1, 781: 0, 782: 0, 783: 1, 784: 0, 785: 0, 786: 0, 787: 0, 788: 0, 789: 1, 790: 1, 791: 1, 792: 0, 793: 1, 794: 0, 795: 1, 796: 1, 797: 0, 798: 1, 799: 1, 800: 1}
-9647.0
-8174.0
dealing G16.txt
device 0 start to train
[n] 200 [C] 1130 weight 800
con_list_range [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200]
average_loss tensor(-580.0668, device='cuda:0', grad_fn=<DivBackward0>) best_loss inf
Epoch 0 Epoch time:  1.6565074920654297 current loss tensor(-1154.8513, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.1376, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.0668, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1 Epoch time:  1.7000503540039062 current loss tensor(-1155.0333, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.2078, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.1376, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2 Epoch time:  1.6861791610717773 current loss tensor(-1155.2139, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.7605, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.643937110900879 current loss tensor(-2389.9607, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.615844249725342 current loss tensor(-2390.1577, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.5661094188690186 current loss tensor(-2390.3521, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.57313871383667 current loss tensor(-2390.5430, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.626941442489624 current loss tensor(-2390.7314, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.856125593185425 current loss tensor(-2390.9165, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.8745508193969727 current loss tensor(-2391.0989, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.8350508213043213 current loss tensor(-2391.2783, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.80106782913208 current loss tensor(-2391.4548, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.812082052230835 current loss tensor(-2391.6289, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.8467941284179688 current loss tensor(-2391.7998, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.9281277656555176 current loss tensor(-2391.9680, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.8767752647399902 current loss tensor(-2392.1335, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.942469358444214 current loss tensor(-2392.2961, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.796210765838623 current loss tensor(-2392.4561, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.8781490325927734 current loss tensor(-2392.6135, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.811718225479126 current loss tensor(-2392.7686, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.792527198791504 current loss tensor(-2392.9207, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.798027276992798 current loss tensor(-2393.0703, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.845707893371582 current loss tensor(-2393.2173, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.816697120666504 current loss tensor(-2393.3618, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.8928885459899902 current loss tensor(-2393.5042, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.9338974952697754 current loss tensor(-2393.6436, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.807924270629883 current loss tensor(-2393.7810, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.940336227416992 current loss tensor(-2393.9160, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.814929723739624 current loss tensor(-2394.0483, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.8027524948120117 current loss tensor(-2394.1787, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.8094160556793213 current loss tensor(-2394.3066, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.807565212249756 current loss tensor(-2394.4326, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.800173282623291 current loss tensor(-2394.5562, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.8867669105529785 current loss tensor(-2394.6775, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  3.3299810886383057 current loss tensor(-2394.7966, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.7945239543914795 current loss tensor(-2394.9138, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.873185396194458 current loss tensor(-2395.0288, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.8092494010925293 current loss tensor(-2395.1416, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.8216631412506104 current loss tensor(-2395.2527, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.810260057449341 current loss tensor(-2395.3613, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.80924654006958 current loss tensor(-2395.4683, device='cuda:1', grad_fn=<SumBackward0>)
dealing G16.txt
device 1 start to train
[n] 200 [C] 188 weight 800
con_list_range [201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 221, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 261, 262, 263, 264, 266, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 314, 315, 316, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 370, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 390, 391, 392, 393, 394, 395, 397, 398, 399, 400]
Epoch 0 Epoch time:  0.890592098236084 current loss tensor(-464.6184, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  0.9208106994628906 current loss tensor(-464.6874, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  0.9443454742431641 current loss tensor(-464.7560, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  0.9450106620788574 current loss tensor(-464.8242, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  0.9457967281341553 current loss tensor(-464.8920, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  0.9412956237792969 current loss tensor(-464.9594, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  0.9414381980895996 current loss tensor(-465.0263, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  0.937021017074585 current loss tensor(-465.0927, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  0.9624538421630859 current loss tensor(-465.1587, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  0.9358930587768555 current loss tensor(-465.2242, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  0.9438986778259277 current loss tensor(-465.2891, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  0.9399287700653076 current loss tensor(-465.3536, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  0.9392905235290527 current loss tensor(-465.4175, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  0.9375030994415283 current loss tensor(-465.4811, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  0.9398550987243652 current loss tensor(-465.5441, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  0.9416358470916748 current loss tensor(-465.6066, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  0.9457583427429199 current loss tensor(-465.6687, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  0.9393551349639893 current loss tensor(-465.7302, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  0.9481616020202637 current loss tensor(-465.7913, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  0.9392564296722412 current loss tensor(-465.8519, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  0.939124584197998 current loss tensor(-465.9120, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  0.939605712890625 current loss tensor(-465.9715, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  0.9397540092468262 current loss tensor(-466.0306, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  0.9398653507232666 current loss tensor(-466.0892, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  0.9442496299743652 current loss tensor(-466.1473, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  0.9399042129516602 current loss tensor(-2391.4355, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.5463335514068604 current loss tensor(-2391.6123, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.622807264328003 current loss tensor(-2391.7864, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.605990409851074 current loss tensor(-2391.9575, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.5403006076812744 current loss tensor(-2392.1260, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.4395716190338135 current loss tensor(-2392.2917, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.9860386848449707 current loss tensor(-2392.4548, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.7963368892669678 current loss tensor(-2392.6147, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.7803280353546143 current loss tensor(-2392.7725, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.8158841133117676 current loss tensor(-2392.9275, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.805778741836548 current loss tensor(-2393.0801, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.839984893798828 current loss tensor(-2393.2297, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.8820393085479736 current loss tensor(-2393.3770, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.845560312271118 current loss tensor(-2393.5215, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.802133560180664 current loss tensor(-2393.6638, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.909883737564087 current loss tensor(-2393.8037, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.7765681743621826 current loss tensor(-2393.9407, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.815424680709839 current loss tensor(-2394.0754, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.787360668182373 current loss tensor(-2394.2075, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.8065617084503174 current loss tensor(-2394.3374, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.8504323959350586 current loss tensor(-2394.4653, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.811770439147949 current loss tensor(-2394.5908, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.878713607788086 current loss tensor(-2394.7139, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.8038761615753174 current loss tensor(-2394.8345, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.963758945465088 current loss tensor(-2394.9534, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.770061492919922 current loss tensor(-2395.0698, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.816685199737549 current loss tensor(-2395.1843, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.7979376316070557 current loss tensor(-2395.2969, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.7979135513305664 current loss tensor(-2395.4072, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.8130345344543457 current loss tensor(-2395.5154, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.792813777923584 current loss tensor(-2395.6216, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.8565714359283447 current loss tensor(-2395.7258, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.8633980751037598 current loss tensor(-2395.8281, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.957869529724121 current loss tensor(-2395.9287, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.767730951309204 current loss tensor(-2396.0271, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.847876787185669 current loss tensor(-2396.1238, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.778184652328491 current loss tensor(-2396.2185, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.8181679248809814 current loss tensor(-2396.3115, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.807201862335205 current loss tensor(-2396.4028, device='cuda:2', grad_fn=<SumBackward0>)
dealing G16.txt
device 2 start to train
[n] 200 [C] 110 weight 800
con_list_range [401, 403, 404, 406, 407, 408, 409, 412, 413, 414, 417, 419, 421, 422, 423, 425, 426, 427, 428, 430, 433, 434, 437, 438, 441, 443, 444, 446, 447, 450, 452, 455, 457, 458, 460, 461, 463, 464, 465, 468, 469, 470, 471, 472, 474, 475, 476, 477, 478, 480, 481, 482, 483, 484, 485, 486, 487, 489, 490, 492, 493, 494, 495, 498, 499, 501, 502, 503, 504, 505, 506, 507, 509, 511, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 525, 526, 528, 529, 532, 533, 536, 537, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 556, 557, 558, 559, 560, 561, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 581, 582, 583, 584, 586, 587, 588, 589, 590, 592, 593, 596, 599, 600]
Epoch 0 Epoch time:  0.7388858795166016 current loss tensor(-379.1234, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  0.7682747840881348 current loss tensor(-379.1443, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  0.7915761470794678 current loss tensor(-379.1649, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  0.7925455570220947 current loss tensor(-379.1854, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  0.7934033870697021 current loss tensor(-379.2055, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  0.7900967597961426 current loss tensor(-379.2253, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  0.7872414588928223 current loss tensor(-379.2448, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  0.7843384742736816 current loss tensor(-379.2642, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  0.7891578674316406 current loss tensor(-379.2831, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  0.7830402851104736 current loss tensor(-379.3019, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  0.7855794429779053 current loss tensor(-379.3203, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  0.7861874103546143 current loss tensor(-379.3385, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  0.7882945537567139 current loss tensor(-379.3564, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  0.7835309505462646 current loss tensor(-379.3740, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  0.7883872985839844 current loss tensor(-379.3914, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  0.7861802577972412 current loss tensor(-379.4084, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  0.7907631397247314 current loss tensor(-379.4252, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  0.7882006168365479 current loss tensor(-379.4418, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  0.9341700077056885 current loss tensor(-379.4580, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  0.7880122661590576 current loss tensor(-379.4739, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  0.788006067276001 current loss tensor(-379.4896, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  0.7789616584777832 current loss tensor(-379.5050, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  0.8533236980438232 current loss tensor(-379.5202, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  0.8563985824584961 current loss tensor(-379.5351, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  0.8564929962158203 current loss tensor(-379.5497, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  0.8557674884796143 current loss tensor(-379.5641, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  0.8551151752471924 current loss tensor(-379.5783, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  tensor(-2371.4214, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.65525221824646 current loss tensor(-2371.5776, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.494626760482788 current loss tensor(-2371.7314, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.615070104598999 current loss tensor(-2371.8828, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.485361099243164 current loss tensor(-2372.0317, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.3430464267730713 current loss tensor(-2372.1777, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.8105862140655518 current loss tensor(-2372.3213, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.7779080867767334 current loss tensor(-2372.4622, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.7899587154388428 current loss tensor(-2372.6006, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.785914421081543 current loss tensor(-2372.7368, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.7768170833587646 current loss tensor(-2372.8704, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.936127185821533 current loss tensor(-2373.0015, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.847344398498535 current loss tensor(-2373.1299, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.821908473968506 current loss tensor(-2373.2563, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.791452169418335 current loss tensor(-2373.3804, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.7839713096618652 current loss tensor(-2373.5020, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.786663293838501 current loss tensor(-2373.6213, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.7797598838806152 current loss tensor(-2373.7385, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.7943055629730225 current loss tensor(-2373.8535, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.785158634185791 current loss tensor(-2373.9663, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.8265206813812256 current loss tensor(-2374.0767, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.93243408203125 current loss tensor(-2374.1851, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.7854418754577637 current loss tensor(-2374.2910, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.7845618724823 current loss tensor(-2374.3955, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.7809486389160156 current loss tensor(-2374.4976, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.7666399478912354 current loss tensor(-2374.5974, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.765894651412964 current loss tensor(-2374.6953, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.7881739139556885 current loss tensor(-2374.7915, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.7938761711120605 current loss tensor(-2374.8855, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.7835400104522705 current loss tensor(-2374.9780, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.8093984127044678 current loss tensor(-2375.0681, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.942598342895508 current loss tensor(-2375.1565, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.730921506881714 current loss tensor(-2375.2432, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.767094373703003 current loss tensor(-2375.3281, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.790346622467041 current loss tensor(-2375.4109, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.792480230331421 current loss tensor(-2375.4922, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.794348955154419 current loss tensor(-2375.5718, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.7648746967315674 current loss tensor(-2375.6494, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.758120059967041 current loss tensor(-2375.7256, device='cuda:3', grad_fn=<SumBackward0>)
dealing G16.txt
device 3 start to train
[n] 200 [C] 101 weight 800
con_list_range [601, 602, 604, 605, 607, 608, 609, 610, 611, 613, 615, 620, 621, 624, 625, 626, 628, 629, 632, 633, 635, 636, 637, 638, 640, 641, 642, 643, 644, 646, 647, 649, 650, 651, 653, 655, 658, 662, 663, 665, 666, 668, 669, 671, 672, 676, 677, 679, 681, 682, 684, 687, 688, 689, 691, 692, 693, 694, 697, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 710, 711, 712, 717, 719, 720, 721, 722, 727, 729, 730, 731, 734, 735, 736, 737, 738, 739, 740, 743, 745, 746, 747, 749, 750, 752, 754, 755, 759, 760, 762, 763, 766, 767, 770, 772, 774, 776, 777, 778, 779, 781, 784, 787, 788, 790, 793, 794, 795, 796, 797, 798, 799, 800]
Epoch 0 Epoch time:  0.6419382095336914 current loss tensor(-321.6740, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  0.6701369285583496 current loss tensor(-321.6852, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  0.6935830116271973 current loss tensor(-321.6965, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  0.6914505958557129 current loss tensor(-321.7076, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  0.6892764568328857 current loss tensor(-321.7185, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  0.6878976821899414 current loss tensor(-321.7294, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  0.6898159980773926 current loss tensor(-321.7402, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  0.6866343021392822 current loss tensor(-321.7510, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  0.6906042098999023 current loss tensor(-321.7617, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  0.6865861415863037 current loss tensor(-321.7722, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  0.6887927055358887 current loss tensor(-321.7827, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  0.6892743110656738 current loss tensor(-321.7931, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  0.6884078979492188 current loss tensor(-321.8033, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  0.6868772506713867 current loss tensor(-321.8135, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  0.6909422874450684 current loss tensor(-321.8235, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  0.689070463180542 current loss tensor(-321.8333, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  0.691030740737915 current loss tensor(-321.8430, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  0.6902379989624023 current loss tensor(-321.8526, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  0.693631649017334 current loss tensor(-321.8620, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  0.6873607635498047 current loss tensor(-321.8712, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  0.6875889301300049 current loss tensor(-321.8803, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  0.6870365142822266 current loss tensor(-321.8893, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  0.6857080459594727 current loss tensor(-321.8982, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  0.6905930042266846 current loss tensor(-321.9069, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  0.6864299774169922 current loss tensor(-321.9155, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  0.6868727207183838 current loss tensor(-321.9240, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  0.6869499683380127 current loss tensor(-321.9324, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  0.6888589859008789 current loss tensor(-580.2775, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.2078, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3 Epoch time:  1.6852338314056396 current loss tensor(-1155.3928, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.3466, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.2775, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4 Epoch time:  1.6847038269042969 current loss tensor(-1155.5703, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.4151, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.3466, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5 Epoch time:  1.681396245956421 current loss tensor(-1155.7463, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.4830, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.4151, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6 Epoch time:  1.6821894645690918 current loss tensor(-1155.9208, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.5504, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.4830, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7 Epoch time:  1.6827783584594727 current loss tensor(-1156.0935, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.6171, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.5504, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8 Epoch time:  1.6813113689422607 current loss tensor(-1156.2646, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.6832, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.6171, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9 Epoch time:  1.6849894523620605 current loss tensor(-1156.4343, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.7486, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.6832, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10 Epoch time:  1.6764867305755615 current loss tensor(-1156.6023, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.8135, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.7486, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11 Epoch time:  1.6860918998718262 current loss tensor(-1156.7688, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.8778, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.8135, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12 Epoch time:  1.6808199882507324 current loss tensor(-1156.9338, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.9414, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.8778, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13 Epoch time:  1.6808133125305176 current loss tensor(-1157.0972, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.0045, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.9414, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14 Epoch time:  1.683642864227295 current loss tensor(-1157.2590, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.0669, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.0045, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15 Epoch time:  1.676903247833252 current loss tensor(-1157.4192, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.1287, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.0669, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16 Epoch time:  1.6840593814849854 current loss tensor(-1157.5776, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.1898, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.1287, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17 Epoch time:  1.6795101165771484 current loss tensor(-1157.7346, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.2504, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.1898, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18 Epoch time:  1.6872057914733887 current loss tensor(-1157.8901, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.3102, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.2504, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19 Epoch time:  1.7085039615631104 current loss tensor(-1158.0438, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.3695, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.3102, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20 Epoch time:  1.6846258640289307 current loss tensor(-1158.1962, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.4282, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.3695, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21 Epoch time:  1.6763639450073242 current loss tensor(-1158.3469, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.4862, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.4282, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22 Epoch time:  1.677394151687622 current loss tensor(-1158.4960, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.5436, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.4862, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23 Epoch time:  1.676814079284668 current loss tensor(-1158.6433, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.6005, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.5436, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24 Epoch time:  1.6782803535461426 current loss tensor(-1158.7892, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.6566, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.6005, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25 Epoch time:  1.6792469024658203 current loss tensor(-1158.9333, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.7122, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.6566, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26 Epoch time:  1.6773862838745117 current loss tensor(-1159.0759, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.7671, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.7122, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27 Epoch time:  1.6860291957855225 current loss tensor(-1159.2168, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.8214, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.7671, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28 Epoch time:  1.6842224597930908 current loss tensor(-1159.3560, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.8750, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.8214, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29 Epoch time:  1.6961498260498047 current loss tensor(-1159.4935, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.9280, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.8750, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30 Epoch time:  1.709700107574463 current loss tensor(-1159.6294, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.9805, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.9280, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31 Epoch time:  1.6802172660827637 current loss tensor(-1159.7638, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.0323, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.9805, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32 Epoch time:  1.6809370517730713 current loss tensor(-1159.8965, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.0836, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.0323, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33 Epoch time:  1.6978113651275635 current loss tensor(-1160.0276, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.1343, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.0836, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34 Epoch time:  1.6837503910064697 current loss tensor(-1160.1570, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.1844, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.1343, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35 Epoch time:  1.8098671436309814 current loss tensor(-1160.2849, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.2338, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.1844, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36 Epoch time:  1.697723388671875 current loss tensor(-1160.4110, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.2827, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.2338, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37 Epoch time:  1.6908564567565918 current loss tensor(-1160.5356, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.3310, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.2827, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38 Epoch time:  1.6992783546447754 current loss tensor(-1160.6587, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.3787, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.3310, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39 Epoch time:  1.688565969467163 current loss tensor(-1160.7803, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.4259, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.3787, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40 Epoch time:  1.681096076965332 current loss tensor(-1160.9001, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.4725, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.4259, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41 Epoch time:  1.6843111515045166 current loss tensor(-1161.0186, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.5186, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.4725, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42 Epoch time:  1.678105354309082 current loss tensor(-1161.1353, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.5641, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.5186, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43 Epoch time:  1.6784460544586182 current loss tensor(-1161.2505, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.6091, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.5641, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44 Epoch time:  1.684389591217041 current loss tensor(-1161.3638, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.6534, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.6091, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45 Epoch time:  1.6840391159057617 current loss tensor(-1161.4757, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.6974, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.6534, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46 Epoch time:  1.6774003505706787 current loss tensor(-1161.5859, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.7407, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.6974, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47 Epoch time:  1.678659200668335 current loss tensor(-1161.6948, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.7836, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.7407, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48 Epoch time:  1.6789360046386719 current loss tensor(-1161.8022, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.8259, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.7836, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49 Epoch time:  1.68092679977417 current loss tensor(-1161.9082, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.8676, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.8259, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 50 Epoch time:  1.6814382076263428 current loss tensor(-1162.0127, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.9089, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.8676, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 51 Epoch time:  1.6798477172851562 current loss tensor(-1162.1158, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.9497, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.9089, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 52 Epoch time:  1.718881368637085 current loss tensor(-1162.2174, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.9899, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.9497, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 53 Epoch time:  1.6817569732666016 current loss tensor(-1162.3173, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.0294, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.9899, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 54 Epoch time:  1.6895084381103516 current loss tensor(-1162.4158, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.0685, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.0294, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 55 Epoch time:  1.6869511604309082 current loss tensor(-1162.5128, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.1071, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.0685, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 56 Epoch time:  1.6961236000061035 current loss tensor(-1162.6084, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.1452, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.1071, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 57 Epoch time:  1.6829535961151123 current loss tensor(-1162.7026, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.1829, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.1452, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 58 Epoch time:  1.6771910190582275 current loss tensor(-1162.7955, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.2200, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.1829, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 59 Epoch time:  1.6756794452667236 current loss tensor(-1162.8870, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.2567, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.2200, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 60 Epoch time:  1.6920380592346191 current loss tensor(-1162.9773, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.2928, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.2567, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 61 Epoch time:  1.6750562191009521 current loss tensor(-1163.0662, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.3287, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.2928, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 62 Epoch time:  1.679675579071045 current loss tensor(-1163.1538, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.3640, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.3287, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 63 Epoch time:  1.6811439990997314 current loss tensor(-1163.2402, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.3989, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.3640, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 64 Epoch time:  1.6824672222137451 current loss tensor(-1163.3254, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.4334, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.3989, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 65 Epoch time:  1.8222670555114746 current loss tensor(-1163.4094, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.4675, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.4334, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 66 Epoch time:  1.6781034469604492 current loss tensor(-1163.4919, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-466.2050, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  0.9400670528411865 current loss tensor(-466.2620, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  0.9429705142974854 current loss tensor(-466.3185, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  0.9436972141265869 current loss tensor(-466.3746, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  0.9551117420196533 current loss tensor(-466.4302, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  0.9724223613739014 current loss tensor(-466.4853, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  0.9404463768005371 current loss tensor(-466.5399, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  0.9409348964691162 current loss tensor(-466.5941, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  0.95768141746521 current loss tensor(-466.6477, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  0.9414317607879639 current loss tensor(-466.7009, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  0.9435446262359619 current loss tensor(-466.7536, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  0.959418773651123 current loss tensor(-466.8059, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  0.9495275020599365 current loss tensor(-466.8577, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  0.956592321395874 current loss tensor(-466.9090, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  0.9494905471801758 current loss tensor(-466.9599, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  0.9435153007507324 current loss tensor(-467.0103, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  0.9419856071472168 current loss tensor(-467.0604, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  0.9408223628997803 current loss tensor(-467.1100, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  0.9392678737640381 current loss tensor(-467.1592, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  0.9437534809112549 current loss tensor(-467.2080, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  0.9440040588378906 current loss tensor(-467.2564, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  0.9462010860443115 current loss tensor(-467.3044, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  0.9450192451477051 current loss tensor(-467.3521, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  0.9404113292694092 current loss tensor(-467.3993, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  0.9435608386993408 current loss tensor(-467.4461, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  0.941650390625 current loss tensor(-467.4925, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  0.9417414665222168 current loss tensor(-467.5385, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  0.9430665969848633 current loss tensor(-467.5842, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  0.9452807903289795 current loss tensor(-467.6292, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  0.9430298805236816 current loss tensor(-467.6738, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  0.9482314586639404 current loss tensor(-467.7180, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  0.9639546871185303 current loss tensor(-467.7617, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  1.0785229206085205 current loss tensor(-467.8049, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  0.9397573471069336 current loss tensor(-467.8478, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  0.9436943531036377 current loss tensor(-467.8904, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  0.9435360431671143 current loss tensor(-467.9325, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  0.9399206638336182 current loss tensor(-467.9742, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  0.9390292167663574 current loss tensor(-468.0157, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  0.93971848487854 current loss tensor(-468.0567, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  0.9422779083251953 current loss tensor(-468.0974, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  0.9433269500732422 current loss tensor(-468.1377, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  0.944124698638916 current loss tensor(-468.1777, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  0.9420745372772217 current loss tensor(-468.2173, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  0.9370889663696289 current loss tensor(-468.2566, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  0.9437532424926758 current loss tensor(-468.2956, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  0.9537990093231201 current loss tensor(-468.3342, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  0.9431960582733154 current loss tensor(-468.3724, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  0.9457700252532959 current loss tensor(-468.4103, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  0.959223747253418 current loss tensor(-468.4480, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  0.9403746128082275 current loss tensor(-468.4853, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  0.9375174045562744 current loss tensor(-468.5223, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  0.9440264701843262 current loss tensor(-468.5590, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  0.9417650699615479 current loss tensor(-468.5954, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  0.9377989768981934 current loss tensor(-468.6315, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  0.9393434524536133 current loss tensor(-468.6672, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  0.9404125213623047 current loss tensor(-468.7027, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  0.944368839263916 current loss tensor(-468.7379, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  0.94264817237854 current loss tensor(-468.7728, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  0.9393560886383057 current loss tensor(-468.8074, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  0.9396505355834961 current loss tensor(-468.8417, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  0.9474260807037354 current loss tensor(-468.8757, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  0.9416615962982178 current loss tensor(-468.9095, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  0.9407193660736084 current loss tensor(-468.9430, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  0.939152717590332 current loss tensor(-468.9763, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  0.9432673454284668 current loss tensor(-469.0092, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  0.942399263381958 current loss tensor(-469.0420, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  0.9448831081390381 current loss tensor(-469.0745, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  0.9469835758209229 current loss tensor(-469.1067, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  0.9476466178894043 current loss tensor(-469.1387, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  0.9548048973083496 current loss tensor(-469.1705, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  0.9342114925384521 current loss tensor(-469.2021, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  0.9369184970855713 current loss tensor(-469.2334, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  0.9392995834350586 current loss tensor(-469.2645, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 98 0.8571887016296387 current loss tensor(-379.5923, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  0.8619763851165771 current loss tensor(-379.6060, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  0.8686075210571289 current loss tensor(-379.6194, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  0.8831367492675781 current loss tensor(-379.6326, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  0.8566932678222656 current loss tensor(-379.6456, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  0.857276439666748 current loss tensor(-379.6584, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  0.8712990283966064 current loss tensor(-379.6711, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  0.8576223850250244 current loss tensor(-379.6834, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  0.856177806854248 current loss tensor(-379.6956, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  0.8695507049560547 current loss tensor(-379.7076, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  0.8652608394622803 current loss tensor(-379.7194, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  0.8706741333007812 current loss tensor(-379.7310, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  0.8636054992675781 current loss tensor(-379.7423, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  0.85701584815979 current loss tensor(-379.7535, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  0.8534300327301025 current loss tensor(-379.7646, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  0.8569962978363037 current loss tensor(-379.7754, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  0.8521287441253662 current loss tensor(-379.7861, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  0.8589138984680176 current loss tensor(-379.7967, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  0.8597381114959717 current loss tensor(-379.8071, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  0.8557605743408203 current loss tensor(-379.8174, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  0.8533108234405518 current loss tensor(-379.8275, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  0.8552775382995605 current loss tensor(-379.8374, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  0.8560512065887451 current loss tensor(-379.8472, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  0.8551607131958008 current loss tensor(-379.8568, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  0.8545193672180176 current loss tensor(-379.8663, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  0.8549594879150391 current loss tensor(-379.8757, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  0.8604640960693359 current loss tensor(-379.8848, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  0.859886646270752 current loss tensor(-379.8939, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  0.8601217269897461 current loss tensor(-379.9027, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  0.8714268207550049 current loss tensor(-379.9115, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  0.8564398288726807 current loss tensor(-379.9201, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  0.8539319038391113 current loss tensor(-379.9286, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  0.8571016788482666 current loss tensor(-379.9371, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  0.854135274887085 current loss tensor(-379.9453, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  0.8556182384490967 current loss tensor(-379.9535, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  0.8553144931793213 current loss tensor(-379.9615, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  0.8570733070373535 current loss tensor(-379.9694, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  0.8484172821044922 current loss tensor(-379.9772, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  0.8596644401550293 current loss tensor(-379.9849, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  0.8573806285858154 current loss tensor(-379.9926, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  0.859015703201294 current loss tensor(-380.0001, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  0.8532817363739014 current loss tensor(-380.0075, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  0.8604393005371094 current loss tensor(-380.0149, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  0.8631079196929932 current loss tensor(-380.0222, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  0.8575983047485352 current loss tensor(-380.0294, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  0.8587758541107178 current loss tensor(-380.0366, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  0.8700010776519775 current loss tensor(-380.0437, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  0.8552076816558838 current loss tensor(-380.0507, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  0.8556015491485596 current loss tensor(-380.0577, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  0.8538427352905273 current loss tensor(-380.0646, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  0.857607364654541 current loss tensor(-380.0714, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  0.8528122901916504 current loss tensor(-380.0782, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  0.8565919399261475 current loss tensor(-380.0850, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  0.8565318584442139 current loss tensor(-380.0916, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  0.8561351299285889 current loss tensor(-380.0983, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  0.8589789867401123 current loss tensor(-380.1049, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  0.8527529239654541 current loss tensor(-380.1115, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  0.8605127334594727 current loss tensor(-380.1180, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  0.8576271533966064 current loss tensor(-380.1244, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  0.8555140495300293 current loss tensor(-380.1309, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  0.8557288646697998 current loss tensor(-380.1373, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  0.8559443950653076 current loss tensor(-380.1436, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  0.8630218505859375 current loss tensor(-380.1500, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  0.8543124198913574 current loss tensor(-380.1563, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  0.8578536510467529 current loss tensor(-380.1626, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  0.8589901924133301 current loss tensor(-380.1688, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  0.8610913753509521 current loss tensor(-380.1750, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  0.8676438331604004 current loss tensor(-380.1813, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  0.8571243286132812 current loss tensor(-380.1874, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  0.854517936706543 current loss tensor(-380.1936, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  0.8542609214782715 current loss tensor(-380.1998, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  0.8420441150665283 current loss tensor(-380.2059, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  0.8562753200531006 current loss tensor(-321.9407, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  0.6883490085601807 current loss tensor(-321.9489, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  0.6982393264770508 current loss tensor(-321.9569, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  0.8572802543640137 current loss tensor(-321.9649, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  0.6913912296295166 current loss tensor(-321.9728, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  0.6875081062316895 current loss tensor(-321.9805, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  0.704042911529541 current loss tensor(-321.9883, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  0.6904611587524414 current loss tensor(-321.9958, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  0.6910872459411621 current loss tensor(-322.0034, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  0.8158495426177979 current loss tensor(-322.0108, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  0.6914010047912598 current loss tensor(-322.0181, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  0.6996400356292725 current loss tensor(-322.0253, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  0.696645975112915 current loss tensor(-322.0324, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  0.691664457321167 current loss tensor(-322.0396, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  0.6914465427398682 current loss tensor(-322.0468, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  0.6897690296173096 current loss tensor(-322.0538, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  0.6889877319335938 current loss tensor(-322.0609, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  0.6938202381134033 current loss tensor(-322.0678, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  0.6949176788330078 current loss tensor(-322.0748, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  0.6895835399627686 current loss tensor(-322.0816, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  0.6888713836669922 current loss tensor(-322.0884, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  0.690131425857544 current loss tensor(-322.0952, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  0.6889998912811279 current loss tensor(-322.1019, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  0.689244270324707 current loss tensor(-322.1085, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  0.6906068325042725 current loss tensor(-322.1151, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  0.6879732608795166 current loss tensor(-322.1216, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  0.6932833194732666 current loss tensor(-322.1280, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  0.6912589073181152 current loss tensor(-322.1343, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  0.6992087364196777 current loss tensor(-322.1406, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  0.7013463973999023 current loss tensor(-322.1469, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  0.6902315616607666 current loss tensor(-322.1531, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  0.6862409114837646 current loss tensor(-322.1593, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  0.6893875598907471 current loss tensor(-322.1655, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  0.6902267932891846 current loss tensor(-322.1715, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  0.6891376972198486 current loss tensor(-322.1776, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  0.6898946762084961 current loss tensor(-322.1837, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  0.6904897689819336 current loss tensor(-322.1897, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  0.700782060623169 current loss tensor(-322.1957, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  0.6897013187408447 current loss tensor(-322.2017, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  0.6920604705810547 current loss tensor(-322.2076, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  0.6895372867584229 current loss tensor(-322.2135, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  0.6876754760742188 current loss tensor(-322.2194, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  0.6939716339111328 current loss tensor(-322.2252, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  0.6967282295227051 current loss tensor(-322.2311, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  0.690075159072876 current loss tensor(-322.2369, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  0.6957249641418457 current loss tensor(-322.2427, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  0.7020838260650635 current loss tensor(-322.2485, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  0.6876206398010254 current loss tensor(-322.2543, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  0.6884336471557617 current loss tensor(-322.2600, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  0.6908769607543945 current loss tensor(-322.2658, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  0.6899292469024658 current loss tensor(-322.2715, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  0.6934206485748291 current loss tensor(-322.2772, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  0.6893134117126465 current loss tensor(-322.2829, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  0.6884040832519531 current loss tensor(-322.2886, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  0.6899797916412354 current loss tensor(-322.2942, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  0.6933116912841797 current loss tensor(-322.2999, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  0.6874678134918213 current loss tensor(-322.3055, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  0.6888086795806885 current loss tensor(-322.3112, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  0.6913025379180908 current loss tensor(-322.3169, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  0.6893825531005859 current loss tensor(-322.3225, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  0.6899526119232178 current loss tensor(-322.3282, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  0.690873384475708 current loss tensor(-322.3338, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  0.6922597885131836 current loss tensor(-322.3395, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  0.6891052722930908 current loss tensor(-322.3452, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  0.6927435398101807 current loss tensor(-322.3508, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  0.6985461711883545 current loss tensor(-322.3565, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  0.6944704055786133 current loss tensor(-322.3622, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  0.7009069919586182 current loss tensor(-322.3678, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  0.6880803108215332 current loss tensor(-322.3735, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  0.6881446838378906 current loss tensor(-322.3792, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  0.6847519874572754 current loss tensor(-322.3849, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  0.6852591037750244 current loss tensor(-322.3906, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  0.6885552406311035 current loss tensor(-322.3964, device='cuda:3', grad_fn=<SumBackward0>)
tensor(-583.5010, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.4675, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 67 Epoch time:  1.6801950931549072 current loss tensor(-1163.5732, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.5342, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.5010, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 68 Epoch time:  1.6896395683288574 current loss tensor(-1163.6534, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.5670, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.5342, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 69 Epoch time:  1.6857423782348633 current loss tensor(-1163.7324, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.5994, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.5670, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 70 Epoch time:  1.690201759338379 current loss tensor(-1163.8102, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.6314, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.5994, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 71 Epoch time:  1.6797804832458496 current loss tensor(-1163.8868, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.6630, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.6314, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 72 Epoch time:  1.6836066246032715 current loss tensor(-1163.9623, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.6942, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.6630, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 73 Epoch time:  1.6943695545196533 current loss tensor(-1164.0364, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.7249, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.6942, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 74 Epoch time:  1.6800823211669922 current loss tensor(-1164.1093, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.7552, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.7249, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 75 Epoch time:  1.682835340499878 current loss tensor(-1164.1812, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.7853, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.7552, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 76 Epoch time:  1.6892151832580566 current loss tensor(-1164.2520, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.8149, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.7853, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 77 Epoch time:  1.6765477657318115 current loss tensor(-1164.3217, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.8444, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.8149, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 78 Epoch time:  1.680539846420288 current loss tensor(-1164.3904, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.8732, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.8444, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 79 Epoch time:  1.6795494556427002 current loss tensor(-1164.4578, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.9019, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.8732, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 80 Epoch time:  1.6766324043273926 current loss tensor(-1164.5244, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.9301, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.9019, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 81 Epoch time:  1.6784553527832031 current loss tensor(-1164.5898, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.9580, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.9301, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 82 Epoch time:  1.6811275482177734 current loss tensor(-1164.6543, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-583.9855, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.9580, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 83 Epoch time:  1.6822621822357178 current loss tensor(-1164.7178, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.0128, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-583.9855, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 84 Epoch time:  1.7151625156402588 current loss tensor(-1164.7803, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.0397, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.0128, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 85 Epoch time:  1.6755881309509277 current loss tensor(-1164.8418, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.0662, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.0397, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 86 Epoch time:  1.6794495582580566 current loss tensor(-1164.9021, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.0925, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.0662, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 87 Epoch time:  1.6805698871612549 current loss tensor(-1164.9618, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.1185, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.0925, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 88 Epoch time:  1.6816692352294922 current loss tensor(-1165.0205, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.1442, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.1185, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 89 Epoch time:  1.6815648078918457 current loss tensor(-1165.0781, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.1696, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.1442, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 90 Epoch time:  1.67952299118042 current loss tensor(-1165.1349, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.1947, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.1696, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 91 Epoch time:  1.6770086288452148 current loss tensor(-1165.1908, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.2195, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.1947, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 92 Epoch time:  1.693657398223877 current loss tensor(-1165.2458, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.2439, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.2195, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 93 Epoch time:  1.6833984851837158 current loss tensor(-1165.2998, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.2682, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.2439, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 94 Epoch time:  1.6925106048583984 current loss tensor(-1165.3530, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.2921, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.2682, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 95 Epoch time:  1.6770431995391846 current loss tensor(-1165.4053, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.3157, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.2921, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 96 Epoch time:  1.679091453552246 current loss tensor(-1165.4568, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.3391, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.3157, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 97 Epoch time:  1.6762242317199707 current loss tensor(-1165.5074, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.3623, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.3391, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 98 Epoch time:  1.6806912422180176 current loss tensor(-1165.5571, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-584.3851, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-584.3623, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 99 Epoch time:  1.678891897201538 current loss tensor(-1165.6062, device='cuda:0', grad_fn=<SumBackward0>)
best_out [0.4253486  0.44888508 0.41382754 0.3843171  0.38599637 0.35542178
 0.4499658  0.44585574 0.4225732  0.475912   0.4891258  0.47237834
 0.42101273 0.45252246 0.47116    0.45437187 0.3986371  0.4673515
 0.53080964 0.4008178  0.47717246 0.47286862 0.46053225 0.3573531
 0.4154647  0.38597044 0.4512337  0.5162878  0.4263363  0.43109187
 0.5068183  0.43973398 0.43009743 0.44716755 0.44436994 0.3321039
 0.43581024 0.45937324 0.48658022 0.36318636 0.48711056 0.40526572
 0.3751515  0.4500135  0.3853908  0.44665378 0.42559165 0.49645147
 0.43310633 0.3577148  0.46591678 0.40589574 0.5274549  0.522911
 0.48347113 0.48489836 0.41184816 0.35782    0.48688444 0.44790497
 0.48329458 0.5566452  0.49904886 0.5078435  0.41836378 0.47725913
 0.3887852  0.53732455 0.43090612 0.40627643 0.4503047  0.53477174
 0.41383052 0.5068465  0.4593925  0.45746186 0.47587013 0.50456804
 0.40763435 0.4491186  0.5358621  0.5088846  0.4884371  0.52546394
 0.5119259  0.39199263 0.3780197  0.43789145 0.4786215  0.5025292
 0.47876576 0.38997766 0.38648677 0.45199987 0.4568876  0.41164884
 0.40254053 0.5113688  0.47594193 0.47540075 0.47897768 0.37241715
 0.53836167 0.4073957  0.3981175  0.51856375 0.38032746 0.4408075
 0.54173183 0.46168292 0.44988838 0.36775666 0.4397043  0.42358312
 0.5274667  0.4494442  0.5119863  0.42350528 0.5181407  0.45690924
 0.38454208 0.42092672 0.52581525 0.42194766 0.42811137 0.42095974
 0.49436727 0.4691164  0.49025664 0.43443522 0.47440448 0.44184893
 0.5360131  0.55181694 0.45360634 0.5140414  0.6054141  0.494102
 0.38990018 0.5128282  0.52943236 0.52759    0.49053457 0.43378392
 0.5585961  0.46353316 0.45063296 0.5063883  0.42397276 0.4173459
 0.52046984 0.50086516 0.43829507 0.46378285 0.50247467 0.5068918
 0.42339438 0.4801392  0.5367068  0.5930979  0.5269885  0.45738724
 0.47688526 0.4593263  0.5259391  0.5996256  0.4222963  0.4977891
 0.45104805 0.48537198 0.51368433 0.4127088  0.54541713 0.5048123
 0.4222068  0.4230234  0.5536664  0.3790743  0.5894866  0.47774088
 0.41667232 0.42471823 0.4535638  0.49552336 0.47692126 0.48016098
 0.5675995  0.35279283 0.45226288 0.5204384  0.4252717  0.49929526
 0.4923085  0.46767318 0.5086032  0.44650286 0.4466479  0.49199042
 0.4783904  0.39654619 0.4753743  0.7549983  0.22770835 0.16565858
 0.2252095  0.35502177 0.40335277 0.41725546 0.28522024 0.7327771
 0.35199434 0.4540046  0.35530773 0.47887003 0.9539142  0.23860393
 0.73105854 0.3660263  0.6145831  0.73105854 0.2655318  0.73105854
 0.08313638 0.73105854 0.6825271  0.6166756  0.3664068  0.56892735
 0.64944607 0.2777968  0.7102295  0.30911425 0.641351   0.48901138
 0.24750349 0.73105854 0.73105854 0.40823004 0.54831487 0.40981448
 0.3934213  0.24170542 0.12871826 0.41869953 0.31435537 0.2320027
 0.51837313 0.65384173 0.4867895  0.12856321 0.3552752  0.62598443
 0.27983353 0.7614034  0.73105854 0.69647104 0.34585392 0.11484337
 0.86547995 0.73105854 0.23000947 0.831571   0.7942518  0.8408608
 0.73105854 0.57584286 0.73105854 0.73105854 0.12814638 0.73105854
 0.78821564 0.6971318  0.31688806 0.3332084  0.45165265 0.34790596
 0.8703383  0.7573529  0.43397167 0.35874715 0.9001169  0.30678496
 0.85689485 0.49704686 0.8391999  0.73105854 0.37858644 0.73105854
 0.7614034  0.831571   0.25299898 0.32846218 0.09306519 0.25166392
 0.33510178 0.43820736 0.73105854 0.31598246 0.73105854 0.2841696
 0.26568228 0.14585733 0.77909833 0.7970234  0.5925632  0.73105854
 0.6102547  0.4092735  0.7613587  0.19515857 0.18299995 0.73105854
 0.73105854 0.35730913 0.31340575 0.6849395  0.73105854 0.8172493
 0.6524657  0.73105854 0.34133694 0.14518985 0.5796438  0.2802637
 0.572711   0.33050427 0.41321465 0.5510296  0.69650507 0.73105854
 0.758621   0.30082598 0.73105854 0.6464408  0.28300765 0.35029697
 0.69344896 0.55931276 0.10556402 0.7993033  0.5753613  0.6371224
 0.4683252  0.19485268 0.64437217 0.73105854 0.3996622  0.25289598
 0.64944607 0.29682404 0.65836054 0.31650257 0.3583243  0.33150682
 0.3284423  0.21893026 0.73105854 0.7588389  0.5411955  0.31645584
 0.45953956 0.7771377  0.51440686 0.23727056 0.474082   0.73105854
 0.37295073 0.4145798  0.73105854 0.69019264 0.73105854 0.51837313
 0.5017079  0.6524657  0.73105854 0.73105854 0.75836986 0.47915703
 0.8028962  0.55832845 0.3044472  0.34354085 0.48005983 0.34988344
 0.34085804 0.6620575  0.73105854 0.20891127 0.38081524 0.64944607
 0.5926048  0.70424175 0.43550262 0.47870958 0.12605977 0.73105854
 0.60966593 0.40823004 0.6523607  0.4092735  0.41856724 0.73105854
 0.09343039 0.02359544 0.73105854 0.04100279 0.53908205 0.5634416
 0.2528366  0.73105854 0.73105854 0.4156089  0.49318075 0.61629295
 0.73105854 0.73105854 0.22394316 0.73105854 0.58861375 0.73105854
 0.68133587 0.79535586 0.04869299 0.73105854 0.6238854  0.37936577
 0.55867606 0.53806484 0.73105854 0.6786201  0.73105854 0.73105854
 0.5967296  0.45696765 0.73105854 0.73105854 0.22188671 0.3802437
 0.73105854 0.73105854 0.3497666  0.73105854 0.05494415 0.6355047
 0.73105854 0.16431749 0.54824847 0.73105854 0.73105854 0.3665773
 0.73105854 0.83882207 0.73105854 0.73105854 0.20162238 0.73105854
 0.07376394 0.00355301 0.73105854 0.70433193 0.36736405 0.73105854
 0.55476314 0.7133974  0.11487804 0.73105854 0.73105854 0.49722162
 0.14704053 0.090359   0.5718289  0.6242933  0.73105854 0.32327265
 0.52628165 0.86070853 0.83882207 0.68133587 0.73105854 0.712141
 0.49960002 0.50159127 0.78330064 0.61524343 0.78851736 0.7434231
 0.47537652 0.73105854 0.7050421  0.7252285  0.73105854 0.21439563
 0.18824032 0.3641654  0.2953764  0.73105854 0.73105854 0.33392385
 0.7782582  0.73105854 0.16742994 0.02437266 0.64791954 0.9029072
 0.5803594  0.69306797 0.2528366  0.73105854 0.6079439  0.73105854
 0.2510343  0.73105854 0.73105854 0.02949294 0.18823704 0.6864576
 0.40757152 0.8170334  0.712141   0.4022976  0.35314935 0.15090239
 0.31657785 0.73105854 0.10965097 0.712141   0.73105854 0.10038199
 0.31497675 0.73105854 0.73105854 0.31449166 0.7238523  0.73105854
 0.73105854 0.6888005  0.65182275 0.73105854 0.04846985 0.36487588
 0.785385   0.63293445 0.7698516  0.26757696 0.9029072  0.48413572
 0.2919498  0.73105854 0.6864576  0.73105854 0.73105854 0.73105854
 0.73105854 0.73105854 0.73105854 0.18251781 0.38179615 0.8496177
 0.5671446  0.63293445 0.79646975 0.73105854 0.73105854 0.73105854
 0.48247257 0.49498576 0.73105854 0.79535586 0.607128   0.5684975
 0.6329436  0.36487588 0.42939886 0.47055963 0.47055963 0.12985641
 0.73105854 0.3591011  0.73105854 0.73105854 0.18823704 0.67752093
 0.89298356 0.5489209  0.73105854 0.70835495 0.24148858 0.04863349
 0.425131   0.6290181  0.73105854 0.6637142  0.18824032 0.73105854
 0.73105854 0.4542819  0.73105854 0.73105854 0.69471824 0.53185135
 0.29152632 0.8044806  0.73105854 0.09121405 0.12967145 0.73105854
 0.504104   0.7787614  0.1850447  0.9106693  0.5435706  0.73105854
 0.5352369  0.73105854 0.8134239  0.73105854 0.73105854 0.73105854
 0.73105854 0.67035395 0.2829044  0.73105854 0.73105854 0.1010034
 0.8141675  0.2763249  0.73105854 0.70580167 0.34456566 0.73105854
 0.73105854 0.43901724 0.84107715 0.73105854 0.03947699 0.35763824
 0.2413659  0.58911026 0.73105854 0.26353267 0.47025236 0.13085933
 0.56979525 0.6908436  0.73105854 0.0700602  0.5230642  0.73105854
 0.12049778 0.3557547  0.4706455  0.73105854 0.36053842 0.73105854
 0.30532786 0.73105854 0.73105854 0.11169729 0.73105854 0.73105854
 0.73105854 0.485496   0.69963485 0.73105854 0.14222337 0.74843675
 0.73105854 0.23157173 0.27407417 0.73105854 0.51961315 0.47919196
 0.73105854 0.73105854 0.73105854 0.8607364  0.60680044 0.73105854
 0.33850023 0.73105854 0.4668558  0.4951408  0.73105854 0.578088
 0.73105854 0.73105854 0.43619412 0.6748197  0.1848709  0.73105854
 0.2763249  0.16410361 0.08220699 0.01957214 0.73105854 0.73105854
 0.6188567  0.73105854 0.7784425  0.2156964  0.25475323 0.43256345
 0.38079515 0.83149326 0.63534445 0.7871109  0.1402344  0.29038268
 0.73105854 0.25447312 0.5330892  0.05543726 0.73105854 0.73105854
 0.73105854 0.73105854 0.79253334 0.73105854 0.6748197  0.22975937
 0.5540494  0.08263109 0.73105854 0.73105854 0.73105854 0.73105854
 0.4722121  0.73105854 0.4706455  0.47716877 0.44587365 0.73105854
 0.73105854 0.5445384  0.19854786 0.9076053  0.7098234  0.64107895
 0.1848709  0.5699866  0.73105854 0.73105854 0.3577437  0.73105854
 0.5615997  0.67035395 0.63795346 0.73105854 0.11272766 0.32330093
 0.73105854 0.5445384  0.73105854 0.63795346 0.44197565 0.73105854
 0.73105854 0.73105854 0.859717   0.64826334 0.73105854 0.83010864
 0.5563027  0.73105854 0.73105854 0.56979525 0.632104   0.73105854
 0.73105854 0.6843347  0.73105854 0.09772807 0.73105854 0.35136434
 0.73105854 0.5445384  0.7516084  0.05496309 0.78613526 0.73105854
 0.16127135 0.73105854 0.73105854 0.4824414  0.73105854 0.73105854
 0.13016325 0.09322064 0.73105854 0.7691256  0.73105854 0.73105854
 0.1010034  0.39358294 0.16127135 0.8077349  0.5330892  0.28256354
 0.6945705  0.6256685 ]
info_input_total 800 weights 800 total_C 4672
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
-2447
res {1: 1, 2: 0, 3: 1, 4: 1, 5: 0, 6: 0, 7: 0, 8: 1, 9: 0, 10: 0, 11: 1, 12: 0, 13: 0, 14: 1, 15: 0, 16: 1, 17: 0, 18: 0, 19: 1, 20: 0, 21: 1, 22: 1, 23: 1, 24: 1, 25: 0, 26: 0, 27: 1, 28: 1, 29: 0, 30: 0, 31: 0, 32: 1, 33: 0, 34: 1, 35: 1, 36: 0, 37: 0, 38: 1, 39: 1, 40: 0, 41: 0, 42: 0, 43: 1, 44: 1, 45: 1, 46: 0, 47: 0, 48: 0, 49: 1, 50: 1, 51: 0, 52: 1, 53: 0, 54: 0, 55: 1, 56: 1, 57: 1, 58: 0, 59: 0, 60: 0, 61: 1, 62: 0, 63: 1, 64: 1, 65: 0, 66: 1, 67: 1, 68: 0, 69: 0, 70: 0, 71: 1, 72: 0, 73: 1, 74: 1, 75: 0, 76: 1, 77: 1, 78: 0, 79: 0, 80: 0, 81: 0, 82: 0, 83: 0, 84: 0, 85: 0, 86: 1, 87: 1, 88: 1, 89: 1, 90: 1, 91: 0, 92: 1, 93: 0, 94: 0, 95: 0, 96: 0, 97: 1, 98: 1, 99: 1, 100: 1, 101: 1, 102: 0, 103: 0, 104: 1, 105: 0, 106: 0, 107: 1, 108: 1, 109: 1, 110: 0, 111: 0, 112: 0, 113: 0, 114: 1, 115: 0, 116: 1, 117: 0, 118: 0, 119: 0, 120: 1, 121: 0, 122: 0, 123: 1, 124: 0, 125: 1, 126: 1, 127: 1, 128: 1, 129: 1, 130: 1, 131: 1, 132: 1, 133: 1, 134: 1, 135: 0, 136: 1, 137: 0, 138: 1, 139: 0, 140: 0, 141: 1, 142: 0, 143: 1, 144: 0, 145: 0, 146: 1, 147: 0, 148: 1, 149: 1, 150: 1, 151: 0, 152: 0, 153: 1, 154: 0, 155: 0, 156: 0, 157: 0, 158: 0, 159: 1, 160: 1, 161: 1, 162: 1, 163: 0, 164: 0, 165: 1, 166: 0, 167: 1, 168: 1, 169: 1, 170: 0, 171: 0, 172: 0, 173: 1, 174: 1, 175: 1, 176: 1, 177: 1, 178: 1, 179: 0, 180: 0, 181: 1, 182: 1, 183: 1, 184: 0, 185: 1, 186: 0, 187: 0, 188: 1, 189: 0, 190: 1, 191: 1, 192: 1, 193: 1, 194: 1, 195: 0, 196: 0, 197: 1, 198: 0, 199: 0, 200: 0, 201: 0, 202: 1, 203: 0, 204: 1, 205: 1, 206: 0, 207: 0, 208: 1, 209: 0, 210: 1, 211: 1, 212: 1, 213: 0, 214: 1, 215: 1, 216: 0, 217: 1, 218: 0, 219: 1, 220: 1, 221: 0, 222: 1, 223: 0, 224: 1, 225: 1, 226: 1, 227: 1, 228: 1, 229: 1, 230: 1, 231: 0, 232: 0, 233: 1, 234: 0, 235: 0, 236: 0, 237: 1, 238: 0, 239: 0, 240: 0, 241: 0, 242: 0, 243: 0, 244: 1, 245: 0, 246: 0, 247: 1, 248: 1, 249: 1, 250: 0, 251: 0, 252: 1, 253: 1, 254: 1, 255: 1, 256: 0, 257: 1, 258: 0, 259: 1, 260: 1, 261: 0, 262: 1, 263: 1, 264: 1, 265: 1, 266: 1, 267: 1, 268: 1, 269: 0, 270: 1, 271: 1, 272: 1, 273: 0, 274: 1, 275: 1, 276: 0, 277: 1, 278: 1, 279: 0, 280: 1, 281: 1, 282: 0, 283: 1, 284: 0, 285: 1, 286: 1, 287: 1, 288: 1, 289: 1, 290: 1, 291: 0, 292: 0, 293: 0, 294: 0, 295: 1, 296: 1, 297: 0, 298: 0, 299: 1, 300: 0, 301: 0, 302: 0, 303: 1, 304: 1, 305: 1, 306: 0, 307: 0, 308: 0, 309: 1, 310: 0, 311: 0, 312: 1, 313: 1, 314: 1, 315: 0, 316: 1, 317: 1, 318: 1, 319: 0, 320: 0, 321: 0, 322: 0, 323: 1, 324: 0, 325: 0, 326: 0, 327: 0, 328: 1, 329: 0, 330: 0, 331: 1, 332: 1, 333: 1, 334: 0, 335: 0, 336: 1, 337: 1, 338: 1, 339: 1, 340: 1, 341: 1, 342: 1, 343: 1, 344: 0, 345: 0, 346: 1, 347: 1, 348: 1, 349: 1, 350: 1, 351: 1, 352: 0, 353: 0, 354: 0, 355: 0, 356: 0, 357: 1, 358: 1, 359: 1, 360: 0, 361: 0, 362: 1, 363: 1, 364: 1, 365: 1, 366: 1, 367: 0, 368: 0, 369: 1, 370: 0, 371: 1, 372: 0, 373: 1, 374: 1, 375: 1, 376: 1, 377: 0, 378: 0, 379: 0, 380: 0, 381: 1, 382: 0, 383: 0, 384: 0, 385: 0, 386: 1, 387: 0, 388: 0, 389: 0, 390: 1, 391: 0, 392: 1, 393: 0, 394: 0, 395: 0, 396: 0, 397: 1, 398: 0, 399: 1, 400: 0, 401: 0, 402: 1, 403: 0, 404: 0, 405: 1, 406: 0, 407: 0, 408: 1, 409: 0, 410: 1, 411: 1, 412: 1, 413: 0, 414: 1, 415: 1, 416: 1, 417: 1, 418: 0, 419: 1, 420: 1, 421: 1, 422: 1, 423: 0, 424: 1, 425: 1, 426: 0, 427: 1, 428: 0, 429: 1, 430: 1, 431: 1, 432: 0, 433: 0, 434: 1, 435: 0, 436: 1, 437: 0, 438: 0, 439: 1, 440: 0, 441: 0, 442: 1, 443: 0, 444: 1, 445: 1, 446: 0, 447: 1, 448: 1, 449: 0, 450: 1, 451: 0, 452: 1, 453: 0, 454: 0, 455: 0, 456: 1, 457: 0, 458: 0, 459: 0, 460: 0, 461: 0, 462: 0, 463: 1, 464: 1, 465: 0, 466: 1, 467: 1, 468: 0, 469: 0, 470: 0, 471: 0, 472: 0, 473: 1, 474: 1, 475: 0, 476: 1, 477: 1, 478: 0, 479: 0, 480: 1, 481: 1, 482: 0, 483: 0, 484: 0, 485: 0, 486: 0, 487: 1, 488: 1, 489: 0, 490: 1, 491: 1, 492: 0, 493: 1, 494: 0, 495: 0, 496: 1, 497: 1, 498: 0, 499: 1, 500: 1, 501: 0, 502: 0, 503: 1, 504: 1, 505: 0, 506: 1, 507: 0, 508: 1, 509: 1, 510: 0, 511: 0, 512: 1, 513: 1, 514: 0, 515: 0, 516: 1, 517: 1, 518: 1, 519: 0, 520: 0, 521: 0, 522: 0, 523: 1, 524: 1, 525: 0, 526: 1, 527: 0, 528: 0, 529: 0, 530: 1, 531: 0, 532: 0, 533: 0, 534: 1, 535: 1, 536: 0, 537: 1, 538: 0, 539: 0, 540: 0, 541: 1, 542: 0, 543: 0, 544: 0, 545: 1, 546: 1, 547: 1, 548: 1, 549: 1, 550: 1, 551: 1, 552: 1, 553: 1, 554: 0, 555: 1, 556: 0, 557: 1, 558: 1, 559: 0, 560: 0, 561: 1, 562: 0, 563: 1, 564: 1, 565: 0, 566: 0, 567: 1, 568: 0, 569: 0, 570: 1, 571: 0, 572: 0, 573: 1, 574: 0, 575: 0, 576: 0, 577: 1, 578: 1, 579: 1, 580: 1, 581: 0, 582: 0, 583: 1, 584: 1, 585: 1, 586: 0, 587: 1, 588: 1, 589: 0, 590: 1, 591: 1, 592: 0, 593: 0, 594: 1, 595: 1, 596: 1, 597: 0, 598: 1, 599: 1, 600: 1, 601: 0, 602: 1, 603: 1, 604: 0, 605: 0, 606: 1, 607: 1, 608: 1, 609: 0, 610: 1, 611: 1, 612: 1, 613: 0, 614: 1, 615: 1, 616: 1, 617: 0, 618: 1, 619: 1, 620: 1, 621: 1, 622: 1, 623: 1, 624: 0, 625: 1, 626: 0, 627: 0, 628: 1, 629: 0, 630: 1, 631: 0, 632: 0, 633: 1, 634: 1, 635: 0, 636: 1, 637: 1, 638: 0, 639: 1, 640: 0, 641: 1, 642: 0, 643: 0, 644: 1, 645: 1, 646: 0, 647: 1, 648: 1, 649: 0, 650: 0, 651: 1, 652: 0, 653: 0, 654: 1, 655: 0, 656: 1, 657: 1, 658: 0, 659: 1, 660: 1, 661: 1, 662: 0, 663: 1, 664: 1, 665: 0, 666: 1, 667: 1, 668: 0, 669: 1, 670: 1, 671: 0, 672: 1, 673: 0, 674: 1, 675: 1, 676: 1, 677: 1, 678: 1, 679: 0, 680: 1, 681: 0, 682: 0, 683: 1, 684: 1, 685: 1, 686: 1, 687: 0, 688: 1, 689: 0, 690: 1, 691: 1, 692: 0, 693: 0, 694: 0, 695: 1, 696: 0, 697: 1, 698: 1, 699: 1, 700: 0, 701: 0, 702: 1, 703: 0, 704: 1, 705: 1, 706: 1, 707: 0, 708: 0, 709: 1, 710: 1, 711: 1, 712: 0, 713: 1, 714: 1, 715: 1, 716: 1, 717: 1, 718: 1, 719: 1, 720: 0, 721: 0, 722: 0, 723: 1, 724: 1, 725: 0, 726: 1, 727: 1, 728: 0, 729: 1, 730: 1, 731: 1, 732: 1, 733: 1, 734: 1, 735: 0, 736: 1, 737: 1, 738: 1, 739: 0, 740: 1, 741: 1, 742: 1, 743: 1, 744: 1, 745: 1, 746: 0, 747: 1, 748: 1, 749: 0, 750: 0, 751: 1, 752: 0, 753: 1, 754: 0, 755: 1, 756: 0, 757: 0, 758: 1, 759: 1, 760: 0, 761: 1, 762: 1, 763: 1, 764: 1, 765: 1, 766: 0, 767: 1, 768: 0, 769: 1, 770: 0, 771: 0, 772: 0, 773: 1, 774: 0, 775: 1, 776: 0, 777: 1, 778: 0, 779: 1, 780: 1, 781: 0, 782: 0, 783: 1, 784: 0, 785: 0, 786: 1, 787: 0, 788: 0, 789: 1, 790: 1, 791: 1, 792: 0, 793: 0, 794: 0, 795: 0, 796: 1, 797: 0, 798: 1, 799: 1, 800: 1}
-2447.0
-2168.0
dealing G2.txt
device 0 start to train
[n] 200 [C] 1233 weight 800
con_list_range [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200]
average_loss tensor(-2367.7332, device='cuda:0', grad_fn=<DivBackward0>) best_loss inf
Epoch 0 Epoch time:  3.2139370441436768 current loss tensor(-2397.8035, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2368.1465, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2367.7332, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1 Epoch time:  2.860288619995117 current loss tensor(-2398.1885, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2368.5566, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2368.1465, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2 Epoch time:  2.7953243255615234 current loss tensor(-2398.5708, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2368.9639, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2368.5566, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3 Epoch time:  2.9144530296325684 current loss tensor(-2398.9497, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2369.3682, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2368.9639, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4 Epoch time:  2.825240135192871 current loss tensor(-2399.3257, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2369.7693, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2369.3682, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5 Epoch time:  2.826049566268921 current loss tensor(-2399.6987, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2370.1670, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2369.7693, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6 Epoch time:  2.927541732788086 current loss tensor(-2400.0679, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2370.5615, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2370.1670, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7 Epoch time:  2.9247443675994873 current loss tensor(-2400.4341, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2370.9526, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2370.5615, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8 Epoch time:  2.820025682449341 current loss tensor(-2400.7969, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2371.3406, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2370.9526, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9 Epoch time:  2.8758902549743652 current loss tensor(-2401.1562, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2371.7251, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2371.3406, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10 Epoch time:  2.817652940750122 current loss tensor(-2401.5122, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2372.1060, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2371.7251, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11 Epoch time:  2.8110458850860596 current loss tensor(-2401.8647, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2372.4834, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2372.1060, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12 Epoch time:  2.899705410003662 current loss tensor(-2402.2139, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2372.8574, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2372.4834, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13 Epoch time:  2.81610107421875 current loss tensor(-2402.5591, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2373.2275, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2372.8574, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14 Epoch time:  2.8929951190948486 current loss tensor(-2402.9014, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2373.5942, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2373.2275, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15 Epoch time:  2.831519365310669 current loss tensor(-2403.2395, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2373.9575, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2373.5942, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16 Epoch time:  2.8705272674560547 current loss tensor(-2403.5742, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2374.3169, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2373.9575, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17 Epoch time:  2.82487154006958 current loss tensor(-2403.9058, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2374.6731, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2374.3169, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18 Epoch time:  2.957972764968872 current loss tensor(-2404.2336, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2375.0251, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2374.6731, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19 Epoch time:  2.8093554973602295 current loss tensor(-2404.5574, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2375.3735, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.0251, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20 Epoch time:  2.8348677158355713 current loss tensor(-2404.8774, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2375.7183, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.3735, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21 Epoch time:  2.8888258934020996 current loss tensor(-2405.1938, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.0591, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.7183, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22 Epoch time:  2.922041177749634 current loss tensor(-2405.5068, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.3958, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.0591, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23 Epoch time:  2.885922431945801 current loss tensor(-2405.8154, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.7290, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.3958, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24 Epoch time:  2.8145956993103027 current loss tensor(-2406.1206, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.0586, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.7290, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25 Epoch time:  2.822098970413208 current loss tensor(-2406.4224, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.3843, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.0586, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26 Epoch time:  2.8335726261138916 current loss tensor(-2406.7202, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.7061, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.3843, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27 Epoch time:  2.936797618865967 current loss tensor(-2407.0142, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.0239, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.7061, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28 Epoch time:  2.818359851837158 current loss tensor(-2407.3044, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.3379, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.0239, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29 Epoch time:  2.8220303058624268 current loss tensor(-2407.5908, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.6482, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.3379, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30 Epoch time:  2.8270134925842285 current loss tensor(-2407.8738, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.9548, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.6482, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31 Epoch time:  2.817056655883789 current loss tensor(-2408.1526, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.2576, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.9548, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32 Epoch time:  2.90041184425354 current loss tensor(-2408.4280, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.5569, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.2576, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33 Epoch time:  2.8193752765655518 current loss tensor(-2408.6997, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.8525, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.5569, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34 Epoch time:  2.9225709438323975 current loss tensor(-2408.9683, device='cuda:0', grad_fn=<SumBackward0>)
Epoch time:  0.9413847923278809 current loss tensor(-469.2954, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  0.9465377330780029 current loss tensor(-469.3260, device='cuda:1', grad_fn=<SumBackward0>)
dealing G2.txt
device 1 start to train
[n] 200 [C] 1180 weight 800
con_list_range [201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400]
Epoch 0 Epoch time:  3.0969583988189697 current loss tensor(-2349.0054, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.742924451828003 current loss tensor(-2349.4521, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.8319473266601562 current loss tensor(-2349.8958, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.9422645568847656 current loss tensor(-2350.3364, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.794459581375122 current loss tensor(-2350.7739, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  2.8361191749572754 current loss tensor(-2351.2078, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.8035755157470703 current loss tensor(-2351.6387, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.8626999855041504 current loss tensor(-2352.0664, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  2.8784775733947754 current loss tensor(-2352.4902, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  2.8059563636779785 current loss tensor(-2352.9111, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.858410120010376 current loss tensor(-2353.3286, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.8403873443603516 current loss tensor(-2353.7422, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.9220268726348877 current loss tensor(-2354.1528, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.7880046367645264 current loss tensor(-2354.5593, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.832150459289551 current loss tensor(-2354.9622, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.8847086429595947 current loss tensor(-2355.3613, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.825679063796997 current loss tensor(-2355.7568, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.9031453132629395 current loss tensor(-2356.1487, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.8262369632720947 current loss tensor(-2356.5366, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.8672292232513428 current loss tensor(-2356.9211, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.837144136428833 current loss tensor(-2357.3013, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  2.8284547328948975 current loss tensor(-2357.6777, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.0176455974578857 current loss tensor(-2358.0500, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.7854812145233154 current loss tensor(-2358.4180, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.888345241546631 current loss tensor(-2358.7825, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.8312556743621826 current loss tensor(-2359.1428, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.8383734226226807 current loss tensor(-2359.4995, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.837695360183716 current loss tensor(-2359.8518, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.902233123779297 current loss tensor(-2360.2002, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.8169631958007812 current loss tensor(-2360.5444, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.845841407775879 current loss tensor(-2360.8850, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.8311939239501953 current loss tensor(-2361.2214, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.9489452838897705 current loss tensor(-2361.5542, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.8396849632263184 current loss tensor(-2361.8831, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.7936604022979736 current loss tensor(-2362.2085, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.9020161628723145 current loss tensor(-2362.5295, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.8403146266937256 current loss tensor(-2362.8472, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.887826919555664 current loss tensor(-2363.1606, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.828792095184326 current loss tensor(-2363.4702, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.859966278076172 current loss tensor(-2363.7764, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.9296298027038574 current loss tensor(-2364.0786, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.8035178184509277 current loss tensor(-2364.3774, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.831998348236084 current loss tensor(-2364.6724, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.8240630626678467 current loss tensor(-2364.9639, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.83652400970459 current loss tensor(-2365.2515, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.8678088188171387 current loss tensor(-2365.5356, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  2.890514373779297 current loss tensor(-2365.8159, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.8894801139831543 current loss tensor(-2366.0928, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  2.82552433013916 current loss tensor(-2366.3657, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.0528323650360107 current loss tensor(-2366.6353, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  2.9420406818389893 current loss tensor(-2366.9009, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.889258623123169 current loss tensor(-2367.1636, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.8338098526000977 current loss tensor(-2367.4224, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.8194942474365234 current loss tensor(-2367.6777, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.841223955154419 current loss tensor(-2367.9297, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.8833465576171875 current loss tensor(-2368.1777, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  2.855177879333496 current loss tensor(-2368.4224, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.8220038414001465 current loss tensor(-2368.6636, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  2.8878252506256104 current loss tensor(-2368.9019, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  2.9590280055999756 current loss tensor(-2369.1367, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  2.7981693744659424 current loss tensor(-380.2121, device='cuda:2', grad_fn=<SumBackward0>)
dealing G2.txt
device 2 start to train
[n] 200 [C] 1186 weight 800
con_list_range [401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600]
Epoch 0 Epoch time:  3.210740804672241 current loss tensor(-2368.8525, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.7438621520996094 current loss tensor(-2369.2859, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.8266265392303467 current loss tensor(-2369.7166, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.809727668762207 current loss tensor(-2370.1445, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.828129291534424 current loss tensor(-2370.5696, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  2.819676637649536 current loss tensor(-2370.9912, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.9707601070404053 current loss tensor(-2371.4102, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.781965494155884 current loss tensor(-2371.8257, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  2.842247486114502 current loss tensor(-2372.2378, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  2.819370746612549 current loss tensor(-2372.6470, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.8637213706970215 current loss tensor(-2373.0522, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.8123819828033447 current loss tensor(-2373.4546, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.805121898651123 current loss tensor(-2373.8530, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.8445160388946533 current loss tensor(-2374.2480, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.91874623298645 current loss tensor(-2374.6394, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.78525710105896 current loss tensor(-2375.0269, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.830479383468628 current loss tensor(-2375.4111, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.9329934120178223 current loss tensor(-2375.7920, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.7975144386291504 current loss tensor(-2376.1689, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.8839235305786133 current loss tensor(-2376.5422, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.809666156768799 current loss tensor(-2376.9116, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  2.926054000854492 current loss tensor(-2377.2773, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  2.795747995376587 current loss tensor(-2377.6394, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.8557543754577637 current loss tensor(-2377.9976, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.8778297901153564 current loss tensor(-2378.3521, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.835334300994873 current loss tensor(-2378.7026, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.834193706512451 current loss tensor(-2379.0493, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.8312337398529053 current loss tensor(-2379.3921, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.8934075832366943 current loss tensor(-2379.7310, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.8343660831451416 current loss tensor(-2380.0662, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.810713768005371 current loss tensor(-2380.3975, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.838459014892578 current loss tensor(-2380.7246, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.8292322158813477 current loss tensor(-2381.0486, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.851461172103882 current loss tensor(-2381.3687, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.9762039184570312 current loss tensor(-2381.6851, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.7858846187591553 current loss tensor(-2381.9978, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.829230308532715 current loss tensor(-2382.3069, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.8913896083831787 current loss tensor(-2382.6123, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.8269474506378174 current loss tensor(-2382.9141, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.847937822341919 current loss tensor(-2383.2119, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.8298754692077637 current loss tensor(-2383.5066, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.854947805404663 current loss tensor(-2383.7974, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.8284902572631836 current loss tensor(-2384.0847, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.836353302001953 current loss tensor(-2384.3682, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.8286867141723633 current loss tensor(-2384.6484, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.9091413021087646 current loss tensor(-2384.9248, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.008632183074951 current loss tensor(-2385.1980, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.7948946952819824 current loss tensor(-2385.4673, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.250365972518921 current loss tensor(-2385.7334, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.2598676681518555 current loss tensor(-2385.9963, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.2160592079162598 current loss tensor(-2386.2559, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.79152774810791 current loss tensor(-2386.5120, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.8289873600006104 current loss tensor(-2386.7644, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.8245596885681152 current loss tensor(-2387.0137, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.8472092151641846 current loss tensor(-2387.2598, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.8839316368103027 current loss tensor(-2387.5022, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  2.843465566635132 current loss tensor(-2387.7412, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.9652302265167236 current loss tensor(-2387.9773, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  2.791592597961426 current loss tensor(-2388.2100, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  2.8359262943267822 current loss tensor(-2388.4399, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  2.842163562774658 current loss tensor(-2388.6665, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.842442035675049 current loss tensor(-2388.8901, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  dealing G2.txt
device 3 start to train
[n] 200 [C] 1141 weight 800
con_list_range [601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800]
Epoch 0 Epoch time:  3.1121604442596436 current loss tensor(-2355.2712, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.8549866676330566 current loss tensor(-2355.6589, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.7231533527374268 current loss tensor(-2356.0435, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.798815965652466 current loss tensor(-2356.4253, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.7844316959381104 current loss tensor(-2356.8040, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  2.815955877304077 current loss tensor(-2357.1792, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.8054652214050293 current loss tensor(-2357.5518, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.7729883193969727 current loss tensor(-2357.9204, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  2.8478269577026367 current loss tensor(-2358.2859, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  2.934138774871826 current loss tensor(-2358.6482, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.744184970855713 current loss tensor(-2359.0073, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.861797332763672 current loss tensor(-2359.3625, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.7710838317871094 current loss tensor(-2359.7144, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.800232410430908 current loss tensor(-2360.0630, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.799290895462036 current loss tensor(-2360.4077, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.7979962825775146 current loss tensor(-2360.7493, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.946699380874634 current loss tensor(-2361.0874, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.7516982555389404 current loss tensor(-2361.4219, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.802492141723633 current loss tensor(-2361.7529, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.820385456085205 current loss tensor(-2362.0801, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.8257241249084473 current loss tensor(-2362.4038, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  2.8337714672088623 current loss tensor(-2362.7234, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  2.8135876655578613 current loss tensor(-2363.0396, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.945101499557495 current loss tensor(-2363.3521, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.763568639755249 current loss tensor(-2363.6611, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.817519187927246 current loss tensor(-2363.9663, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.8474068641662598 current loss tensor(-2364.2678, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.830625295639038 current loss tensor(-2364.5657, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.847439765930176 current loss tensor(-2364.8599, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.8133692741394043 current loss tensor(-2365.1504, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.8292486667633057 current loss tensor(-2365.4370, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.8212311267852783 current loss tensor(-2365.7202, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.8225226402282715 current loss tensor(-2366., device='cuda:3', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.8071343898773193 current loss tensor(-2366.2759, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.8498616218566895 current loss tensor(-2366.5488, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.7797510623931885 current loss tensor(-2366.8179, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.9605166912078857 current loss tensor(-2367.0835, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.838172435760498 current loss tensor(-2367.3455, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.8354272842407227 current loss tensor(-2367.6040, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.822037696838379 current loss tensor(-2367.8594, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.8230466842651367 current loss tensor(-2368.1108, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.7954158782958984 current loss tensor(-2368.3589, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.8297641277313232 current loss tensor(-2368.6033, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.8283987045288086 current loss tensor(-2368.8447, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.8191769123077393 current loss tensor(-2369.0825, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.8496341705322266 current loss tensor(-2369.3171, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  2.834841251373291 current loss tensor(-2369.5483, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.807847023010254 current loss tensor(-2369.7759, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  2.9546337127685547 current loss tensor(-2370.0007, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  2.8498005867004395 current loss tensor(-2370.2219, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  2.8501219749450684 current loss tensor(-2370.4399, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.8154494762420654 current loss tensor(-2370.6543, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.826251268386841 current loss tensor(-2370.8660, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.82063627243042 current loss tensor(-2371.0742, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.8437089920043945 current loss tensor(-2371.2793, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.852729082107544 current loss tensor(-2371.4810, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  2.8447039127349854 current loss tensor(-2371.6797, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.8277831077575684 current loss tensor(-2371.8750, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  2.8118643760681152 current loss tensor(-2372.0674, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  2.9576220512390137 current loss tensor(-2372.2568, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  2.803948163986206 current loss tensor(-2372.4431, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.837181568145752 current loss tensor(-2372.6267, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  2.8381056785583496 current loss average_loss tensor(-2380.1445, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.8525, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35 Epoch time:  2.832155466079712 current loss tensor(-2409.2334, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.4331, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.1445, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36 Epoch time:  2.9571926593780518 current loss tensor(-2409.4944, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.7175, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.4331, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37 Epoch time:  2.8229317665100098 current loss tensor(-2409.7522, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.9985, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.7175, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38 Epoch time:  2.829571008682251 current loss tensor(-2410.0063, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.2761, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.9985, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39 Epoch time:  2.821915626525879 current loss tensor(-2410.2568, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.5498, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.2761, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40 Epoch time:  2.902461528778076 current loss tensor(-2410.5039, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.8203, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.5498, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41 Epoch time:  2.8261685371398926 current loss tensor(-2410.7473, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.0869, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.8203, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42 Epoch time:  2.823246717453003 current loss tensor(-2410.9873, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.3501, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.0869, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43 Epoch time:  2.8341524600982666 current loss tensor(-2411.2239, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.6099, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.3501, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44 Epoch time:  2.866814374923706 current loss tensor(-2411.4570, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.8660, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.6099, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45 Epoch time:  2.943621873855591 current loss tensor(-2411.6865, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.1187, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.8660, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46 Epoch time:  2.915559768676758 current loss tensor(-2411.9131, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.3679, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.1187, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47 Epoch time:  2.8307769298553467 current loss tensor(-2412.1357, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.6138, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.3679, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48 Epoch time:  3.208012104034424 current loss tensor(-2412.3555, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.8564, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.6138, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49 Epoch time:  3.2527413368225098 current loss tensor(-2412.5718, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.0952, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.8564, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 50 Epoch time:  3.2320213317871094 current loss tensor(-2412.7847, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.3311, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.0952, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 51 Epoch time:  2.828115224838257 current loss tensor(-2412.9946, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.5635, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.3311, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 52 Epoch time:  2.8246285915374756 current loss tensor(-2413.2012, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.7925, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.5635, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 53 Epoch time:  2.8392210006713867 current loss tensor(-2413.4043, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.0183, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.7925, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 54 Epoch time:  2.9425408840179443 current loss tensor(-2413.6045, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.2405, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.0183, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 55 Epoch time:  2.8399879932403564 current loss tensor(-2413.8015, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.4597, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.2405, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 56 Epoch time:  2.8325436115264893 current loss tensor(-2413.9954, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.6753, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.4597, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 57 Epoch time:  2.932264804840088 current loss tensor(-2414.1858, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.8882, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.6753, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 58 Epoch time:  2.835040330886841 current loss tensor(-2414.3735, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.0979, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.8882, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 59 Epoch time:  2.9190871715545654 current loss tensor(-2414.5579, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.3044, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.0979, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 60 Epoch time:  2.8419878482818604 current loss tensor(-2414.7393, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.5081, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.3044, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 61 Epoch time:  2.8398818969726562 current loss tensor(-2414.9180, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.7085, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.5081, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 62 Epoch time:  2.9729018211364746 current loss tensor(-2415.0935, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.9058, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.7085, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 63 Epoch time:  2.8308448791503906 current loss tensor(-2415.2659, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.1003, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.9058, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 64 Epoch time:  2.8325021266937256 current loss tensor(-2415.4353, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.2915, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.1003, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 65 Epoch time:  2.8271684646606445 current loss tensor(-2415.6021, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.4800, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.2915, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 66 Epoch time:  2.856058359146118 current loss tensor(-2415.7659, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.6655, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.4800, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 67 Epoch time:  2.82757830619812 current loss tensor(-2415.9268, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.8484, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.6655, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 68 Epoch time:  2.923325777053833 current loss tensor(-2416.0850, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.0283, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.8484, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 69 Epoch time:  2.9317739009857178 current loss tensor(-2416.2407, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.2056, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.0283, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 70 Epoch time:  2.89711856842041 current loss tensor(-2416.3938, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.3799, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.2056, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 71 Epoch time:  2.847311019897461 current loss tensor(-2416.5439, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.5518, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.3799, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 72 Epoch time:  2.831301689147949 current loss tensor(-2416.6917, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.7207, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.5518, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 73 Epoch time:  2.831517219543457 current loss tensor(-2416.8367, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.8872, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.7207, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 74 Epoch time:  2.8388965129852295 current loss tensor(-2416.9790, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.0505, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.8872, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 75 Epoch time:  2.827087640762329 current loss tensor(-2417.1189, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.2114, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.0505, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 76 Epoch time:  2.833852529525757 current loss tensor(-2417.2563, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.3699, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.2114, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 77 Epoch time:  2.964376926422119 current loss tensor(-2417.3914, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.5259, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.3699, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 78 Epoch time:  2.8294196128845215 current loss tensor(-2417.5237, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.6787, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.5259, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 79 Epoch time:  2.9308276176452637 current loss tensor(-2417.6536, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.8296, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.6787, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 80 Epoch time:  2.836773633956909 current loss tensor(-2417.7812, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.9780, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.8296, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 81 Epoch time:  2.8318638801574707 current loss tensor(-2417.9062, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.1240, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.9780, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 82 Epoch time:  2.8363053798675537 current loss tensor(-2418.0293, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.2671, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.1240, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 83 Epoch time:  2.83255672454834 current loss tensor(-2418.1499, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.4082, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.2671, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 84 Epoch time:  2.948275089263916 current loss tensor(-2418.2683, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.5469, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.4082, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 85 Epoch time:  2.8308961391448975 current loss tensor(-2418.3843, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.6831, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.5469, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 86 Epoch time:  2.9318511486053467 current loss tensor(-2418.4980, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.8171, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.6831, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 87 Epoch time:  2.9070074558258057 current loss tensor(-2418.6096, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.9487, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.8171, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 88 Epoch time:  2.8761346340179443 current loss tensor(-2418.7188, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.0781, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.9487, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 89 Epoch time:  2.8454713821411133 current loss tensor(-2418.8262, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.2056, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.0781, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 90 Epoch time:  2.8279316425323486 current loss tensor(-2418.9312, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.3306, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.2056, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 91 Epoch time:  2.83286714553833 current loss tensor(-2419.0344, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.4534, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.3306, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 92 Epoch time:  2.832435369491577 current loss tensor(-2419.1355, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.5742, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.4534, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 93 Epoch time:  2.8432109355926514 current loss tensor(-2419.2344, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.6929, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.5742, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 94 Epoch time:  2.8321712017059326 current loss tensor(-2419.3315, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.8093, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.6929, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 95 Epoch time:  2.915553331375122 current loss tensor(-2419.4268, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.9236, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.8093, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 96 Epoch time:  2.8298628330230713 current loss tensor(-2419.5195, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.0359, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.9236, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 97 Epoch time:  2.9418342113494873 current loss tensor(-2419.6108, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.1462, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.0359, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 98 Epoch time:  2.834942102432251 current loss tensor(-2419.7000, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.2546, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.1462, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 99 Epoch time:  2.840723991394043 current loss tensor(-2419.7874, device='cuda:0', grad_fn=<SumBackward0>)
best_out [0.46028665 0.54971975 0.5015445  0.4243092  0.4705736  0.45307606
 0.5506014  0.4846117  0.48968422 0.5164714  0.48378944 0.4545535
 0.46062583 0.5202425  0.57368743 0.5330749  0.48401698 0.47992462
 0.51733637 0.5036832  0.464109   0.5145342  0.43128145 0.4422774
 0.5139333  0.44915494 0.5063153  0.5308349  0.4677163  0.5157883
 0.5617773  0.48779166 0.50166833 0.4933311  0.4719598  0.3967561
 0.43370304 0.4634334  0.47303155 0.46703345 0.49025133 0.48707628
 0.4774728  0.5251375  0.46512285 0.47127032 0.544255   0.5040174
 0.45482877 0.46520287 0.52537245 0.49745822 0.50254494 0.49635735
 0.46223927 0.42206302 0.4864726  0.37536073 0.5561403  0.47710854
 0.5004783  0.53808784 0.47884172 0.49701682 0.43412808 0.47832122
 0.38302684 0.46810436 0.4960088  0.47754952 0.48425412 0.53742707
 0.49220556 0.50764245 0.4467516  0.5390663  0.50612533 0.51301026
 0.49379295 0.51506627 0.48214325 0.520726   0.52432287 0.4989364
 0.5329992  0.51924485 0.51570547 0.48906824 0.47663727 0.54859567
 0.50257826 0.41643763 0.44332528 0.45947763 0.52232414 0.46173817
 0.5332125  0.466261   0.53824115 0.49050072 0.4967047  0.3957125
 0.51054275 0.5027319  0.504944   0.5209175  0.4523454  0.43529028
 0.5399812  0.4810882  0.4734853  0.44517624 0.47586408 0.47552246
 0.4375403  0.5201049  0.48083705 0.4993152  0.47742513 0.46732837
 0.46081498 0.4545059  0.4709065  0.44290236 0.42642504 0.47395846
 0.49971452 0.41459456 0.47459581 0.5427864  0.41944155 0.41295913
 0.49619117 0.514346   0.44642478 0.52764463 0.5638012  0.56602126
 0.41166136 0.48233166 0.5038566  0.440555   0.5229692  0.43116745
 0.52457887 0.47821182 0.42150036 0.4548354  0.46391514 0.4641405
 0.5536126  0.43232286 0.4636623  0.5005605  0.53574795 0.4391652
 0.51504725 0.5305429  0.5412226  0.50958675 0.4879646  0.526064
 0.54838806 0.47905463 0.5193985  0.5236837  0.4907216  0.47498965
 0.40631363 0.49822718 0.56516445 0.4095906  0.49481508 0.48795244
 0.5231647  0.48901898 0.52072114 0.41864184 0.503492   0.52978295
 0.4536894  0.48702747 0.49113503 0.4880902  0.44762814 0.47500756
 0.39800015 0.46687794 0.46090302 0.52339417 0.566062   0.4945538
 0.44455284 0.53562844 0.4497456  0.5436468  0.5347835  0.4919726
 0.50741875 0.46061257 0.4655343  0.48734275 0.45150495 0.4152775
 0.44989774 0.43654588 0.45755717 0.45473    0.47531515 0.5262391
 0.48675856 0.4717728  0.5430589  0.4671919  0.49856597 0.500592
 0.41449443 0.40763673 0.50269175 0.4803026  0.45965964 0.5373614
 0.46430686 0.37047496 0.47621948 0.41885865 0.42446086 0.46594805
 0.47155696 0.4616597  0.52441657 0.49663422 0.46712488 0.45239186
 0.42956617 0.4071619  0.48055452 0.47683775 0.5083159  0.45421174
 0.43224722 0.4685502  0.4375473  0.5011928  0.45992097 0.41785568
 0.47231218 0.45766127 0.5019926  0.43431157 0.47996414 0.54664826
 0.45532182 0.46997026 0.44957677 0.43738487 0.43528026 0.4134571
 0.52255493 0.49199855 0.48740694 0.44260606 0.54457396 0.5140039
 0.43290463 0.4918748  0.44496098 0.42723417 0.47304404 0.43793327
 0.44439897 0.491636   0.42532036 0.4148672  0.45065758 0.54163194
 0.5284758  0.52944756 0.42892456 0.4600453  0.46990222 0.44352162
 0.47136328 0.50143456 0.49243584 0.4792627  0.48022777 0.41955325
 0.4777844  0.49156085 0.4669112  0.41626796 0.4203627  0.3749541
 0.4906561  0.4813966  0.52010566 0.45326716 0.4783177  0.46073148
 0.40380958 0.42022792 0.4922487  0.54105175 0.45217058 0.51356953
 0.43363237 0.45964828 0.54428333 0.47116587 0.4311909  0.42684478
 0.50702125 0.40987682 0.46217814 0.5502998  0.4803545  0.56316483
 0.51289725 0.44394392 0.45110714 0.51824236 0.45600897 0.45890003
 0.45277718 0.4745522  0.49582738 0.42410454 0.45609525 0.46769768
 0.4980702  0.3965986  0.4648     0.51979715 0.40699196 0.5180222
 0.5069832  0.51073974 0.38625708 0.52727365 0.4993338  0.4589874
 0.46022844 0.46370324 0.551104   0.50262797 0.49282536 0.4401867
 0.48166868 0.43268716 0.50182176 0.4593533  0.43464997 0.41761544
 0.5072453  0.4644646  0.42730486 0.52991974 0.46689796 0.46776727
 0.4605228  0.47722596 0.48626167 0.43684104 0.49403864 0.42357105
 0.46929228 0.4607707  0.47369456 0.465131   0.48492193 0.44943798
 0.49423876 0.49759194 0.49929675 0.4649828  0.50761473 0.4673265
 0.5940448  0.5221522  0.4105216  0.43923554 0.5040273  0.534717
 0.46766406 0.4829057  0.44798133 0.39569062 0.43350917 0.5509515
 0.55136794 0.4742351  0.45938244 0.41649407 0.5419843  0.43101338
 0.48846945 0.4676018  0.54846    0.46717554 0.48332116 0.6395347
 0.4390313  0.3869329  0.34446475 0.40249333 0.5278839  0.5043788
 0.4549325  0.5341419  0.5112869  0.4202125  0.47072607 0.4871293
 0.53723145 0.41652626 0.4562449  0.44424844 0.48939386 0.48276192
 0.4442551  0.4806848  0.43662778 0.47413293 0.5030138  0.4507731
 0.48418707 0.44439387 0.45687246 0.4632414  0.5032693  0.5073517
 0.46381038 0.4895722  0.4618125  0.37242845 0.45242918 0.45344713
 0.44379228 0.47069022 0.4706741  0.446674   0.45548683 0.50859874
 0.47256345 0.48015755 0.52240676 0.47329977 0.39575946 0.44606227
 0.50871116 0.41944224 0.49554437 0.43253857 0.5091357  0.5013939
 0.40658838 0.4133734  0.54357386 0.5163573  0.428722   0.4439505
 0.5250496  0.5393799  0.46026054 0.4769582  0.42944998 0.47591665
 0.48095745 0.43525568 0.503843   0.5436702  0.44344786 0.40919793
 0.439719   0.5536405  0.48600355 0.47587475 0.55214685 0.49961728
 0.3883968  0.48980144 0.47494653 0.457513   0.49189118 0.5028239
 0.4430328  0.48076835 0.4420106  0.469219   0.4667825  0.4467746
 0.45853484 0.46564925 0.43691403 0.4575207  0.48939094 0.4728513
 0.49012902 0.4565131  0.40606344 0.4378539  0.4663904  0.51594186
 0.49642086 0.493711   0.4599306  0.47223443 0.46588728 0.46115962
 0.48774743 0.42444512 0.48881972 0.45677984 0.41376603 0.62395054
 0.47755453 0.47858372 0.4989217  0.44555253 0.4332554  0.45368925
 0.47156885 0.4538023  0.44804737 0.480168   0.47734874 0.4420283
 0.4887637  0.5116124  0.4556332  0.42363432 0.50050926 0.5311281
 0.42336285 0.48521766 0.5254677  0.47234237 0.44603467 0.5176896
 0.50570184 0.47299606 0.4280096  0.45282394 0.5210105  0.4883007
 0.47631    0.47505325 0.44984177 0.41361472 0.5350511  0.47486565
 0.4737651  0.37267947 0.4758198  0.4180326  0.48305818 0.50783515
 0.49386638 0.4854972  0.43563223 0.48923    0.46024624 0.4040677
 0.5699231  0.53241974 0.4771406  0.43818277 0.41180015 0.48889568
 0.51063615 0.40545976 0.51075494 0.47030878 0.45490095 0.4039349
 0.4617795  0.4709377  0.5033277  0.43257782 0.4417189  0.49631307
 0.5771062  0.4521712  0.5373136  0.4919999  0.45622376 0.43392685
 0.42801666 0.4969014  0.5024559  0.49300185 0.41821465 0.5125335
 0.4649658  0.47826743 0.51316684 0.44769844 0.46453008 0.47591996
 0.49224412 0.462364   0.4991368  0.4694411  0.4864643  0.4495756
 0.51267457 0.47010356 0.4538007  0.56507313 0.45328137 0.50872
 0.5116266  0.4730484  0.52959377 0.5344274  0.42212144 0.3346628
 0.5311034  0.49930894 0.4744809  0.5246898  0.4024757  0.39379042
 0.53869814 0.49496773 0.43533126 0.46247905 0.5008989  0.4656215
 0.5075986  0.5120332  0.5500114  0.46975097 0.45294312 0.42808232
 0.44534484 0.5469089  0.44753325 0.4248793  0.50229573 0.44469923
 0.4662452  0.4800968  0.510658   0.4983006  0.59033555 0.50678647
 0.45437974 0.43925384 0.46265066 0.471485   0.4288029  0.47480312
 0.47518337 0.4755865  0.41419983 0.37027264 0.5314555  0.50486577
 0.49850935 0.48851746 0.49873903 0.54663754 0.484738   0.5727669
 0.42681715 0.5008243  0.49887684 0.48526606 0.5453866  0.49505487
 0.43070152 0.47554585 0.47915494 0.51121956 0.4943938  0.45284462
 0.5198115  0.4707859  0.48073608 0.46761    0.5804695  0.48913878
 0.4808451  0.47951397 0.46478933 0.46172485 0.5086952  0.44943798
 0.5052567  0.4648498  0.4965974  0.45305237 0.44671965 0.4871355
 0.5046928  0.50123084 0.44899943 0.44374317 0.4259993  0.47762325
 0.5437076  0.5196883  0.4481392  0.5428713  0.48505124 0.5358657
 0.50536597 0.47706583 0.48108456 0.43240747 0.51775116 0.43107298
 0.436881   0.5780752  0.49224523 0.5034601  0.49300903 0.4775668
 0.48972368 0.41930202 0.49717784 0.43736938 0.4516082  0.4483301
 0.46512595 0.41578653 0.482115   0.5064223  0.48035353 0.39929476
 0.5016556  0.53711575 0.4152675  0.521761   0.53296226 0.50645566
 0.47288424 0.5219239  0.5521794  0.4955415  0.52845204 0.41663983
 0.50162685 0.49113962 0.46761572 0.47203884 0.4891506  0.4998677
 0.533678   0.49779037 0.5637056  0.44560108 0.48413125 0.45721054
 0.5026735  0.53281087 0.49347302 0.49908254 0.49095923 0.5611066
 0.44266874 0.43220964 0.53248703 0.5343355  0.5237813  0.44429114
 0.47396114 0.47197235 0.46264777 0.37513137 0.49530113 0.4638936
 0.47771126 0.4481471  0.47001186 0.4623665  0.5643991  0.48759627
 0.4942489  0.4834582  0.50865513 0.4686503  0.49652717 0.47674468
 0.41603044 0.4679409  0.40964597 0.5288347  0.48043013 0.5278346
 0.507871   0.49933782 0.44164398 0.47057483 0.53115743 0.46060792
 0.4972611  0.5092502 ]
info_input_total 800 weights 800 total_C 19176
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
-9634
res {1: 1, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0, 10: 1, 11: 1, 12: 1, 13: 0, 14: 0, 15: 1, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 0, 22: 0, 23: 1, 24: 1, 25: 0, 26: 0, 27: 1, 28: 1, 29: 0, 30: 1, 31: 1, 32: 0, 33: 0, 34: 1, 35: 0, 36: 1, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 1, 43: 1, 44: 1, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0, 50: 0, 51: 1, 52: 1, 53: 0, 54: 0, 55: 0, 56: 0, 57: 1, 58: 1, 59: 0, 60: 0, 61: 0, 62: 1, 63: 0, 64: 0, 65: 1, 66: 0, 67: 1, 68: 1, 69: 1, 70: 0, 71: 1, 72: 0, 73: 1, 74: 1, 75: 0, 76: 0, 77: 0, 78: 1, 79: 1, 80: 0, 81: 1, 82: 1, 83: 0, 84: 1, 85: 1, 86: 0, 87: 1, 88: 1, 89: 1, 90: 0, 91: 1, 92: 0, 93: 0, 94: 1, 95: 1, 96: 0, 97: 1, 98: 0, 99: 0, 100: 1, 101: 0, 102: 0, 103: 1, 104: 1, 105: 1, 106: 0, 107: 0, 108: 1, 109: 1, 110: 1, 111: 0, 112: 0, 113: 1, 114: 1, 115: 1, 116: 0, 117: 0, 118: 1, 119: 1, 120: 0, 121: 0, 122: 0, 123: 0, 124: 0, 125: 0, 126: 0, 127: 0, 128: 0, 129: 0, 130: 1, 131: 0, 132: 0, 133: 1, 134: 0, 135: 0, 136: 0, 137: 1, 138: 1, 139: 1, 140: 0, 141: 1, 142: 1, 143: 0, 144: 1, 145: 1, 146: 0, 147: 0, 148: 0, 149: 1, 150: 1, 151: 0, 152: 0, 153: 0, 154: 1, 155: 1, 156: 1, 157: 0, 158: 1, 159: 0, 160: 0, 161: 0, 162: 0, 163: 1, 164: 0, 165: 0, 166: 1, 167: 1, 168: 1, 169: 0, 170: 0, 171: 1, 172: 0, 173: 0, 174: 1, 175: 1, 176: 1, 177: 0, 178: 1, 179: 1, 180: 0, 181: 0, 182: 1, 183: 1, 184: 1, 185: 1, 186: 1, 187: 1, 188: 0, 189: 0, 190: 1, 191: 0, 192: 1, 193: 1, 194: 0, 195: 0, 196: 1, 197: 1, 198: 0, 199: 1, 200: 0, 201: 0, 202: 1, 203: 0, 204: 1, 205: 1, 206: 0, 207: 0, 208: 1, 209: 0, 210: 1, 211: 1, 212: 1, 213: 0, 214: 1, 215: 0, 216: 1, 217: 1, 218: 0, 219: 0, 220: 0, 221: 0, 222: 1, 223: 0, 224: 1, 225: 1, 226: 1, 227: 1, 228: 0, 229: 0, 230: 1, 231: 0, 232: 0, 233: 1, 234: 0, 235: 1, 236: 0, 237: 0, 238: 0, 239: 0, 240: 0, 241: 0, 242: 1, 243: 0, 244: 1, 245: 0, 246: 0, 247: 1, 248: 1, 249: 1, 250: 1, 251: 1, 252: 1, 253: 1, 254: 1, 255: 1, 256: 0, 257: 1, 258: 0, 259: 1, 260: 0, 261: 0, 262: 1, 263: 0, 264: 1, 265: 1, 266: 1, 267: 0, 268: 1, 269: 0, 270: 1, 271: 1, 272: 1, 273: 0, 274: 1, 275: 1, 276: 0, 277: 0, 278: 1, 279: 0, 280: 1, 281: 1, 282: 0, 283: 1, 284: 0, 285: 0, 286: 1, 287: 1, 288: 1, 289: 1, 290: 0, 291: 0, 292: 0, 293: 0, 294: 0, 295: 1, 296: 1, 297: 0, 298: 0, 299: 0, 300: 0, 301: 0, 302: 1, 303: 0, 304: 1, 305: 0, 306: 0, 307: 0, 308: 0, 309: 1, 310: 0, 311: 0, 312: 0, 313: 1, 314: 1, 315: 0, 316: 0, 317: 1, 318: 1, 319: 0, 320: 0, 321: 0, 322: 0, 323: 1, 324: 1, 325: 0, 326: 1, 327: 0, 328: 1, 329: 0, 330: 0, 331: 0, 332: 1, 333: 1, 334: 0, 335: 0, 336: 1, 337: 1, 338: 1, 339: 1, 340: 1, 341: 0, 342: 1, 343: 1, 344: 0, 345: 0, 346: 1, 347: 1, 348: 1, 349: 0, 350: 1, 351: 1, 352: 0, 353: 0, 354: 0, 355: 0, 356: 0, 357: 1, 358: 0, 359: 1, 360: 0, 361: 0, 362: 1, 363: 1, 364: 1, 365: 1, 366: 1, 367: 1, 368: 0, 369: 1, 370: 0, 371: 1, 372: 0, 373: 1, 374: 1, 375: 1, 376: 1, 377: 0, 378: 0, 379: 0, 380: 0, 381: 1, 382: 0, 383: 0, 384: 0, 385: 0, 386: 1, 387: 0, 388: 1, 389: 0, 390: 1, 391: 0, 392: 1, 393: 0, 394: 0, 395: 0, 396: 0, 397: 1, 398: 0, 399: 1, 400: 0, 401: 0, 402: 1, 403: 1, 404: 1, 405: 0, 406: 1, 407: 0, 408: 1, 409: 1, 410: 1, 411: 1, 412: 1, 413: 0, 414: 1, 415: 1, 416: 1, 417: 1, 418: 0, 419: 1, 420: 1, 421: 1, 422: 0, 423: 0, 424: 1, 425: 1, 426: 0, 427: 1, 428: 0, 429: 0, 430: 1, 431: 1, 432: 0, 433: 0, 434: 1, 435: 0, 436: 1, 437: 0, 438: 0, 439: 1, 440: 0, 441: 0, 442: 0, 443: 1, 444: 1, 445: 0, 446: 1, 447: 1, 448: 1, 449: 0, 450: 1, 451: 0, 452: 1, 453: 0, 454: 0, 455: 1, 456: 1, 457: 1, 458: 1, 459: 0, 460: 0, 461: 0, 462: 0, 463: 1, 464: 1, 465: 0, 466: 0, 467: 0, 468: 0, 469: 0, 470: 1, 471: 0, 472: 0, 473: 0, 474: 1, 475: 0, 476: 1, 477: 1, 478: 0, 479: 0, 480: 1, 481: 1, 482: 0, 483: 0, 484: 0, 485: 0, 486: 0, 487: 1, 488: 1, 489: 0, 490: 1, 491: 1, 492: 1, 493: 1, 494: 0, 495: 0, 496: 0, 497: 1, 498: 0, 499: 0, 500: 0, 501: 0, 502: 0, 503: 1, 504: 1, 505: 0, 506: 1, 507: 0, 508: 1, 509: 1, 510: 0, 511: 1, 512: 0, 513: 1, 514: 0, 515: 0, 516: 1, 517: 1, 518: 0, 519: 0, 520: 0, 521: 0, 522: 0, 523: 1, 524: 1, 525: 1, 526: 0, 527: 0, 528: 0, 529: 0, 530: 1, 531: 0, 532: 0, 533: 0, 534: 1, 535: 0, 536: 0, 537: 1, 538: 0, 539: 0, 540: 0, 541: 0, 542: 0, 543: 0, 544: 0, 545: 0, 546: 1, 547: 1, 548: 1, 549: 0, 550: 1, 551: 0, 552: 1, 553: 1, 554: 0, 555: 1, 556: 0, 557: 1, 558: 1, 559: 0, 560: 0, 561: 1, 562: 0, 563: 1, 564: 1, 565: 0, 566: 0, 567: 0, 568: 0, 569: 0, 570: 1, 571: 0, 572: 0, 573: 1, 574: 0, 575: 0, 576: 0, 577: 0, 578: 1, 579: 0, 580: 0, 581: 0, 582: 0, 583: 0, 584: 1, 585: 0, 586: 0, 587: 1, 588: 1, 589: 0, 590: 0, 591: 1, 592: 0, 593: 0, 594: 1, 595: 1, 596: 1, 597: 0, 598: 1, 599: 1, 600: 1, 601: 0, 602: 0, 603: 1, 604: 0, 605: 1, 606: 1, 607: 1, 608: 1, 609: 0, 610: 0, 611: 1, 612: 1, 613: 0, 614: 1, 615: 0, 616: 1, 617: 0, 618: 0, 619: 1, 620: 1, 621: 1, 622: 1, 623: 0, 624: 1, 625: 0, 626: 0, 627: 0, 628: 1, 629: 0, 630: 1, 631: 0, 632: 0, 633: 0, 634: 0, 635: 1, 636: 1, 637: 1, 638: 0, 639: 1, 640: 0, 641: 1, 642: 0, 643: 0, 644: 1, 645: 1, 646: 1, 647: 1, 648: 1, 649: 1, 650: 0, 651: 1, 652: 0, 653: 0, 654: 0, 655: 1, 656: 1, 657: 0, 658: 1, 659: 0, 660: 1, 661: 0, 662: 0, 663: 1, 664: 1, 665: 0, 666: 1, 667: 1, 668: 1, 669: 1, 670: 1, 671: 0, 672: 1, 673: 0, 674: 1, 675: 1, 676: 1, 677: 1, 678: 0, 679: 0, 680: 1, 681: 0, 682: 0, 683: 0, 684: 1, 685: 0, 686: 0, 687: 0, 688: 1, 689: 0, 690: 1, 691: 1, 692: 0, 693: 1, 694: 0, 695: 1, 696: 0, 697: 1, 698: 0, 699: 1, 700: 0, 701: 0, 702: 1, 703: 1, 704: 1, 705: 0, 706: 1, 707: 0, 708: 0, 709: 1, 710: 1, 711: 1, 712: 0, 713: 1, 714: 1, 715: 1, 716: 1, 717: 1, 718: 1, 719: 0, 720: 0, 721: 0, 722: 0, 723: 1, 724: 0, 725: 0, 726: 0, 727: 1, 728: 0, 729: 1, 730: 1, 731: 1, 732: 1, 733: 0, 734: 1, 735: 0, 736: 1, 737: 1, 738: 0, 739: 1, 740: 1, 741: 1, 742: 1, 743: 1, 744: 0, 745: 1, 746: 0, 747: 1, 748: 0, 749: 0, 750: 0, 751: 1, 752: 0, 753: 1, 754: 0, 755: 1, 756: 0, 757: 0, 758: 1, 759: 0, 760: 0, 761: 1, 762: 1, 763: 0, 764: 1, 765: 1, 766: 0, 767: 1, 768: 0, 769: 1, 770: 0, 771: 0, 772: 0, 773: 0, 774: 0, 775: 1, 776: 0, 777: 1, 778: 1, 779: 0, 780: 1, 781: 0, 782: 0, 783: 1, 784: 0, 785: 0, 786: 0, 787: 0, 788: 0, 789: 1, 790: 1, 791: 1, 792: 0, 793: 1, 794: 0, 795: 0, 796: 1, 797: 0, 798: 1, 799: 1, 800: 1}
-9634.0
-7774.0
dealing G25.txt
device 0 start to train
[n] 500 [C] 1335 weight 2000
con_list_range tensor(-2372.8076, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.8371670246124268 current loss tensor(-2372.9854, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.8428640365600586 current loss tensor(-2373.1602, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.834080934524536 current loss tensor(-2373.3320, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.8302555084228516 current loss tensor(-2373.5012, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.8486618995666504 current loss tensor(-2373.6675, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.841282844543457 current loss tensor(-2373.8315, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.81565260887146 current loss tensor(-2373.9924, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.977280378341675 current loss tensor(-2374.1509, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.767275810241699 current loss tensor(-2374.3066, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.8428032398223877 current loss tensor(-2374.4597, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.8341355323791504 current loss tensor(-2374.6104, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.8169164657592773 current loss tensor(-2374.7588, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.835498094558716 current loss tensor(-2374.9038, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.818535566329956 current loss tensor(-2375.0471, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.8413383960723877 current loss tensor(-2375.1875, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.8494350910186768 current loss tensor(-2375.3257, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.9999263286590576 current loss tensor(-2375.4609, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.7673113346099854 current loss tensor(-2375.5945, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.8296058177948 current loss tensor(-2375.7256, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.8316917419433594 current loss tensor(-2375.8545, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.8342816829681396 current loss tensor(-2375.9807, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.8332674503326416 current loss tensor(-2376.1050, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.8783442974090576 current loss tensor(-2376.2271, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.8007419109344482 current loss tensor(-2376.3467, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.801116466522217 current loss tensor(-2376.4644, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.9291772842407227 current loss tensor(-2376.5796, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.7641818523406982 current loss tensor(-2376.6929, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.8167920112609863 current loss tensor(-2376.8042, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.82267165184021 current loss tensor(-2376.9136, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.828011989593506 current loss tensor(-2377.0205, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.8359735012054443 current loss tensor(-2377.1260, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.8295297622680664 current loss tensor(-2377.2295, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.8326218128204346 current loss tensor(-2377.3308, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.821331739425659 current loss tensor(-2377.4302, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.9626216888427734 current loss tensor(-2377.5278, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.7940163612365723 current loss tensor(-2377.6235, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.8307301998138428 current loss tensor(-2377.7175, device='cuda:3', grad_fn=<SumBackward0>)
dealing G25.txt
device 3 start to train
[n] 500 [C] 1270 weight 2000
con_list_range [1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000]
Epoch 0 Epoch time:  3.6567282676696777 current loss tensor(-2507.9355, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.0869197845458984 current loss tensor(-2508.0608, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.153134346008301 current loss tensor(-2508.1836, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.362011432647705 current loss tensor(-2508.3032, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.145427942276001 current loss tensor(-2508.4207, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.187958002090454 current loss tensor(-2508.5352, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.1965794563293457 current loss tensor(-2508.6470, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.1938669681549072 current loss 2.8492045402526855 current loss tensor(-2389.1104, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.8873536586761475 current loss tensor(-2389.3276, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.825706958770752 current loss tensor(-2389.5420, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.833390951156616 current loss tensor(-2389.7529, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.8266146183013916 current loss tensor(-2389.9609, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.85901141166687 current loss tensor(-2390.1660, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.958202838897705 current loss tensor(-2390.3682, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.7974226474761963 current loss tensor(-2390.5674, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.873589515686035 current loss tensor(-2390.7642, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.889676570892334 current loss tensor(-2390.9575, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.8442330360412598 current loss tensor(-2391.1487, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.866462230682373 current loss tensor(-2391.3369, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.7986974716186523 current loss tensor(-2391.5222, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.83125901222229 current loss tensor(-2391.7051, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.8294804096221924 current loss tensor(-2391.8848, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.9445674419403076 current loss tensor(-2392.0620, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.854238510131836 current loss tensor(-2392.2366, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.856036901473999 current loss tensor(-2392.4084, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.850440740585327 current loss tensor(-2392.5776, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.843702793121338 current loss tensor(-2392.7446, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.8246474266052246 current loss tensor(-2392.9092, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.8420233726501465 current loss tensor(-2393.0708, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.8219974040985107 current loss tensor(-2393.2302, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.895779848098755 current loss tensor(-2393.3872, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.954181432723999 current loss tensor(-2393.5417, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.7953708171844482 current loss tensor(-2393.6938, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.840390682220459 current loss tensor(-2393.8438, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.8809213638305664 current loss tensor(-2393.9912, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.8441264629364014 current loss tensor(-2394.1362, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.8236021995544434 current loss tensor(-2394.2788, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.830395221710205 current loss tensor(-2394.4194, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.8422598838806152 current loss tensor(-2394.5579, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.837989091873169 current loss tensor(-2394.6938, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.955756187438965 current loss tensor(-2394.8274, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.795581102371216 current loss tensor(-2394.9590, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.821078300476074 current loss tensor(-2395.0884, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.8848698139190674 current loss tensor(-2395.2158, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.8365864753723145 current loss tensor(-2395.3408, device='cuda:2', grad_fn=<SumBackward0>)
dealing G25.txt
device 2 start to train
[n] 500 [C] 1243 weight 2000
con_list_range [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500]
Epoch 0 Epoch time:  3.686856985092163 current loss tensor(-2498.8242, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.1176953315734863 current loss tensor(-2498.9587, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.176785469055176 current loss tensor(-2499.0906, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.2349603176116943 current loss tensor(-2499.2197, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.2536585330963135 current loss tensor(-2499.3464, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.1955201625823975 current loss tensor(-2499.4700, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.2160630226135254 current loss tensor(-2499.5908, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.1865456104278564 current loss tensor(-2369.3687, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.882091522216797 current loss tensor(-2369.5972, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  2.807440996170044 current loss tensor(-2369.8225, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.889322519302368 current loss tensor(-2370.0447, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.8314719200134277 current loss tensor(-2370.2637, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.829054355621338 current loss tensor(-2370.4797, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.8401334285736084 current loss tensor(-2370.6926, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.846691846847534 current loss tensor(-2370.9023, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.821010112762451 current loss tensor(-2371.1089, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.9935054779052734 current loss tensor(-2371.3130, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.824385404586792 current loss tensor(-2371.5137, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.892594337463379 current loss tensor(-2371.7117, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.8531882762908936 current loss tensor(-2371.9067, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.824899435043335 current loss tensor(-2372.0989, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.83455228805542 current loss tensor(-2372.2881, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.828744411468506 current loss tensor(-2372.4746, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.8232369422912598 current loss tensor(-2372.6582, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.835491895675659 current loss tensor(-2372.8389, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.8904218673706055 current loss tensor(-2373.0171, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.9561941623687744 current loss tensor(-2373.1924, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.8051979541778564 current loss tensor(-2373.3652, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.834716796875 current loss tensor(-2373.5352, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.835010051727295 current loss tensor(-2373.7026, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.8336181640625 current loss tensor(-2373.8674, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.832367181777954 current loss tensor(-2374.0293, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.8871870040893555 current loss tensor(-2374.1892, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.825721263885498 current loss tensor(-2374.3462, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.999617576599121 current loss tensor(-2374.5010, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.798455238342285 current loss tensor(-2374.6533, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.9255714416503906 current loss tensor(-2374.8027, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.797240734100342 current loss tensor(-2374.9502, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.8309831619262695 current loss tensor(-2375.0955, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.8307998180389404 current loss tensor(-2375.2380, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.8309357166290283 current loss tensor(-2375.3784, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.860504388809204 current loss tensor(-2375.5166, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.816349506378174 current loss tensor(-2375.6521, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.8917505741119385 current loss tensor(-2375.7856, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.931800603866577 current loss tensor(-2375.9167, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.838017225265503 current loss tensor(-2376.0459, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.8302807807922363 current loss tensor(-2376.1726, device='cuda:1', grad_fn=<SumBackward0>)
dealing G25.txt
device 1 start to train
[n] 500 [C] 1212 weight 2000
con_list_range [501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
Epoch 0 Epoch time:  3.4859561920166016 current loss tensor(-2449.8994, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.19321346282959 current loss tensor(-2450.0259, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.1082472801208496 current loss tensor(-2450.1504, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.211679697036743 current loss tensor(-2450.2720, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.220714569091797 current loss tensor(-2450.3911, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.2365024089813232 current loss tensor(-2450.5078, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.154280185699463 current loss tensor(-2450.6221, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.1891250610351562 current loss tensor(-2450.7339, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.195127248764038 current loss tensor(-2450.8425, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.352616786956787 current loss tensor(-2450.9490, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.179018259048462 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]
average_loss tensor(-2495.3135, device='cuda:0', grad_fn=<DivBackward0>) best_loss inf
Epoch 0 Epoch time:  3.6890196800231934 current loss tensor(-2524.5952, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2495.4390, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2495.3135, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1 Epoch time:  3.197321653366089 current loss tensor(-2524.7104, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2495.5620, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2495.4390, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2 Epoch time:  3.345193862915039 current loss tensor(-2524.8230, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2495.6819, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2495.5620, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3 Epoch time:  3.2874433994293213 current loss tensor(-2524.9329, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2495.7996, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2495.6819, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4 Epoch time:  3.1973073482513428 current loss tensor(-2525.0403, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2495.9146, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2495.7996, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5 Epoch time:  3.195683240890503 current loss tensor(-2525.1450, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.0269, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2495.9146, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6 Epoch time:  3.1967275142669678 current loss tensor(-2525.2471, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.1362, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.0269, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7 Epoch time:  3.2185304164886475 current loss tensor(-2525.3467, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.2429, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.1362, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8 Epoch time:  3.2171072959899902 current loss tensor(-2525.4434, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.3472, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.2429, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9 Epoch time:  3.32483172416687 current loss tensor(-2525.5376, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.4482, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.3472, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10 Epoch time:  3.2132067680358887 current loss tensor(-2525.6292, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.5469, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.4482, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11 Epoch time:  3.31657075881958 current loss tensor(-2525.7180, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.6426, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.5469, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12 Epoch time:  3.2092514038085938 current loss tensor(-2525.8042, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.7354, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.6426, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13 Epoch time:  3.201678991317749 current loss tensor(-2525.8877, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.8259, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.7354, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14 Epoch time:  3.20029354095459 current loss tensor(-2525.9688, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.9136, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.8259, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15 Epoch time:  3.204960823059082 current loss tensor(-2526.0471, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.9985, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.9136, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16 Epoch time:  3.216641664505005 current loss tensor(-2526.1233, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.0811, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.9985, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17 Epoch time:  3.272533893585205 current loss tensor(-2526.1968, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.1609, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.0811, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18 Epoch time:  3.27913761138916 current loss tensor(-2526.2676, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.2380, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.1609, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19 Epoch time:  3.2051799297332764 current loss tensor(-2526.3362, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.3127, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.2380, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20 Epoch time:  3.284083127975464 current loss tensor(-2526.4023, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.3853, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.3127, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21 Epoch time:  3.331176280975342 current loss tensor(-2526.4663, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.4551, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.3853, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22 Epoch time:  3.2197458744049072 current loss tensor(-2526.5278, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.5225, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.4551, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23 Epoch time:  3.225714921951294 current loss tensor(-2526.5874, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.5876, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.5225, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24 Epoch time:  3.2431702613830566 current loss tensor(-2526.6445, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.6506, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.5876, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25 Epoch time:  3.2208139896392822 current loss tensor(-2526.6997, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.7117, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.6506, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26 Epoch time:  3.287630081176758 current loss tensor(-2526.7529, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.7703, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.7117, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27 Epoch time:  3.2304797172546387 current loss tensor(-2526.8047, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.8271, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.7703, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28 Epoch time:  3.2116811275482178 current loss tensor(-2526.8540, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.8818, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.8271, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29 Epoch time:  3.3225998878479004 current loss tensor(-2526.9014, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.9346, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.8818, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30 Epoch time:  3.293391704559326 current loss tensor(-2526.9475, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.9858, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.9346, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31 Epoch time:  3.2123236656188965 current loss tensor(-2526.9917, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.0349, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.9858, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32 Epoch time:  3.2082130908966064 current loss tensor(-2527.0342, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.0823, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.0349, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33 Epoch time:  3.243691921234131 current loss tensor(-2527.0754, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.1284, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.0823, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34 Epoch time:  3.3242850303649902 current loss tensor(-2527.1152, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.1726, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.1284, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35 Epoch time:  3.217264175415039 current loss tensor(-2527.1533, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.2156, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.1726, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36 Epoch time:  3.2180685997009277 current loss tensor(-2527.1904, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.2568, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.2156, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37 Epoch time:  3.2623491287231445 current loss tensor(-2527.2261, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.2969, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.2568, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38 Epoch time:  3.342189311981201 current loss tensor(-2527.2607, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.3357, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.2969, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39 Epoch time:  3.207024335861206 current loss tensor(-2527.2939, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.3730, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.3357, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40 Epoch time:  3.2148282527923584 current loss tensor(-2527.3262, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.4097, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.3730, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41 Epoch time:  3.2283694744110107 current loss tensor(-2527.3574, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.4448, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.4097, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42 Epoch time:  3.2092604637145996 current loss tensor(-2527.3877, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.4788, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.4448, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43 Epoch time:  3.2092113494873047 current loss tensor(-2527.4170, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.5117, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.4788, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44 Epoch time:  3.295924186706543 current loss tensor(-2527.4453, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.5442, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.5117, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45 Epoch time:  3.220641851425171 current loss tensor(-2527.4729, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.5754, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.5442, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46 Epoch time:  3.2186434268951416 current loss tensor(-2527.4998, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.6060, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.5754, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47 Epoch time:  3.2901344299316406 current loss tensor(-2527.5259, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.6355, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.6060, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48 Epoch time:  3.3470444679260254 current loss tensor(-2527.5515, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.6646, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.6355, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49 Epoch time:  3.281141996383667 current loss tensor(-2527.5762, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.6926, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.6646, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 50 Epoch time:  3.2152023315429688 current loss tensor(-2527.6003, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.7202, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.6926, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 51 Epoch time:  3.2172443866729736 current loss tensor(-2527.6240, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.7471, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.7202, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 52 Epoch time:  3.3198344707489014 current loss tensor(-2527.6475, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.7732, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.7471, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 53 Epoch time:  3.204824686050415 current loss tensor(-2527.6699, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.7988, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.7732, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 54 Epoch time:  tensor(-2508.7561, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.2178561687469482 current loss tensor(-2508.8623, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.2298362255096436 current loss tensor(-2508.9658, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.2135305404663086 current loss tensor(-2509.0664, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.315950870513916 current loss tensor(-2509.1641, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.2007720470428467 current loss tensor(-2509.2588, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.197000503540039 current loss tensor(-2509.3511, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.204685926437378 current loss tensor(-2509.4407, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.259646415710449 current loss tensor(-2509.5273, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.1418135166168213 current loss tensor(-2509.6113, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.1884517669677734 current loss tensor(-2509.6929, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.199223041534424 current loss tensor(-2509.7717, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.2090022563934326 current loss tensor(-2509.8479, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.329749345779419 current loss tensor(-2509.9214, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.19022798538208 current loss tensor(-2509.9927, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.2630510330200195 current loss tensor(-2510.0613, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.2037580013275146 current loss tensor(-2510.1274, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.208080291748047 current loss tensor(-2510.1914, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.1769425868988037 current loss tensor(-2510.2534, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.2152974605560303 current loss tensor(-2510.3130, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.210846185684204 current loss tensor(-2510.3701, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.232963800430298 current loss tensor(-2510.4255, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.1949636936187744 current loss tensor(-2510.4788, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.3900787830352783 current loss tensor(-2510.5305, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.156609058380127 current loss tensor(-2510.5801, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.2004313468933105 current loss tensor(-2510.6279, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.214219331741333 current loss tensor(-2510.6738, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.2377004623413086 current loss tensor(-2510.7188, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.222017526626587 current loss tensor(-2510.7615, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.2258832454681396 current loss tensor(-2510.8032, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.194186210632324 current loss tensor(-2510.8433, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.3593175411224365 current loss tensor(-2510.8818, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.196415424346924 current loss tensor(-2510.9194, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.1991758346557617 current loss tensor(-2510.9556, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.244269847869873 current loss tensor(-2510.9907, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.190385103225708 current loss tensor(-2511.0244, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.1997857093811035 current loss tensor(-2511.0576, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.210341215133667 current loss tensor(-2511.0894, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.21591854095459 current loss tensor(-2511.1206, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.237680435180664 current loss tensor(-2511.1509, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.302919387817383 current loss tensor(-2511.1802, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.1708731651306152 current loss tensor(-2511.2090, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.2537684440612793 current loss tensor(-2511.2368, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.2249832153320312 current loss tensor(-2511.2639, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.2181732654571533 current loss tensor(-2511.2908, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.190725803375244 current loss tensor(-2511.3167, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.2197535037994385 current loss tensor(-2511.3423, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.214407205581665 current loss tensor(-2511.3672, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.2101221084594727 current loss tensor(-2511.3916, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.207446575164795 current loss tensor(-2511.4155, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.3763439655303955 current loss tensor(-2511.4395, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.165250778198242 current loss tensor(-2511.4624, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.223551034927368 current loss tensor(-2511.4854, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.209193706512451 current loss tensor(-2511.5081, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.232034206390381 current loss tensor(-2511.5303, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.2081291675567627 current loss tensor(-2511.5522, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.2293741703033447 current loss tensor(-2511.5742, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.2153103351593018 current loss tensor(-2511.5957, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.3248298168182373 current loss tensor(-2511.6167, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.2744152545928955 current loss tensor(-2511.6377, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  3.1737451553344727 current loss tensor(-2511.6587, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  3.2222771644592285 current loss tensor(-2511.6797, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  3.203662395477295 current loss tensor(-2511.7002, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  3.218621253967285 current loss tensor(-2511.7205, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  3.227895498275757 current loss tensor(-2511.7407, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  3.205699920654297 current loss tensor(-2511.7607, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  3.2117557525634766 current loss tensor(-2511.7810, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  3.3182497024536133 current loss tensor(-2511.8010, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  3.1711933612823486 current loss tensor(-2511.8206, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  3.2817986011505127 current loss tensor(-2511.8403, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  3.2089455127716064 current loss tensor(-2511.8604, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  3.2451417446136475 current loss tensor(-2511.8796, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  3.2008631229400635 current loss tensor(-2499.7087, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.2263612747192383 current loss tensor(-2499.8237, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.368049383163452 current loss tensor(-2499.9360, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.190065860748291 current loss tensor(-2500.0454, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.18390154838562 current loss tensor(-2500.1519, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.26857328414917 current loss tensor(-2500.2554, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.1959121227264404 current loss tensor(-2500.3560, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.216102361679077 current loss tensor(-2500.4541, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.2031047344207764 current loss tensor(-2500.5491, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.2700607776641846 current loss tensor(-2500.6414, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.165735960006714 current loss tensor(-2500.7310, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.321645498275757 current loss tensor(-2500.8181, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.1935603618621826 current loss tensor(-2500.9021, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.1981403827667236 current loss tensor(-2500.9834, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.30519962310791 current loss tensor(-2501.0625, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.2699015140533447 current loss tensor(-2501.1387, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.2073850631713867 current loss tensor(-2501.2126, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.209530830383301 current loss tensor(-2501.2839, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.248919725418091 current loss tensor(-2501.3530, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.306156873703003 current loss tensor(-2501.4199, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.1864395141601562 current loss tensor(-2501.4841, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.226088047027588 current loss tensor(-2501.5464, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.2166643142700195 current loss tensor(-2501.6067, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.284137725830078 current loss tensor(-2501.6648, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.2757749557495117 current loss tensor(-2501.7207, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.19466495513916 current loss tensor(-2501.7749, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.1977896690368652 current loss tensor(-2501.8271, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.379081964492798 current loss tensor(-2501.8777, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.1774044036865234 current loss tensor(-2501.9263, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.2119874954223633 current loss tensor(-2501.9736, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.202047109603882 current loss tensor(-2502.0190, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.2461681365966797 current loss tensor(-2502.0630, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.289743185043335 current loss tensor(-2502.1055, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.2001805305480957 current loss tensor(-2502.1465, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.2636237144470215 current loss tensor(-2502.1865, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.1810121536254883 current loss tensor(-2502.2251, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.1979031562805176 current loss tensor(-2502.2622, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.3359456062316895 current loss tensor(-2502.2986, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.169734239578247 current loss tensor(-2502.3335, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.25570011138916 current loss tensor(-2502.3677, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.1711204051971436 current loss tensor(-2502.4006, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.2808966636657715 current loss tensor(-2502.4329, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.267714500427246 current loss tensor(-2502.4641, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.21087646484375 current loss tensor(-2502.4944, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.211660861968994 current loss tensor(-2502.5242, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.3522982597351074 current loss tensor(-2502.5530, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.1854336261749268 current loss tensor(-2502.5811, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.2219645977020264 current loss tensor(-2502.6084, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.212129592895508 current loss tensor(-2502.6353, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.2262964248657227 current loss tensor(-2502.6614, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.2759807109832764 current loss tensor(-2502.6870, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.2916042804718018 current loss tensor(-2502.7122, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.219630718231201 current loss tensor(-2502.7366, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.2153139114379883 current loss tensor(-2502.7607, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.375354290008545 current loss tensor(-2502.7844, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.1892659664154053 current loss tensor(-2502.8076, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.2387921810150146 current loss tensor(-2502.8301, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.187856435775757 current loss tensor(-2502.8525, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.2139365673065186 current loss tensor(-2502.8745, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.3065781593322754 current loss tensor(-2502.8962, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  3.1854143142700195 current loss tensor(-2502.9180, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  3.226447820663452 current loss tensor(-2502.9390, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  3.2205920219421387 current loss tensor(-2502.9600, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  3.211862087249756 current loss tensor(-2502.9805, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  3.3702356815338135 current loss tensor(-2503.0010, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  3.183441400527954 current loss tensor(-2503.0210, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  3.21620774269104 current loss tensor(-2503.0410, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  3.2118918895721436 current loss tensor(-2503.0608, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  3.272141933441162 current loss tensor(-2503.0806, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  3.2792012691497803 current loss tensor(-2503.0999, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  3.200162649154663 current loss tensor(-2503.1191, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  3.247441530227661 current loss tensor(-2503.1384, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  3.3211638927459717 current loss current loss tensor(-2451.0522, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.194664716720581 current loss tensor(-2451.1533, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.2383289337158203 current loss tensor(-2451.2515, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.2203879356384277 current loss tensor(-2451.3472, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.211272716522217 current loss tensor(-2451.4402, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.2246878147125244 current loss tensor(-2451.5308, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.188908815383911 current loss tensor(-2451.6184, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.358795166015625 current loss tensor(-2451.7034, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.13627290725708 current loss tensor(-2451.7861, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.2337329387664795 current loss tensor(-2451.8662, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.2144064903259277 current loss tensor(-2451.9438, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.2359397411346436 current loss tensor(-2452.0190, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.2355310916900635 current loss tensor(-2452.0918, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.2182834148406982 current loss tensor(-2452.1626, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.3351054191589355 current loss tensor(-2452.2310, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.1367859840393066 current loss tensor(-2452.2966, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.1993610858917236 current loss tensor(-2452.3608, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.2354841232299805 current loss tensor(-2452.4224, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.212364912033081 current loss tensor(-2452.4824, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.2008259296417236 current loss tensor(-2452.5403, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.2641100883483887 current loss tensor(-2452.5962, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.2563552856445312 current loss tensor(-2452.6501, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.1814863681793213 current loss tensor(-2452.7024, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.222027063369751 current loss tensor(-2452.7529, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.2399559020996094 current loss tensor(-2452.8018, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.258383274078369 current loss tensor(-2452.8491, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.156161069869995 current loss tensor(-2452.8950, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.316612958908081 current loss tensor(-2452.9395, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.130643844604492 current loss tensor(-2452.9824, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.221639633178711 current loss tensor(-2453.0239, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.2240030765533447 current loss tensor(-2453.0645, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.1948583126068115 current loss tensor(-2453.1035, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.2184834480285645 current loss tensor(-2453.1416, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.202745199203491 current loss tensor(-2453.1785, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.2240140438079834 current loss tensor(-2453.2144, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.2591638565063477 current loss tensor(-2453.2495, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.192445993423462 current loss tensor(-2453.2834, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.2109642028808594 current loss tensor(-2453.3167, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.2397828102111816 current loss tensor(-2453.3489, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.361743688583374 current loss tensor(-2453.3806, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.1413230895996094 current loss tensor(-2453.4114, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.2069478034973145 current loss tensor(-2453.4414, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.2081921100616455 current loss tensor(-2453.4709, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.241591215133667 current loss tensor(-2453.4995, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.2109291553497314 current loss tensor(-2453.5278, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.248181104660034 current loss tensor(-2453.5559, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.1429474353790283 current loss tensor(-2453.5830, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.2128000259399414 current loss tensor(-2453.6096, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.2563841342926025 current loss tensor(-2453.6357, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.206895351409912 current loss tensor(-2453.6616, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.3518178462982178 current loss tensor(-2453.6870, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.1476962566375732 current loss tensor(-2453.7119, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.2483725547790527 current loss tensor(-2453.7368, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.2153518199920654 current loss tensor(-2453.7612, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.21317458152771 current loss tensor(-2453.7849, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.2169291973114014 current loss tensor(-2453.8091, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.226067304611206 current loss tensor(-2453.8325, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  3.219379186630249 current loss tensor(-2453.8557, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  3.213799476623535 current loss tensor(-2453.8789, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  3.2140557765960693 current loss tensor(-2453.9016, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  3.2323355674743652 current loss tensor(-2453.9243, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  3.3194808959960938 current loss tensor(-2453.9468, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  3.2165842056274414 current loss tensor(-2453.9690, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  3.2014877796173096 current loss tensor(-2453.9912, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  3.1995928287506104 current loss tensor(-2454.0132, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  3.2496891021728516 current loss tensor(-2454.0352, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  3.2319304943084717 current loss tensor(-2454.0566, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  3.2194807529449463 current loss tensor(-2454.0784, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  3.2424111366271973 current loss tensor(-2454.0999, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  3.2091636657714844 current loss tensor(-2454.1216, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  3.4003071784973145 current loss tensor(-2454.1428, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  3.1500191688537598 current loss tensor(-2454.1641, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  3.212899684906006 3.2145395278930664 current loss tensor(-2527.6924, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.8242, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.7988, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 55 Epoch time:  3.213074207305908 current loss tensor(-2527.7139, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.8486, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.8242, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 56 Epoch time:  3.319837808609009 current loss tensor(-2527.7354, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.8730, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.8486, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 57 Epoch time:  3.293769359588623 current loss tensor(-2527.7563, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.8967, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.8730, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 58 Epoch time:  3.2213544845581055 current loss tensor(-2527.7771, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.9204, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.8967, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 59 Epoch time:  3.2132349014282227 current loss tensor(-2527.7974, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.9434, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.9204, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 60 Epoch time:  3.275228261947632 current loss tensor(-2527.8174, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.9658, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.9434, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 61 Epoch time:  3.314622640609741 current loss tensor(-2527.8374, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.9883, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.9658, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 62 Epoch time:  3.229513645172119 current loss tensor(-2527.8569, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.0105, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.9883, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 63 Epoch time:  3.2041916847229004 current loss tensor(-2527.8762, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.0322, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.0105, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 64 Epoch time:  3.2189605236053467 current loss tensor(-2527.8953, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.0537, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.0322, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 65 Epoch time:  3.3517301082611084 current loss tensor(-2527.9141, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.0747, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.0537, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 66 Epoch time:  3.2083475589752197 current loss tensor(-2527.9326, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.0957, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.0747, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 67 Epoch time:  3.227321147918701 current loss tensor(-2527.9509, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.1167, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.0957, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 68 Epoch time:  3.217593193054199 current loss tensor(-2527.9692, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.1372, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.1167, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 69 Epoch time:  3.2081315517425537 current loss tensor(-2527.9873, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.1577, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.1372, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 70 Epoch time:  3.2115275859832764 current loss tensor(-2528.0054, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.1780, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.1577, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 71 Epoch time:  3.342543840408325 current loss tensor(-2528.0232, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.1980, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.1780, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 72 Epoch time:  3.2193641662597656 current loss tensor(-2528.0410, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.2180, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.1980, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 73 Epoch time:  3.215897560119629 current loss tensor(-2528.0583, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.2378, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.2180, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 74 Epoch time:  3.27114200592041 current loss tensor(-2528.0762, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.2573, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.2378, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 75 Epoch time:  3.3314085006713867 current loss tensor(-2528.0933, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.2769, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.2573, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 76 Epoch time:  3.2076845169067383 current loss tensor(-2528.1106, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.2964, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.2769, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 77 Epoch time:  3.249312162399292 current loss tensor(-2528.1279, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3159, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.2964, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 78 Epoch time:  3.205357789993286 current loss tensor(-2528.1453, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3352, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3159, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 79 Epoch time:  3.3113415241241455 current loss tensor(-2528.1624, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3545, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3352, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 80 Epoch time:  3.312004327774048 current loss tensor(-2528.1792, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3735, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3545, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 81 Epoch time:  3.219230890274048 current loss tensor(-2528.1963, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3926, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3735, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 82 Epoch time:  3.2542359828948975 current loss tensor(-2528.2134, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4116, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3926, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 83 Epoch time:  3.3225574493408203 current loss tensor(-2528.2300, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4304, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4116, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 84 Epoch time:  3.299410820007324 current loss tensor(-2528.2468, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4492, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4304, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 85 Epoch time:  3.2169766426086426 current loss tensor(-2528.2637, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4683, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4492, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 86 Epoch time:  3.2231171131134033 current loss tensor(-2528.2803, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4871, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4683, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 87 Epoch time:  3.2165842056274414 current loss tensor(-2528.2971, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5059, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4871, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 88 Epoch time:  3.299156665802002 current loss tensor(-2528.3137, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5244, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5059, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 89 Epoch time:  3.2151904106140137 current loss tensor(-2528.3306, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5435, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5244, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 90 Epoch time:  3.276822328567505 current loss tensor(-2528.3472, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5620, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5435, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 91 Epoch time:  3.223716974258423 current loss tensor(-2528.3638, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5808, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5620, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 92 Epoch time:  3.346971273422241 current loss tensor(-2528.3801, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5996, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5808, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 93 Epoch time:  3.213062047958374 current loss tensor(-2528.3970, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6182, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5996, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 94 Epoch time:  3.2147748470306396 current loss tensor(-2528.4131, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6370, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6182, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 95 Epoch time:  3.2189431190490723 current loss tensor(-2528.4297, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6558, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6370, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 96 Epoch time:  3.226813793182373 current loss tensor(-2528.4463, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6743, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6558, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 97 Epoch time:  3.2116055488586426 current loss tensor(-2528.4629, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6931, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6743, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 98 Epoch time:  3.2926688194274902 current loss tensor(-2528.4792, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.7119, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6931, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 99 Epoch time:  3.2217655181884766 current loss tensor(-2528.4958, device='cuda:0', grad_fn=<SumBackward0>)
best_out [0.5423913  0.5309553  0.5229805  ... 0.45959818 0.5579053  0.52563524]
info_input_total 2000 weights 2000 total_C 19990
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
-10112
res {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 0, 19: 0, 20: 1, 21: 0, 22: 0, 23: 0, 24: 1, 25: 0, 26: 1, 27: 0, 28: 0, 29: 1, 30: 1, 31: 0, 32: 1, 33: 0, 34: 1, 35: 1, 36: 1, 37: 0, 38: 1, 39: 0, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 0, 48: 1, 49: 0, 50: 0, 51: 0, 52: 1, 53: 0, 54: 1, 55: 0, 56: 0, 57: 1, 58: 0, 59: 1, 60: 0, 61: 1, 62: 1, 63: 1, 64: 0, 65: 0, 66: 1, 67: 0, 68: 0, 69: 1, 70: 1, 71: 1, 72: 0, 73: 0, 74: 1, 75: 1, 76: 1, 77: 0, 78: 0, 79: 0, 80: 1, 81: 0, 82: 0, 83: 0, 84: 1, 85: 0, 86: 1, 87: 0, 88: 0, 89: 1, 90: 0, 91: 0, 92: 1, 93: 1, 94: 0, 95: 0, 96: 1, 97: 0, 98: 1, 99: 1, 100: 0, 101: 0, 102: 1, 103: 1, 104: 0, 105: 1, 106: 0, 107: 0, 108: 1, 109: 1, 110: 1, 111: 1, 112: 1, 113: 0, 114: 0, 115: 0, 116: 0, 117: 1, 118: 1, 119: 1, 120: 0, 121: 0, 122: 1, 123: 0, 124: 0, 125: 0, 126: 0, 127: 0, 128: 1, 129: 0, 130: 1, 131: 0, 132: 1, 133: 1, 134: 1, 135: 0, 136: 0, 137: 0, 138: 0, 139: 1, 140: 1, 141: 0, 142: 1, 143: 0, 144: 1, 145: 1, 146: 1, 147: 1, 148: 0, 149: 1, 150: 1, 151: 0, 152: 0, 153: 1, 154: 0, 155: 1, 156: 0, 157: 0, 158: 1, 159: 0, 160: 0, 161: 0, 162: 1, 163: 1, 164: 0, 165: 0, 166: 1, 167: 0, 168: 1, 169: 0, 170: 0, 171: 1, 172: 1, 173: 1, 174: 0, 175: 1, 176: 1, 177: 1, 178: 1, 179: 0, 180: 0, 181: 1, 182: 0, 183: 1, 184: 1, 185: 1, 186: 1, 187: 0, 188: 1, 189: 0, 190: 0, 191: 1, 192: 1, 193: 1, 194: 1, 195: 0, 196: 1, 197: 1, 198: 0, 199: 1, 200: 1, 201: 1, 202: 1, 203: 1, 204: 1, 205: 1, 206: 1, 207: 0, 208: 0, 209: 0, 210: 1, 211: 1, 212: 1, 213: 0, 214: 1, 215: 0, 216: 1, 217: 1, 218: 1, 219: 1, 220: 1, 221: 1, 222: 1, 223: 1, 224: 1, 225: 1, 226: 1, 227: 0, 228: 0, 229: 0, 230: 0, 231: 0, 232: 1, 233: 0, 234: 0, 235: 0, 236: 1, 237: 0, 238: 1, 239: 1, 240: 1, 241: 1, 242: 0, 243: 1, 244: 0, 245: 1, 246: 1, 247: 0, 248: 0, 249: 1, 250: 0, 251: 0, 252: 0, 253: 1, 254: 0, 255: 0, 256: 1, 257: 1, 258: 1, 259: 0, 260: 0, 261: 1, 262: 1, 263: 0, 264: 1, 265: 1, 266: 0, 267: 1, 268: 1, 269: 1, 270: 0, 271: 0, 272: 0, 273: 1, 274: 0, 275: 0, 276: 0, 277: 0, 278: 1, 279: 0, 280: 0, 281: 1, 282: 1, 283: 0, 284: 0, 285: 0, 286: 1, 287: 1, 288: 1, 289: 0, 290: 0, 291: 0, 292: 0, 293: 0, 294: 1, 295: 0, 296: 0, 297: 0, 298: 0, 299: 0, 300: 0, 301: 0, 302: 1, 303: 0, 304: 1, 305: 0, 306: 0, 307: 0, 308: 1, 309: 1, 310: 1, 311: 1, 312: 1, 313: 0, 314: 1, 315: 1, 316: 1, 317: 1, 318: 1, 319: 1, 320: 1, 321: 1, 322: 0, 323: 0, 324: 1, 325: 1, 326: 1, 327: 1, 328: 1, 329: 1, 330: 1, 331: 0, 332: 0, 333: 0, 334: 0, 335: 1, 336: 0, 337: 0, 338: 0, 339: 0, 340: 1, 341: 0, 342: 1, 343: 1, 344: 0, 345: 0, 346: 0, 347: 1, 348: 0, 349: 1, 350: 0, 351: 1, 352: 0, 353: 1, 354: 1, 355: 1, 356: 0, 357: 0, 358: 0, 359: 0, 360: 0, 361: 1, 362: 1, 363: 0, 364: 1, 365: 1, 366: 0, 367: 0, 368: 1, 369: 1, 370: 0, 371: 0, 372: 0, 373: 1, 374: 0, 375: 1, 376: 1, 377: 1, 378: 0, 379: 1, 380: 1, 381: 0, 382: 0, 383: 1, 384: 1, 385: 1, 386: 1, 387: 0, 388: 1, 389: 0, 390: 0, 391: 1, 392: 0, 393: 0, 394: 1, 395: 1, 396: 1, 397: 1, 398: 0, 399: 1, 400: 0, 401: 0, 402: 1, 403: 0, 404: 0, 405: 1, 406: 0, 407: 0, 408: 0, 409: 1, 410: 0, 411: 0, 412: 1, 413: 1, 414: 0, 415: 1, 416: 1, 417: 0, 418: 1, 419: 0, 420: 1, 421: 0, 422: 1, 423: 0, 424: 1, 425: 1, 426: 0, 427: 0, 428: 1, 429: 0, 430: 1, 431: 1, 432: 0, 433: 1, 434: 1, 435: 1, 436: 0, 437: 0, 438: 1, 439: 0, 440: 0, 441: 0, 442: 0, 443: 0, 444: 0, 445: 1, 446: 0, 447: 0, 448: 1, 449: 0, 450: 1, 451: 1, 452: 1, 453: 0, 454: 0, 455: 0, 456: 0, 457: 1, 458: 0, 459: 1, 460: 1, 461: 1, 462: 0, 463: 0, 464: 0, 465: 1, 466: 1, 467: 0, 468: 0, 469: 0, 470: 0, 471: 0, 472: 1, 473: 1, 474: 0, 475: 1, 476: 1, 477: 0, 478: 1, 479: 1, 480: 1, 481: 0, 482: 0, 483: 0, 484: 0, 485: 0, 486: 0, 487: 0, 488: 1, 489: 1, 490: 1, 491: 1, 492: 0, 493: 0, 494: 0, 495: 1, 496: 0, 497: 1, 498: 1, 499: 0, 500: 0, 501: 1, 502: 0, 503: 1, 504: 0, 505: 0, 506: 1, 507: 0, 508: 1, 509: 1, 510: 0, 511: 0, 512: 0, 513: 1, 514: 1, 515: 0, 516: 1, 517: 1, 518: 0, 519: 0, 520: 0, 521: 1, 522: 0, 523: 1, 524: 1, 525: 1, 526: 0, 527: 0, 528: 0, 529: 0, 530: 1, 531: 0, 532: 0, 533: 0, 534: 1, 535: 1, 536: 0, 537: 1, 538: 0, 539: 1, 540: 0, 541: 0, 542: 0, 543: 0, 544: 0, 545: 0, 546: 1, 547: 1, 548: 1, 549: 0, 550: 1, 551: 0, 552: 1, 553: 1, 554: 0, 555: 1, 556: 0, 557: 1, 558: 1, 559: 0, 560: 0, 561: 1, 562: 0, 563: 1, 564: 1, 565: 0, 566: 0, 567: 0, 568: 0, 569: 0, 570: 1, 571: 0, 572: 0, 573: 1, 574: 0, 575: 0, 576: 1, 577: 1, 578: 1, 579: 0, 580: 0, 581: 0, 582: 0, 583: 0, 584: 1, 585: 0, 586: 0, 587: 1, 588: 1, 589: 0, 590: 1, 591: 1, 592: 0, 593: 1, 594: 1, 595: 1, 596: 1, 597: 0, 598: 1, 599: 1, 600: 1, 601: 1, 602: 0, 603: 1, 604: 0, 605: 0, 606: 1, 607: 1, 608: 1, 609: 1, 610: 0, 611: 1, 612: 1, 613: 0, 614: 1, 615: 0, 616: 1, 617: 0, 618: 0, 619: 1, 620: 1, 621: 1, 622: 1, 623: 0, 624: 1, 625: 0, 626: 0, 627: 0, 628: 1, 629: 0, 630: 1, 631: 0, 632: 0, 633: 0, 634: 0, 635: 1, 636: 1, 637: 1, 638: 0, 639: 1, 640: 0, 641: 1, 642: 0, 643: 0, 644: 1, 645: 1, 646: 1, 647: 1, 648: 1, 649: 1, 650: 0, 651: 1, 652: 0, 653: 1, 654: 0, 655: 1, 656: 1, 657: 1, 658: 1, 659: 0, 660: 1, 661: 0, 662: 1, 663: 1, 664: 1, 665: 0, 666: 1, 667: 1, 668: 1, 669: 1, 670: 1, 671: 0, 672: 1, 673: 0, 674: 1, 675: 1, 676: 1, 677: 0, 678: 0, 679: 1, 680: 1, 681: 0, 682: 0, 683: 0, 684: 1, 685: 1, 686: 1, 687: 0, 688: 1, 689: 0, 690: 1, 691: 1, 692: 0, 693: 1, 694: 1, 695: 1, 696: 0, 697: 1, 698: 0, 699: 1, 700: 0, 701: 0, 702: 1, 703: 0, 704: 0, 705: 1, 706: 1, 707: 0, 708: 0, 709: 1, 710: 1, 711: 1, 712: 0, 713: 1, 714: 1, 715: 1, 716: 1, 717: 1, 718: 1, 719: 1, 720: 0, 721: 0, 722: 0, 723: 1, 724: 0, 725: 0, 726: 1, 727: 1, 728: 0, 729: 1, 730: 1, 731: 1, 732: 1, 733: 1, 734: 1, 735: 0, 736: 1, 737: 1, 738: 0, 739: 1, 740: 0, 741: 1, 742: 0, 743: 1, 744: 0, 745: 1, 746: 0, 747: 1, 748: 0, 749: 0, 750: 0, 751: 1, 752: 0, 753: 1, 754: 0, 755: 0, 756: 0, 757: 0, 758: 0, 759: 0, 760: 0, 761: 1, 762: 1, 763: 0, 764: 1, 765: 1, 766: 0, 767: 1, 768: 0, 769: 1, 770: 0, 771: 0, 772: 0, 773: 0, 774: 0, 775: 1, 776: 0, 777: 1, 778: 1, 779: 0, 780: 1, 781: 0, 782: 0, 783: 1, 784: 0, 785: 0, 786: 0, 787: 0, 788: 0, 789: 1, 790: 1, 791: 1, 792: 0, 793: 0, 794: 0, 795: 1, 796: 0, 797: 0, 798: 1, 799: 1, 800: 1, 801: 1, 802: 1, 803: 0, 804: 0, 805: 1, 806: 0, 807: 1, 808: 0, 809: 0, 810: 1, 811: 0, 812: 0, 813: 0, 814: 1, 815: 1, 816: 1, 817: 0, 818: 0, 819: 1, 820: 1, 821: 1, 822: 0, 823: 0, 824: 0, 825: 1, 826: 0, 827: 0, 828: 0, 829: 0, 830: 0, 831: 1, 832: 1, 833: 0, 834: 0, 835: 1, 836: 1, 837: 0, 838: 0, 839: 0, 840: 1, 841: 0, 842: 1, 843: 1, 844: 1, 845: 1, 846: 0, 847: 1, 848: 1, 849: 0, 850: 0, 851: 0, 852: 0, 853: 0, 854: 0, 855: 0, 856: 0, 857: 1, 858: 0, 859: 1, 860: 0, 861: 0, 862: 1, 863: 1, 864: 1, 865: 0, 866: 0, 867: 1, 868: 0, 869: 0, 870: 1, 871: 1, 872: 1, 873: 0, 874: 0, 875: 0, 876: 1, 877: 1, 878: 0, 879: 0, 880: 0, 881: 0, 882: 0, 883: 1, 884: 0, 885: 1, 886: 0, 887: 0, 888: 0, 889: 0, 890: 1, 891: 1, 892: 1, 893: 1, 894: 0, 895: 0, 896: 1, 897: 0, 898: 0, 899: 1, 900: 1, 901: 1, 902: 1, 903: 0, 904: 1, 905: 0, 906: 1, 907: 0, 908: 0, 909: 0, 910: 1, 911: 0, 912: 1, 913: 0, 914: 0, 915: 0, 916: 0, 917: 0, 918: 1, 919: 0, 920: 1, 921: 0, 922: 1, 923: 0, 924: 1, 925: 0, 926: 0, 927: 1, 928: 1, 929: 1, 930: 0, 931: 0, 932: 0, 933: 0, 934: 1, 935: 1, 936: 1, 937: 1, 938: 0, 939: 1, 940: 1, 941: 0, 942: 1, 943: 1, 944: 0, 945: 0, 946: 0, 947: 0, 948: 1, 949: 0, 950: 1, 951: 1, 952: 1, 953: 1, 954: 1, 955: 1, 956: 0, 957: 0, 958: 0, 959: 1, 960: 1, 961: 1, 962: 1, 963: 0, 964: 1, 965: 0, 966: 1, 967: 1, 968: 1, 969: 0, 970: 1, 971: 0, 972: 1, 973: 0, 974: 0, 975: 1, 976: 0, 977: 0, 978: 0, 979: 0, 980: 1, 981: 1, 982: 1, 983: 1, 984: 1, 985: 1, 986: 0, 987: 0, 988: 0, 989: 0, 990: 0, 991: 1, 992: 1, 993: 1, 994: 1, 995: 1, 996: 1, 997: 1, 998: 0, 999: 0, 1000: 1, 1001: 0, 1002: 1, 1003: 1, 1004: 0, 1005: 0, 1006: 1, 1007: 1, 1008: 0, 1009: 1, 1010: 0, 1011: 0, 1012: 0, 1013: 1, 1014: 0, 1015: 1, 1016: 0, 1017: 0, 1018: 1, 1019: 0, 1020: 1, 1021: 1, 1022: 0, 1023: 1, 1024: 0, 1025: 1, 1026: 0, 1027: 1, 1028: 0, 1029: 0, 1030: 0, 1031: 0, 1032: 0, 1033: 1, 1034: 1, 1035: 0, 1036: 0, 1037: 0, 1038: 0, 1039: 0, 1040: 1, 1041: 1, 1042: 1, 1043: 1, 1044: 1, 1045: 1, 1046: 0, 1047: 1, 1048: 1, 1049: 0, 1050: 1, 1051: 0, 1052: 1, 1053: 0, 1054: 1, 1055: 0, 1056: 1, 1057: 1, 1058: 0, 1059: 1, 1060: 1, 1061: 0, 1062: 0, 1063: 1, 1064: 0, 1065: 0, 1066: 0, 1067: 1, 1068: 0, 1069: 0, 1070: 1, 1071: 1, 1072: 1, 1073: 1, 1074: 1, 1075: 1, 1076: 1, 1077: 0, 1078: 1, 1079: 1, 1080: 1, 1081: 1, 1082: 1, 1083: 1, 1084: 0, 1085: 1, 1086: 0, 1087: 1, 1088: 1, 1089: 0, 1090: 0, 1091: 0, 1092: 0, 1093: 1, 1094: 0, 1095: 1, 1096: 0, 1097: 0, 1098: 1, 1099: 1, 1100: 1, 1101: 1, 1102: 0, 1103: 0, 1104: 0, 1105: 1, 1106: 1, 1107: 1, 1108: 0, 1109: 1, 1110: 0, 1111: 1, 1112: 0, 1113: 1, 1114: 1, 1115: 0, 1116: 1, 1117: 0, 1118: 0, 1119: 1, 1120: 0, 1121: 0, 1122: 1, 1123: 1, 1124: 1, 1125: 1, 1126: 1, 1127: 1, 1128: 0, 1129: 1, 1130: 0, 1131: 0, 1132: 1, 1133: 1, 1134: 1, 1135: 1, 1136: 1, 1137: 0, 1138: 1, 1139: 1, 1140: 0, 1141: 0, 1142: 1, 1143: 0, 1144: 1, 1145: 1, 1146: 0, 1147: 1, 1148: 0, 1149: 1, 1150: 0, 1151: 0, 1152: 0, 1153: 1, 1154: 0, 1155: 0, 1156: 1, 1157: 1, 1158: 0, 1159: 0, 1160: 1, 1161: 0, 1162: 1, 1163: 0, 1164: 1, 1165: 1, 1166: 1, 1167: 0, 1168: 0, 1169: 0, 1170: 1, 1171: 1, 1172: 0, 1173: 0, 1174: 0, 1175: 1, 1176: 1, 1177: 1, 1178: 0, 1179: 0, 1180: 0, 1181: 1, 1182: 0, 1183: 0, 1184: 1, 1185: 0, 1186: 0, 1187: 0, 1188: 1, 1189: 0, 1190: 0, 1191: 0, 1192: 0, 1193: 0, 1194: 0, 1195: 1, 1196: 1, 1197: 1, 1198: 0, 1199: 0, 1200: 0, 1201: 0, 1202: 1, 1203: 0, 1204: 1, 1205: 0, 1206: 0, 1207: 0, 1208: 0, 1209: 0, 1210: 0, 1211: 0, 1212: 0, 1213: 1, 1214: 1, 1215: 1, 1216: 0, 1217: 0, 1218: 1, 1219: 1, 1220: 0, 1221: 1, 1222: 0, 1223: 1, 1224: 1, 1225: 0, 1226: 1, 1227: 1, 1228: 0, 1229: 0, 1230: 1, 1231: 0, 1232: 1, 1233: 1, 1234: 0, 1235: 0, 1236: 0, 1237: 1, 1238: 1, 1239: 1, 1240: 0, 1241: 1, 1242: 0, 1243: 0, 1244: 0, 1245: 1, 1246: 1, 1247: 0, 1248: 0, 1249: 0, 1250: 0, 1251: 0, 1252: 0, 1253: 0, 1254: 1, 1255: 0, 1256: 1, 1257: 1, 1258: 0, 1259: 1, 1260: 0, 1261: 1, 1262: 1, 1263: 1, 1264: 1, 1265: 0, 1266: 1, 1267: 0, 1268: 1, 1269: 1, 1270: 0, 1271: 0, 1272: 0, 1273: 1, 1274: 0, 1275: 0, 1276: 0, 1277: 0, 1278: 1, 1279: 0, 1280: 0, 1281: 1, 1282: 0, 1283: 1, 1284: 1, 1285: 1, 1286: 0, 1287: 0, 1288: 1, 1289: 0, 1290: 1, 1291: 1, 1292: 1, 1293: 1, 1294: 0, 1295: 0, 1296: 0, 1297: 0, 1298: 0, 1299: 0, 1300: 1, 1301: 0, 1302: 1, 1303: 0, 1304: 1, 1305: 1, 1306: 1, 1307: 0, 1308: 1, 1309: 1, 1310: 1, 1311: 0, 1312: 1, 1313: 0, 1314: 1, 1315: 0, 1316: 1, 1317: 1, 1318: 1, 1319: 1, 1320: 0, 1321: 0, 1322: 0, 1323: 0, 1324: 1, 1325: 1, 1326: 1, 1327: 1, 1328: 1, 1329: 0, 1330: 0, 1331: 0, 1332: 1, 1333: 0, 1334: 1, 1335: 0, 1336: 0, 1337: 0, 1338: 1, 1339: 0, 1340: 0, 1341: 1, 1342: 0, 1343: 0, 1344: 1, 1345: 0, 1346: 1, 1347: 1, 1348: 0, 1349: 1, 1350: 0, 1351: 1, 1352: 0, 1353: 0, 1354: 0, 1355: 0, 1356: 1, 1357: 1, 1358: 0, 1359: 0, 1360: 1, 1361: 1, 1362: 1, 1363: 1, 1364: 1, 1365: 0, 1366: 0, 1367: 1, 1368: 0, 1369: 1, 1370: 0, 1371: 0, 1372: 1, 1373: 1, 1374: 0, 1375: 0, 1376: 0, 1377: 0, 1378: 0, 1379: 0, 1380: 1, 1381: 0, 1382: 1, 1383: 1, 1384: 1, 1385: 0, 1386: 0, 1387: 0, 1388: 0, 1389: 1, 1390: 0, 1391: 0, 1392: 1, 1393: 1, 1394: 1, 1395: 0, 1396: 1, 1397: 0, 1398: 1, 1399: 1, 1400: 0, 1401: 0, 1402: 0, 1403: 1, 1404: 1, 1405: 0, 1406: 0, 1407: 0, 1408: 1, 1409: 0, 1410: 1, 1411: 0, 1412: 0, 1413: 1, 1414: 0, 1415: 0, 1416: 0, 1417: 1, 1418: 1, 1419: 0, 1420: 0, 1421: 0, 1422: 0, 1423: 1, 1424: 0, 1425: 1, 1426: 0, 1427: 1, 1428: 0, 1429: 1, 1430: 1, 1431: 1, 1432: 0, 1433: 0, 1434: 0, 1435: 0, 1436: 1, 1437: 1, 1438: 0, 1439: 0, 1440: 1, 1441: 1, 1442: 1, 1443: 1, 1444: 0, 1445: 0, 1446: 1, 1447: 0, 1448: 1, 1449: 0, 1450: 1, 1451: 0, 1452: 0, 1453: 1, 1454: 1, 1455: 0, 1456: 1, 1457: 0, 1458: 1, 1459: 0, 1460: 0, 1461: 0, 1462: 0, 1463: 1, 1464: 1, 1465: 1, 1466: 1, 1467: 1, 1468: 1, 1469: 0, 1470: 1, 1471: 0, 1472: 0, 1473: 1, 1474: 0, 1475: 0, 1476: 0, 1477: 0, 1478: 1, 1479: 1, 1480: 1, 1481: 1, 1482: 1, 1483: 0, 1484: 0, 1485: 0, 1486: 1, 1487: 1, 1488: 1, 1489: 0, 1490: 0, 1491: 0, 1492: 1, 1493: 0, 1494: 0, 1495: 0, 1496: 1, 1497: 0, 1498: 1, 1499: 1, 1500: 1, 1501: 0, 1502: 0, 1503: 0, 1504: 0, 1505: 1, 1506: 1, 1507: 1, 1508: 1, 1509: 1, 1510: 0, 1511: 0, 1512: 0, 1513: 0, 1514: 0, 1515: 1, 1516: 1, 1517: 0, 1518: 0, 1519: 0, 1520: 0, 1521: 1, 1522: 1, 1523: 1, 1524: 0, 1525: 0, 1526: 1, 1527: 1, 1528: 0, 1529: 0, 1530: 0, 1531: 0, 1532: 0, 1533: 0, 1534: 0, 1535: 1, 1536: 0, 1537: 1, 1538: 0, 1539: 0, 1540: 0, 1541: 0, 1542: 0, 1543: 1, 1544: 0, 1545: 1, 1546: 1, 1547: 1, 1548: 0, 1549: 1, 1550: 0, 1551: 0, 1552: 0, 1553: 0, 1554: 1, 1555: 1, 1556: 0, 1557: 0, 1558: 0, 1559: 1, 1560: 0, 1561: 0, 1562: 0, 1563: 1, 1564: 0, 1565: 0, 1566: 1, 1567: 1, 1568: 0, 1569: 1, 1570: 1, 1571: 1, 1572: 0, 1573: 0, 1574: 1, 1575: 1, 1576: 1, 1577: 0, 1578: 1, 1579: 0, 1580: 1, 1581: 1, 1582: 1, 1583: 1, 1584: 0, 1585: 0, 1586: 1, 1587: 1, 1588: 1, 1589: 1, 1590: 1, 1591: 0, 1592: 1, 1593: 0, 1594: 1, 1595: 1, 1596: 0, 1597: 1, 1598: 0, 1599: 1, 1600: 0, 1601: 1, 1602: 0, 1603: 0, 1604: 1, 1605: 0, 1606: 0, 1607: 0, 1608: 1, 1609: 1, 1610: 1, 1611: 0, 1612: 1, 1613: 0, 1614: 0, 1615: 0, 1616: 0, 1617: 1, 1618: 0, 1619: 0, 1620: 0, 1621: 0, 1622: 1, 1623: 0, 1624: 0, 1625: 0, 1626: 1, 1627: 0, 1628: 0, 1629: 0, 1630: 1, 1631: 1, 1632: 1, 1633: 1, 1634: 1, 1635: 0, 1636: 1, 1637: 0, 1638: 0, 1639: 1, 1640: 0, 1641: 1, 1642: 0, 1643: 1, 1644: 0, 1645: 1, 1646: 1, 1647: 0, 1648: 0, 1649: 1, 1650: 1, 1651: 1, 1652: 0, 1653: 1, 1654: 1, 1655: 0, 1656: 1, 1657: 1, 1658: 0, 1659: 1, 1660: 0, 1661: 0, 1662: 1, 1663: 0, 1664: 1, 1665: 0, 1666: 1, 1667: 0, 1668: 0, 1669: 0, 1670: 0, 1671: 1, 1672: 1, 1673: 0, 1674: 1, 1675: 1, 1676: 1, 1677: 0, 1678: 0, 1679: 1, 1680: 1, 1681: 0, 1682: 0, 1683: 0, 1684: 0, 1685: 1, 1686: 1, 1687: 1, 1688: 0, 1689: 0, 1690: 0, 1691: 0, 1692: 1, 1693: 1, 1694: 1, 1695: 1, 1696: 1, 1697: 0, 1698: 1, 1699: 1, 1700: 0, 1701: 0, 1702: 1, 1703: 0, 1704: 1, 1705: 0, 1706: 0, 1707: 0, 1708: 0, 1709: 0, 1710: 0, 1711: 0, 1712: 1, 1713: 0, 1714: 1, 1715: 0, 1716: 0, 1717: 1, 1718: 0, 1719: 0, 1720: 1, 1721: 1, 1722: 0, 1723: 0, 1724: 0, 1725: 0, 1726: 0, 1727: 1, 1728: 1, 1729: 1, 1730: 0, 1731: 1, 1732: 0, 1733: 1, 1734: 1, 1735: 0, 1736: 0, 1737: 0, 1738: 1, 1739: 0, 1740: 1, 1741: 0, 1742: 0, 1743: 1, 1744: 1, 1745: 1, 1746: 0, 1747: 1, 1748: 1, 1749: 0, 1750: 1, 1751: 1, 1752: 0, 1753: 0, 1754: 0, 1755: 0, 1756: 1, 1757: 1, 1758: 0, 1759: 0, 1760: 1, 1761: 1, 1762: 0, 1763: 0, 1764: 0, 1765: 0, 1766: 0, 1767: 0, 1768: 1, 1769: 1, 1770: 0, 1771: 0, 1772: 0, 1773: 0, 1774: 0, 1775: 0, 1776: 0, 1777: 0, 1778: 1, 1779: 1, 1780: 1, 1781: 1, 1782: 0, 1783: 1, 1784: 0, 1785: 1, 1786: 1, 1787: 1, 1788: 0, 1789: 0, 1790: 1, 1791: 1, 1792: 0, 1793: 0, 1794: 0, 1795: 1, 1796: 1, 1797: 1, 1798: 0, 1799: 0, 1800: 0, 1801: 0, 1802: 1, 1803: 1, 1804: 1, 1805: 1, 1806: 0, 1807: 1, 1808: 0, 1809: 1, 1810: 1, 1811: 1, 1812: 1, 1813: 1, 1814: 1, 1815: 0, 1816: 1, 1817: 0, 1818: 0, 1819: 0, 1820: 1, 1821: 1, 1822: 1, 1823: 1, 1824: 0, 1825: 1, 1826: 1, 1827: 1, 1828: 1, 1829: 0, 1830: 0, 1831: 1, 1832: 1, 1833: 1, 1834: 1, 1835: 0, 1836: 0, 1837: 1, 1838: 0, 1839: 0, 1840: 1, 1841: 0, 1842: 0, 1843: 1, 1844: 0, 1845: 1, 1846: 0, 1847: 1, 1848: 0, 1849: 0, 1850: 1, 1851: 0, 1852: 1, 1853: 1, 1854: 0, 1855: 1, 1856: 0, 1857: 0, 1858: 1, 1859: 1, 1860: 0, 1861: 1, 1862: 0, 1863: 1, 1864: 1, 1865: 0, 1866: 0, 1867: 1, 1868: 0, 1869: 0, 1870: 0, 1871: 1, 1872: 0, 1873: 0, 1874: 1, 1875: 0, 1876: 0, 1877: 0, 1878: 0, 1879: 1, 1880: 1, 1881: 1, 1882: 1, 1883: 1, 1884: 0, 1885: 0, 1886: 1, 1887: 0, 1888: 0, 1889: 1, 1890: 0, 1891: 0, 1892: 0, 1893: 0, 1894: 0, 1895: 1, 1896: 1, 1897: 1, 1898: 1, 1899: 0, 1900: 1, 1901: 1, 1902: 1, 1903: 1, 1904: 0, 1905: 1, 1906: 1, 1907: 0, 1908: 0, 1909: 1, 1910: 1, 1911: 0, 1912: 0, 1913: 1, 1914: 1, 1915: 0, 1916: 0, 1917: 1, 1918: 1, 1919: 0, 1920: 1, 1921: 0, 1922: 1, 1923: 0, 1924: 1, 1925: 1, 1926: 0, 1927: 1, 1928: 1, 1929: 0, 1930: 0, 1931: 0, 1932: 0, 1933: 0, 1934: 0, 1935: 0, 1936: 0, 1937: 0, 1938: 0, 1939: 0, 1940: 0, 1941: 0, 1942: 1, 1943: 0, 1944: 1, 1945: 1, 1946: 1, 1947: 0, 1948: 1, 1949: 1, 1950: 0, 1951: 1, 1952: 1, 1953: 1, 1954: 1, 1955: 1, 1956: 0, 1957: 0, 1958: 0, 1959: 1, 1960: 1, 1961: 0, 1962: 1, 1963: 0, 1964: 1, 1965: 0, 1966: 0, 1967: 1, 1968: 1, 1969: 0, 1970: 0, 1971: 1, 1972: 1, 1973: 0, 1974: 0, 1975: 0, 1976: 0, 1977: 1, 1978: 1, 1979: 0, 1980: 1, 1981: 1, 1982: 1, 1983: 0, 1984: 1, 1985: 0, 1986: 1, 1987: 1, 1988: 1, 1989: 1, 1990: 1, 1991: 0, 1992: 1, 1993: 0, 1994: 0, 1995: 1, 1996: 1, 1997: 0, 1998: 1, 1999: 0, 2000: 1}
-10112.0
-10071.0
dealing G15.txt
device 0 start to train
[n] 200 [C] 1119 weight 800
con_list_range [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200]
average_loss tensor(-576.9189, device='cuda:0', grad_fn=<DivBackward0>) best_loss inf
Epoch 0 Epoch time:  1.6228199005126953 current loss tensor(-1129.2352, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.0106, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-576.9189, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1 Epoch time:  1.6800124645233154 current loss tensor(-1129.4630, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.1017, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.0106, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2 Epoch time:  1.6646480560302734 current loss tensor(-1129.6896, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.1921, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.1017, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3 Epoch time:  1.6675894260406494 current loss tensor(-1129.9148, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.2820, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.1921, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4 Epoch time:  1.806777000427246 current loss tensor(-1130.1387, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.3712, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.2820, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5 Epoch time:  1.666374921798706 current loss tensor(-1130.3611, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.4597, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.3712, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6 Epoch time:  1.6634018421173096 current loss tensor(-1130.5820, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.5475, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.4597, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7 Epoch time:  1.6586031913757324 current loss tensor(-1130.8016, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.6348, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.5475, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8 Epoch time:  1.6649258136749268 current loss tensor(-1131.0197, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.7213, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.6348, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9 Epoch time:  1.661656379699707 current loss tensor(-1131.2363, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.8073, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.7213, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10 Epoch time:  1.6606347560882568 current loss tensor(-1131.4515, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.8926, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.8073, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11 Epoch time:  1.660356044769287 current loss tensor(-1131.6653, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-577.9772, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.8926, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12 Epoch time:  1.6573598384857178 current loss tensor(-1131.8773, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.0610, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-577.9772, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13 Epoch time:  1.6589183807373047 current loss tensor(-1132.0879, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.1442, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.0610, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14 Epoch time:  1.6607954502105713 current loss tensor(-1132.2966, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.2267, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.1442, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15 Epoch time:  1.6783177852630615 current loss tensor(-1132.5039, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.3086, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.2267, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16 Epoch time:  1.6637530326843262 current loss tensor(-1132.7096, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.3898, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.3086, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17 Epoch time:  1.6699819564819336 current loss tensor(-1132.9136, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.4702, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.3898, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18 Epoch time:  1.671818494796753 current loss tensor(-1133.1160, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.5499, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.4702, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19 Epoch time:  1.6698472499847412 current loss tensor(-1133.3165, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.6289, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.5499, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20 Epoch time:  1.6793859004974365 current loss tensor(-1133.5155, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.7072, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.6289, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21 Epoch time:  1.6776137351989746 current loss tensor(-1133.7126, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.7848, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.7072, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22 Epoch time:  1.66074800491333 current loss tensor(-1133.9082, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.8617, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.7848, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23 Epoch time:  1.6622085571289062 current loss tensor(-1134.1023, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-578.9378, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.8617, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24 Epoch time:  1.6581363677978516 current loss tensor(-1134.2944, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.0132, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-578.9378, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25 Epoch time:  1.8610708713531494 current loss tensor(-1134.4849, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.0879, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.0132, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26 Epoch time:  1.8604037761688232 current loss tensor(-1134.6736, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.1619, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.0879, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27 Epoch time:  1.8663034439086914 current loss tensor(-1134.8606, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.2351, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2503.1572, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  3.1817634105682373 current loss tensor(-2503.1763, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  3.2499513626098633 current loss tensor(-2503.1951, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  3.206068754196167 current loss tensor(-2503.2136, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  3.2526416778564453 current loss tensor(-2503.2324, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  3.280712604522705 current loss tensor(-2503.2510, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  3.2936060428619385 current loss tensor(-2503.2693, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  3.223421096801758 current loss tensor(-2503.2878, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  3.1950714588165283 current loss tensor(-2503.3062, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  3.329641342163086 current loss tensor(-2503.3245, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  3.184431552886963 current loss tensor(-2503.3428, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  3.2482988834381104 current loss tensor(-2503.3608, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  3.2366814613342285 current loss tensor(-2503.3792, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  3.22463059425354 current loss tensor(-2503.3972, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  3.2848544120788574 current loss tensor(-2503.4155, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  3.217473268508911 current loss tensor(-2503.4336, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  3.204651355743408 current loss tensor(-2503.4517, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  3.245204448699951 current loss tensor(-2503.4697, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  3.1879501342773438 current loss tensor(-2503.4878, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  3.3300704956054688 current loss tensor(-2503.5054, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  3.1827356815338135 current loss tensor(-2503.5237, device='cuda:2', grad_fn=<SumBackward0>)
dealing G15.txt
device 2 start to train
[n] 200 [C] 111 weight 800
con_list_range [401, 403, 404, 405, 406, 409, 411, 412, 414, 417, 418, 420, 421, 422, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 440, 441, 443, 445, 446, 447, 451, 453, 454, 455, 456, 457, 458, 459, 460, 462, 464, 467, 471, 473, 474, 475, 476, 477, 478, 479, 480, 482, 483, 484, 485, 486, 487, 488, 489, 491, 494, 495, 497, 499, 501, 502, 503, 512, 513, 515, 516, 519, 520, 521, 522, 523, 524, 525, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 544, 546, 547, 548, 549, 551, 554, 556, 557, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 574, 577, 578, 579, 580, 581, 582, 583, 586, 587, 588, 591, 593, 595, 596, 597, 598, 599]
Epoch 0 Epoch time:  0.7354116439819336 current loss tensor(-375.7739, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  0.7724621295928955 current loss tensor(-375.8094, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  0.7937982082366943 current loss tensor(-375.8446, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  0.7896356582641602 current loss tensor(-375.8795, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  0.7874202728271484 current loss tensor(-375.9141, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  0.788456916809082 current loss tensor(-375.9483, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  0.7866179943084717 current loss tensor(-375.9821, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  0.7854709625244141 current loss tensor(-376.0156, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  0.7939705848693848 current loss tensor(-376.0488, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  0.7923214435577393 current loss tensor(-376.0817, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  0.8567824363708496 current loss tensor(-376.1142, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  0.8584814071655273 current loss tensor(-376.1464, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  0.857020378112793 current loss tensor(-376.1783, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  0.8581259250640869 current loss tensor(-376.2098, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  0.8566687107086182 current loss tensor(-376.2410, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  0.8688271045684814 current loss tensor(-376.2719, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  0.8590831756591797 current loss tensor(-376.3024, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  0.8598506450653076 current loss tensor(-376.3326, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  0.8671176433563232 current loss tensor(-376.3625, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  0.8574225902557373 current loss tensor(-376.3920, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  0.8724479675292969 current loss tensor(-376.4212, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  0.8737773895263672 current loss tensor(-376.4501, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  0.8550460338592529 current loss tensor(-376.4786, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  0.8560588359832764 current loss tensor(-376.5069, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  0.8536107540130615 current loss tensor(-376.5348, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  0.8871259689331055 current loss tensor(-376.5623, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  0.8873536586761475 current loss tensor(-376.5896, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  0.891024112701416 current loss tensor(-376.6165, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  0.8940021991729736 current loss tensor(-376.6432, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  0.8937532901763916 current loss tensor(-376.6694, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  0.9028408527374268 current loss tensor(-376.6954, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  0.8876702785491943 current loss tensor(-376.7211, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  0.8964681625366211 current loss tensor(-376.7465, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  0.9083330631256104 current loss tensor(-376.7715, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  0.9278793334960938 current loss tensor(-376.7963, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  0.9247686862945557 current loss tensor(-376.8208, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  0.9148080348968506 current loss tensor(-376.8451, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  0.9284687042236328 current loss tensor(-376.8690, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  0.9287319183349609 current loss tensor(-376.8926, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  0.8871755599975586 current loss tensor(-376.9160, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  0.8883585929870605 current loss tensor(-376.9391, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  0.8896217346191406 current loss tensor(-376.9620, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  0.888812780380249 current loss tensor(-376.9846, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  0.8973667621612549 current loss tensor(-377.0069, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  0.894331693649292 current loss tensor(-377.0289, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  tensor(-2511.8994, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  3.227095127105713 current loss tensor(-2511.9189, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  3.2057251930236816 current loss tensor(-2511.9385, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  3.2026681900024414 current loss tensor(-2511.9580, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  3.2484872341156006 current loss tensor(-2511.9773, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  3.384056568145752 current loss tensor(-2511.9966, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  3.1563754081726074 current loss tensor(-2512.0161, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  3.2289011478424072 current loss tensor(-2512.0352, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  3.1988635063171387 current loss tensor(-2512.0544, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  3.213499069213867 current loss tensor(-2512.0737, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  3.2281253337860107 current loss tensor(-2512.0930, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  3.200166940689087 current loss tensor(-2512.1123, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  3.261570692062378 current loss tensor(-2512.1318, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  3.306835412979126 current loss tensor(-2512.1509, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  3.2404608726501465 current loss tensor(-2512.1704, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  3.2013089656829834 current loss tensor(-2512.1895, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  3.22735333442688 current loss tensor(-2512.2090, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  3.1882119178771973 current loss tensor(-2512.2285, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  3.2065083980560303 current loss tensor(-2512.2480, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  3.197129487991333 current loss tensor(-2512.2676, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  3.200636386871338 current loss tensor(-2512.2871, device='cuda:3', grad_fn=<SumBackward0>)
dealing G15.txt
device 3 start to train
[n] 200 [C] 94 weight 800
con_list_range [601, 602, 603, 604, 605, 606, 609, 610, 611, 612, 614, 616, 620, 623, 624, 625, 626, 632, 635, 637, 638, 639, 644, 645, 647, 649, 651, 653, 654, 659, 661, 665, 666, 667, 668, 672, 673, 674, 675, 676, 679, 680, 681, 683, 684, 685, 686, 687, 689, 691, 692, 696, 698, 700, 701, 702, 706, 708, 710, 714, 716, 717, 718, 719, 720, 721, 723, 725, 727, 728, 730, 731, 732, 735, 738, 740, 741, 743, 744, 749, 751, 752, 754, 755, 756, 757, 758, 761, 762, 763, 764, 765, 766, 767, 769, 770, 771, 772, 774, 775, 776, 777, 778, 779, 780, 783, 785, 786, 787, 788, 792, 794, 795, 796]
Epoch 0 Epoch time:  0.6308834552764893 current loss tensor(-322.8359, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  0.6623532772064209 current loss tensor(-322.8434, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  0.68404221534729 current loss tensor(-322.8506, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  0.686084508895874 current loss tensor(-322.8576, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  0.6798863410949707 current loss tensor(-322.8643, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  0.6821339130401611 current loss tensor(-322.8708, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  0.6796483993530273 current loss tensor(-322.8771, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  0.6809203624725342 current loss tensor(-322.8832, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  0.6828069686889648 current loss tensor(-322.8890, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  0.6832234859466553 current loss tensor(-322.8946, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  0.6799864768981934 current loss tensor(-322.9000, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  0.6786098480224609 current loss tensor(-322.9052, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  0.6792335510253906 current loss tensor(-322.9101, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  0.6804070472717285 current loss tensor(-322.9148, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  0.6783380508422852 current loss tensor(-322.9194, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  0.6911900043487549 current loss tensor(-322.9237, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  0.6841175556182861 current loss tensor(-322.9278, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  0.6834909915924072 current loss tensor(-322.9317, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  0.6897850036621094 current loss tensor(-322.9355, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  0.6836771965026855 current loss tensor(-322.9390, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  0.6938357353210449 current loss tensor(-322.9423, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  0.6973061561584473 current loss tensor(-322.9455, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  0.6812865734100342 current loss tensor(-322.9485, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  0.6783852577209473 current loss tensor(-322.9513, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  0.6790714263916016 current loss tensor(-322.9539, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  0.7127096652984619 current loss tensor(-322.9564, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  0.7142162322998047 current loss tensor(-322.9586, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  0.7172563076019287 current loss tensor(-322.9607, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  0.7139854431152344 current loss tensor(-322.9626, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  0.7327444553375244 current loss tensor(-322.9644, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  0.7309777736663818 current loss tensor(-322.9660, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  0.7132225036621094 current loss tensor(-322.9674, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  0.7213289737701416 current loss tensor(-322.9688, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  0.8729054927825928 current loss tensor(-322.9699, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  0.7514398097991943 current loss tensor(-322.9709, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  0.752500057220459 current loss tensor(-322.9717, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  0.7435994148254395 current loss tensor(-322.9725, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  0.751572847366333 current loss tensor(-322.9731, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  0.7550907135009766 current loss tensor(-322.9734, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  0.7104711532592773 current loss tensor(-322.9738, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  0.7149167060852051 current loss tensor(-322.9739, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  0.7117667198181152 current loss tensor(-322.9740, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  0.7150611877441406 current loss tensor(-322.9739, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  0.7195007801055908 current loss tensor(-322.9737, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  0.721409797668457 current loss tensor(-322.9733, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  0.7139344215393066 current loss tensor(-322.9728, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  current loss tensor(-2454.1851, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  3.254784345626831 current loss tensor(-2454.2063, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  3.2440779209136963 current loss tensor(-2454.2275, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  3.295787811279297 current loss tensor(-2454.2483, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  3.1747043132781982 current loss tensor(-2454.2695, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  3.188239336013794 current loss tensor(-2454.2903, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  3.217251777648926 current loss tensor(-2454.3113, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  3.2422521114349365 current loss tensor(-2454.3320, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  3.3489415645599365 current loss tensor(-2454.3530, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  3.129584312438965 current loss tensor(-2454.3740, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  3.216916799545288 current loss tensor(-2454.3950, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  3.247316837310791 current loss tensor(-2454.4158, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  3.2028470039367676 current loss tensor(-2454.4365, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  3.224837064743042 current loss tensor(-2454.4575, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  3.2042269706726074 current loss tensor(-2454.4780, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  3.223688840866089 current loss tensor(-2454.4990, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  3.331113815307617 current loss tensor(-2454.5200, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  3.1696293354034424 current loss tensor(-2454.5410, device='cuda:1', grad_fn=<SumBackward0>)
dealing G15.txt
device 1 start to train
[n] 200 [C] 212 weight 800
con_list_range [201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 348, 350, 351, 353, 354, 355, 356, 358, 360, 362, 363, 364, 365, 366, 367, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399]
Epoch 0 Epoch time:  0.912804365158081 current loss tensor(-479.8310, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  0.9540603160858154 current loss tensor(-479.9268, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  0.9703569412231445 current loss tensor(-480.0220, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  0.9765543937683105 current loss tensor(-480.1166, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  0.9742865562438965 current loss tensor(-480.2108, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  0.9713644981384277 current loss tensor(-480.3043, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  0.9718785285949707 current loss tensor(-480.3973, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  0.9701023101806641 current loss tensor(-480.4897, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  0.9694511890411377 current loss tensor(-480.5815, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  0.9679632186889648 current loss tensor(-480.6728, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  0.9632515907287598 current loss tensor(-480.7634, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  0.9769816398620605 current loss tensor(-480.8534, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  0.9697034358978271 current loss tensor(-480.9428, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  0.9637691974639893 current loss tensor(-481.0317, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  0.9683606624603271 current loss tensor(-481.1199, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  0.9863417148590088 current loss tensor(-481.2075, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  0.9676485061645508 current loss tensor(-481.2946, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  0.9718039035797119 current loss tensor(-481.3810, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  0.9847817420959473 current loss tensor(-481.4668, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  0.9724311828613281 current loss tensor(-481.5520, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  0.9823732376098633 current loss tensor(-481.6365, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  0.9864459037780762 current loss tensor(-481.7204, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  0.9657914638519287 current loss tensor(-481.8037, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  0.9647066593170166 current loss tensor(-481.8863, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  0.9681282043457031 current loss tensor(-481.9681, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  1.000952959060669 current loss tensor(-482.0493, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  0.9996094703674316 current loss tensor(-482.1298, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  1.0018231868743896 current loss tensor(-482.2096, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  0.9958710670471191 current loss tensor(-482.2888, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  1.004606008529663 current loss tensor(-482.3674, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  1.0104012489318848 current loss tensor(-482.4453, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  1.0013360977172852 current loss tensor(-482.5225, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  1.0044851303100586 current loss tensor(-482.5991, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  1.0188896656036377 current loss tensor(-482.6750, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  1.0418682098388672 current loss tensor(-482.7504, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  1.0425927639007568 current loss tensor(-482.8250, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  1.0377633571624756 current loss tensor(-482.8990, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  1.044400691986084 current loss tensor(-482.9724, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  1.0470709800720215 current loss tensor(-483.0451, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  0.9968986511230469 current loss tensor(-483.1172, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  0.9991450309753418 current loss tensor(-483.1888, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  0.9951934814453125 current loss tensor(-483.2596, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  0.9971020221710205 current loss tensor(-483.3299, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  1.0073401927947998 current loss tensor(-483.3995, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  1.007265567779541 current loss tensor(-483.4684, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  1.0009472370147705 current loss tensor(-483.5367, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 46 tensor(-579.1619, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28 Epoch time:  1.8634693622589111 current loss tensor(-1135.0458, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.3076, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.2351, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29 Epoch time:  1.8696393966674805 current loss tensor(-1135.2292, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.3794, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.3076, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30 Epoch time:  1.8765482902526855 current loss tensor(-1135.4109, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.4505, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.3794, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31 Epoch time:  1.8654091358184814 current loss tensor(-1135.5911, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.5210, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.4505, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32 Epoch time:  1.8721990585327148 current loss tensor(-1135.7695, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.5906, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.5210, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33 Epoch time:  1.887831211090088 current loss tensor(-1135.9460, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.6597, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.5906, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34 Epoch time:  1.9044888019561768 current loss tensor(-1136.1211, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.7280, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.6597, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35 Epoch time:  1.9040570259094238 current loss tensor(-1136.2944, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.7957, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.7280, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36 Epoch time:  1.892651081085205 current loss tensor(-1136.4659, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.8625, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.7957, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37 Epoch time:  1.895477533340454 current loss tensor(-1136.6359, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.9288, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.8625, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38 Epoch time:  2.083631992340088 current loss tensor(-1136.8041, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-579.9944, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.9288, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39 Epoch time:  1.8587465286254883 current loss tensor(-1136.9705, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.0593, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-579.9944, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40 Epoch time:  1.8648033142089844 current loss tensor(-1137.1353, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.1235, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.0593, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41 Epoch time:  1.8595645427703857 current loss tensor(-1137.2983, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.1870, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.1235, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42 Epoch time:  1.857161521911621 current loss tensor(-1137.4597, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.2499, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.1870, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43 Epoch time:  1.898611068725586 current loss tensor(-1137.6195, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.3121, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.2499, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44 Epoch time:  1.8609628677368164 current loss tensor(-1137.7777, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.3737, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.3121, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45 Epoch time:  1.8648242950439453 current loss tensor(-1137.9342, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.4345, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.3737, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46 Epoch time:  1.8560993671417236 current loss tensor(-1138.0891, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.4948, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.4345, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47 Epoch time:  1.8558731079101562 current loss tensor(-1138.2426, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.5543, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.4948, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48 Epoch time:  1.8608026504516602 current loss tensor(-1138.3944, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.6133, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.5543, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49 Epoch time:  1.866844892501831 current loss tensor(-1138.5447, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.6716, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.6133, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 50 Epoch time:  1.890366554260254 current loss tensor(-1138.6932, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.7292, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.6716, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 51 Epoch time:  1.877549648284912 current loss tensor(-1138.8401, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.7863, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.7292, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 52 Epoch time:  1.8935701847076416 current loss tensor(-1138.9856, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.8427, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.7863, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 53 Epoch time:  1.8822107315063477 current loss tensor(-1139.1293, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.8984, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.8427, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 54 Epoch time:  1.8962020874023438 current loss tensor(-1139.2715, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-580.9537, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.8984, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 55 Epoch time:  1.8621940612792969 current loss tensor(-1139.4122, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.0082, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-580.9537, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 56 Epoch time:  1.8588109016418457 current loss tensor(-1139.5513, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.0622, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.0082, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 57 Epoch time:  1.8578848838806152 current loss tensor(-1139.6888, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.1155, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.0622, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 58 Epoch time:  1.8588624000549316 current loss tensor(-1139.8248, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.1682, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.1155, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 59 Epoch time:  1.8642582893371582 current loss tensor(-1139.9591, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.2204, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.1682, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 60 Epoch time:  1.8798224925994873 current loss tensor(-1140.0920, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.2720, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.2204, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 61 Epoch time:  1.8932719230651855 current loss tensor(-1140.2234, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.3229, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.2720, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 62 Epoch time:  1.8995463848114014 current loss tensor(-1140.3533, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.3734, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.3229, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 63 Epoch time:  1.8580992221832275 current loss tensor(-1140.4817, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.4232, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.3734, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 64 Epoch time:  1.8655052185058594 current loss tensor(-1140.6086, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.4725, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.4232, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 65 Epoch time:  1.8679027557373047 current loss tensor(-1140.7343, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.5213, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.4725, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 66 Epoch time:  1.8858163356781006 current loss tensor(-1140.8584, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.5695, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.5213, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 67 Epoch time:  1.868664026260376 current loss tensor(-1140.9811, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.6171, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.5695, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 68 Epoch time:  1.8674607276916504 current loss tensor(-1141.1023, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.6642, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.6171, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 69 Epoch time:  1.8793885707855225 current loss tensor(-1141.2219, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.7108, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.6642, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 70 Epoch time:  1.8929712772369385 current loss tensor(-1141.3402, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.7568, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.7108, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 71 Epoch time:  1.8594443798065186 current loss tensor(-1141.4570, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.8022, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.7568, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 72 Epoch time:  1.8606574535369873 current loss tensor(-1141.5725, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.8472, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.8022, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 73 Epoch time:  1.8573439121246338 current loss tensor(-1141.6863, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.8916, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.8472, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 74 Epoch time:  1.8554842472076416 current loss tensor(-1141.7990, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.9355, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.8916, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 75 Epoch time:  1.8625009059906006 current loss tensor(-1141.9100, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-581.9789, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.9355, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 76 Epoch time:  1.8710687160491943 current loss tensor(-1142.0199, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.0219, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-581.9789, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 77 Epoch time:  2.05027174949646 current loss tensor(-1142.1284, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.0642, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.0219, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 78 Epoch time:  1.901503086090088 current loss tensor(-1142.2356, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.1061, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.0642, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 79 Epoch time:  1.8947041034698486 current loss tensor(-1142.3413, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.1476, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.1061, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 80 Epoch time:  1.8641605377197266 current loss tensor(-1142.4459, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.1885, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.1476, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 81 Epoch time:  1.8662621974945068 current loss tensor(-1142.5492, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.2289, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.1885, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 82 Epoch time:  1.901660680770874 current loss tensor(-1142.6511, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.2689, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.2289, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 83 Epoch time:  1.878525972366333 current loss tensor(-1142.7520, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.3085, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.2689, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 84 Epoch time:  1.8887133598327637 current loss tensor(-1142.8516, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.3475, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.3085, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 85 Epoch time:  1.9174838066101074 current loss tensor(-1142.9500, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.3862, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.3475, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 86 Epoch time:  1.9026823043823242 current loss tensor(-1143.0471, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.4243, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.3862, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 87 Epoch time:  1.920440435409546 current loss tensor(-1143.1429, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.4620, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.4243, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 88 Epoch time:  1.8586034774780273 current loss tensor(-1143.2378, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.4993, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.4620, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 89 Epoch time:  1.8614275455474854 current loss tensor(-1143.3313, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.5361, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.4993, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 90 Epoch time:  1.955979347229004 current loss tensor(-1143.4236, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.5724, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.5361, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 91 Epoch time:  1.8626222610473633 current loss tensor(-1143.5146, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.6085, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.5724, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 92 Epoch time:  1.8727357387542725 current loss tensor(-1143.6049, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.6440, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.6085, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 93 Epoch time:  1.8912959098815918 current loss tensor(-1143.6938, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.6791, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.6440, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 94 Epoch time:  1.8643200397491455 current loss tensor(-1143.7816, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.7137, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.6791, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 95 Epoch time:  1.8704686164855957 current loss tensor(-1143.8684, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.7480, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.7137, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 96 Epoch time:  1.8694591522216797 current loss tensor(-1143.9539, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.7820, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.7480, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 97 Epoch time:  1.8726181983947754 current loss tensor(-1144.0385, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.8156, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.7820, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 98 Epoch time:  1.9032423496246338 current loss tensor(-1144.1219, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-582.8487, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-582.8156, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 99 Epoch time:  1.9095845222473145 current loss tensor(-1144.2043, device='cuda:0', grad_fn=<SumBackward0>)
best_out [0.45897505 0.4448186  0.36812258 0.3556981  0.40191054 0.36809292
 0.46004486 0.45179716 0.42837968 0.4540829  0.43220338 0.4672199
 0.50079596 0.3882606  0.4580677  0.41176483 0.40136376 0.39749378
 0.45771062 0.38896412 0.45908728 0.44927838 0.33579427 0.35160825
 0.49524856 0.44134277 0.4081668  0.42253786 0.43124336 0.4296585
 0.52684444 0.4907336  0.50129336 0.45536795 0.41452107 0.39598215
 0.53671896 0.43356466 0.42202568 0.35416272 0.46280923 0.445481
 0.40338987 0.46650982 0.448394   0.41248128 0.49455532 0.45018032
 0.42858234 0.38601643 0.46778688 0.4444916  0.48095316 0.46956375
 0.41065544 0.37599203 0.39336953 0.32768685 0.50087965 0.41538742
 0.45422533 0.44156742 0.42580694 0.49638426 0.49041772 0.49465957
 0.41109818 0.47606382 0.40165007 0.45038712 0.49645552 0.5151353
 0.5194615  0.48654714 0.47562784 0.51977503 0.49364093 0.5079242
 0.42667946 0.502879   0.5092799  0.4447857  0.48069552 0.45731074
 0.5246829  0.42163834 0.3843717  0.3109324  0.4609985  0.488765
 0.49011505 0.44795913 0.41905743 0.37521082 0.4804614  0.3830022
 0.5249087  0.4674117  0.46391442 0.39866933 0.42129758 0.3253316
 0.48169264 0.5243346  0.50463605 0.46194544 0.37886807 0.46182665
 0.4757163  0.3921722  0.4310389  0.34354463 0.42943192 0.42817536
 0.50110686 0.52146184 0.47403502 0.5385275  0.47403377 0.44069892
 0.44266173 0.48032174 0.48185673 0.35989693 0.41347235 0.4744207
 0.4696287  0.3706819  0.48431656 0.46445304 0.4495019  0.5283001
 0.53511095 0.4506146  0.45953724 0.53578466 0.49936816 0.46803477
 0.36949193 0.5379556  0.47698253 0.47011954 0.5641257  0.47500342
 0.47179046 0.48912403 0.42930615 0.40367496 0.42374206 0.4004134
 0.47812766 0.36685798 0.46576396 0.43075362 0.45418137 0.49423832
 0.46055552 0.48235086 0.5450537  0.45274848 0.4572522  0.5267202
 0.5152101  0.4122547  0.46195024 0.46915302 0.41262233 0.49656084
 0.33724806 0.57339156 0.48786855 0.4031435  0.48245788 0.51382047
 0.4107038  0.47262782 0.4455928  0.36873242 0.5209367  0.46876827
 0.41728348 0.37366045 0.56034577 0.5477577  0.39373448 0.46530646
 0.47511905 0.4348604  0.39555338 0.50693434 0.45370862 0.4313026
 0.44378674 0.50585586 0.4164897  0.37192553 0.5053856  0.40558195
 0.39103246 0.51888776 0.27987024 0.78459096 0.11836109 0.39453378
 0.41664207 0.19425204 0.74074316 0.61325985 0.32907104 0.8999142
 0.57860357 0.40387118 0.37636524 0.73105854 0.632612   0.35341257
 0.53844637 0.73105854 0.73105854 0.38368666 0.32859546 0.6022387
 0.29363215 0.73105854 0.5683645  0.21239288 0.32038632 0.52093315
 0.44580522 0.5130535  0.65701324 0.4090114  0.72857535 0.4439457
 0.42237818 0.27677724 0.1808657  0.47343802 0.48944616 0.2395708
 0.37245172 0.6308267  0.17351852 0.6432357  0.35064757 0.07803309
 0.33809748 0.6462252  0.08169287 0.06565444 0.6060334  0.4519133
 0.8330741  0.6171592  0.73105854 0.4808368  0.09612065 0.22600234
 0.62215954 0.57768357 0.5191702  0.4979416  0.5646537  0.73105854
 0.30253395 0.60884774 0.1876315  0.25846928 0.33382818 0.06544759
 0.4329987  0.36790782 0.30314115 0.44545126 0.4229826  0.7680148
 0.73105854 0.7259945  0.49653676 0.4350567  0.73105854 0.79681265
 0.6308267  0.47667512 0.4337216  0.29157776 0.43603805 0.3801832
 0.33794025 0.68463916 0.34847903 0.24492626 0.2556217  0.24167776
 0.32665488 0.60506517 0.69590735 0.47242793 0.8464623  0.32655135
 0.2854333  0.43195218 0.5696186  0.59093416 0.65372926 0.627311
 0.73105854 0.26922888 0.45923436 0.20773187 0.40288654 0.23410188
 0.551772   0.4781634  0.41439426 0.90436137 0.60103625 0.81726
 0.53050023 0.40849176 0.28867754 0.21113496 0.52139866 0.40593383
 0.20773187 0.09409042 0.5221368  0.4889647  0.36640596 0.42648488
 0.25068194 0.13737838 0.43778917 0.73105854 0.41448036 0.6525074
 0.90468913 0.90468913 0.05754922 0.4425127  0.7595356  0.7723605
 0.73105854 0.46515247 0.6483075  0.40929416 0.40467513 0.5807657
 0.73105854 0.13816428 0.65949833 0.73105854 0.32558927 0.7863479
 0.4229826  0.28538448 0.73105854 0.66766244 0.73105854 0.6651121
 0.73105854 0.81176555 0.61992365 0.5726858  0.3544937  0.637216
 0.28367093 0.73105854 0.4781634  0.65731996 0.7806338  0.18230896
 0.80134    0.73105854 0.33030793 0.3296595  0.5409283  0.19279273
 0.5980789  0.50734687 0.03775818 0.65587044 0.83774006 0.36549044
 0.53688645 0.6470674  0.32932472 0.29218596 0.24167776 0.63074726
 0.49406832 0.53844225 0.30557054 0.44986707 0.42654127 0.296109
 0.23717359 0.35113457 0.61992365 0.73105854 0.40663365 0.73105854
 0.24572511 0.07543086 0.12160487 0.66448134 0.73105854 0.73105854
 0.182603   0.73105854 0.5592732  0.40538839 0.73105854 0.88328195
 0.73105854 0.73105854 0.11599885 0.3544607  0.73105854 0.42899898
 0.3788165  0.4597321  0.73105854 0.03667118 0.7449181  0.18903683
 0.17757836 0.61597127 0.5407539  0.3384705  0.94823015 0.7807048
 0.9013362  0.26655874 0.27150208 0.2582699  0.45311654 0.35586688
 0.73105854 0.41067296 0.64894867 0.73105854 0.65212196 0.73105854
 0.35165143 0.08073292 0.5568027  0.73105854 0.73105854 0.73105854
 0.5671253  0.73105854 0.35653856 0.37126973 0.5018671  0.28485924
 0.24700983 0.03409069 0.83639276 0.8390527  0.73105854 0.47052383
 0.73105854 0.912141   0.73105854 0.73105854 0.02586381 0.73105854
 0.73105854 0.73105854 0.80591404 0.73105854 0.3065418  0.35836414
 0.47521105 0.9020744  0.69673055 0.65921456 0.4995141  0.24572511
 0.73105854 0.1550082  0.82667273 0.6649105  0.8427539  0.88328195
 0.24710946 0.5601727  0.32297298 0.73105854 0.39493844 0.73105854
 0.73105854 0.06973212 0.49126273 0.73105854 0.4086046  0.73105854
 0.6017961  0.73105854 0.37063414 0.02985443 0.60185975 0.73105854
 0.73105854 0.73105854 0.73105854 0.73105854 0.73105854 0.73105854
 0.73105854 0.12513974 0.8427539  0.73105854 0.15125048 0.90461206
 0.73105854 0.73105854 0.7677665  0.7449181  0.35347882 0.5038929
 0.35519314 0.2662319  0.21426407 0.73105854 0.73105854 0.83639276
 0.39797887 0.73105854 0.35931113 0.0410576  0.5774876  0.9199544
 0.20268181 0.73227483 0.4470326  0.62199306 0.01805327 0.5601727
 0.7832146  0.56479275 0.73105854 0.48581553 0.73105854 0.60456574
 0.43542874 0.40118083 0.29239887 0.73105854 0.63172954 0.73105854
 0.73105854 0.23569857 0.73105854 0.50738144 0.1571882  0.73105854
 0.73105854 0.66527593 0.6616286  0.86299473 0.58647907 0.10841201
 0.32608098 0.557749   0.3366321  0.365837   0.10513752 0.5105442
 0.6769609  0.03352332 0.73105854 0.4233596  0.73105854 0.73105854
 0.49702436 0.04395753 0.5705422  0.7716905  0.41328767 0.20429711
 0.837406   0.73105854 0.73105854 0.857626   0.12132426 0.47826433
 0.73105854 0.73105854 0.5891497  0.73105854 0.11548468 0.73105854
 0.1417078  0.24620987 0.4518917  0.47826433 0.5798992  0.73105854
 0.38344333 0.86903894 0.2833099  0.10296687 0.06029978 0.29225728
 0.73105854 0.73105854 0.24532455 0.6501822  0.5929324  0.19168995
 0.73105854 0.5554105  0.73105854 0.5110522  0.73105854 0.73105854
 0.73105854 0.79122776 0.73105854 0.73105854 0.0582609  0.01106284
 0.81360054 0.19777928 0.73105854 0.73105854 0.73105854 0.73105854
 0.73105854 0.59518045 0.73105854 0.73105854 0.27313298 0.73105854
 0.12698314 0.532723   0.47851667 0.73105854 0.73105854 0.73105854
 0.73105854 0.5378977  0.39317018 0.73105854 0.54137117 0.73105854
 0.1740233  0.73105854 0.5311987  0.73105854 0.52608275 0.70702
 0.73105854 0.73105854 0.73105854 0.73105854 0.8449821  0.73105854
 0.32465452 0.73105854 0.73105854 0.73105854 0.15863821 0.8712057
 0.527127   0.25659308 0.73105854 0.73105854 0.73105854 0.6366713
 0.19916715 0.22854209 0.22073217 0.53956383 0.73105854 0.73105854
 0.4143015  0.64251804 0.43943846 0.73105854 0.9114645  0.52334225
 0.89491284 0.4266256  0.521388   0.73105854 0.42045623 0.73105854
 0.53486216 0.61528504 0.73105854 0.73105854 0.73105854 0.39418265
 0.73105854 0.20970894 0.73105854 0.6846249  0.28252113 0.02977181
 0.73105854 0.73105854 0.73105854 0.8175861  0.73105854 0.19416368
 0.73105854 0.13146847 0.73105854 0.73105854 0.73105854 0.0370627
 0.73105854 0.78715694 0.6835887  0.66420585 0.81633425 0.16922782
 0.58526295 0.73105854 0.42708948 0.73105854 0.51776403 0.73105854
 0.48894143 0.13160953 0.73105854 0.51956207 0.25521734 0.4266256
 0.73105854 0.73105854 0.20207784 0.73105854 0.73105854 0.6778574
 0.73105854 0.9114645  0.6472197  0.73105854 0.89491284 0.39565086
 0.73105854 0.73105854 0.73105854 0.73105854 0.1052024  0.73105854
 0.76413023 0.10296687 0.73105854 0.2145954  0.06042095 0.10111712
 0.6472197  0.8248322  0.73105854 0.73105854 0.74690086 0.6846249
 0.5588873  0.2618082  0.77014095 0.50280863 0.29890725 0.73105854
 0.73218477 0.8205148  0.62791294 0.02077466 0.73105854 0.5686605
 0.38341647 0.07967994 0.72650486 0.07176021 0.8889074  0.76562375
 0.73105854 0.73105854 0.61528504 0.73105854 0.27431458 0.8635132
 0.07747406 0.2931006  0.73105854 0.73105854 0.73105854 0.65528613
 0.73105854 0.42103785 0.66420585 0.7579673  0.73105854 0.73105854
 0.73105854 0.73105854]
info_input_total 800 weights 800 total_C 4660
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
-2395
res {1: 0, 2: 1, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0, 8: 1, 9: 1, 10: 1, 11: 1, 12: 0, 13: 1, 14: 1, 15: 0, 16: 0, 17: 1, 18: 0, 19: 0, 20: 0, 21: 0, 22: 1, 23: 0, 24: 0, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 0, 31: 0, 32: 0, 33: 1, 34: 0, 35: 0, 36: 1, 37: 0, 38: 0, 39: 0, 40: 0, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 0, 49: 1, 50: 1, 51: 0, 52: 1, 53: 0, 54: 1, 55: 0, 56: 0, 57: 1, 58: 1, 59: 1, 60: 1, 61: 0, 62: 1, 63: 1, 64: 0, 65: 1, 66: 0, 67: 0, 68: 1, 69: 0, 70: 1, 71: 0, 72: 1, 73: 0, 74: 1, 75: 0, 76: 0, 77: 1, 78: 1, 79: 0, 80: 0, 81: 0, 82: 0, 83: 0, 84: 1, 85: 0, 86: 0, 87: 0, 88: 1, 89: 1, 90: 1, 91: 1, 92: 1, 93: 0, 94: 1, 95: 1, 96: 1, 97: 0, 98: 1, 99: 0, 100: 0, 101: 0, 102: 0, 103: 0, 104: 0, 105: 0, 106: 1, 107: 0, 108: 1, 109: 0, 110: 1, 111: 1, 112: 0, 113: 1, 114: 1, 115: 1, 116: 0, 117: 0, 118: 1, 119: 1, 120: 1, 121: 1, 122: 0, 123: 0, 124: 0, 125: 1, 126: 0, 127: 1, 128: 0, 129: 0, 130: 1, 131: 1, 132: 1, 133: 0, 134: 0, 135: 0, 136: 0, 137: 0, 138: 1, 139: 0, 140: 0, 141: 1, 142: 1, 143: 1, 144: 1, 145: 0, 146: 0, 147: 0, 148: 1, 149: 0, 150: 1, 151: 1, 152: 0, 153: 0, 154: 0, 155: 0, 156: 0, 157: 0, 158: 1, 159: 0, 160: 1, 161: 1, 162: 1, 163: 0, 164: 0, 165: 0, 166: 1, 167: 1, 168: 1, 169: 0, 170: 1, 171: 0, 172: 1, 173: 0, 174: 0, 175: 1, 176: 0, 177: 1, 178: 0, 179: 1, 180: 0, 181: 1, 182: 1, 183: 1, 184: 1, 185: 1, 186: 0, 187: 1, 188: 1, 189: 1, 190: 1, 191: 0, 192: 0, 193: 0, 194: 1, 195: 1, 196: 1, 197: 0, 198: 1, 199: 1, 200: 0, 201: 0, 202: 1, 203: 0, 204: 1, 205: 1, 206: 0, 207: 1, 208: 1, 209: 0, 210: 1, 211: 1, 212: 1, 213: 0, 214: 1, 215: 1, 216: 0, 217: 1, 218: 1, 219: 1, 220: 0, 221: 0, 222: 1, 223: 0, 224: 1, 225: 1, 226: 1, 227: 1, 228: 1, 229: 0, 230: 1, 231: 0, 232: 0, 233: 1, 234: 0, 235: 1, 236: 0, 237: 0, 238: 0, 239: 0, 240: 0, 241: 0, 242: 1, 243: 0, 244: 1, 245: 0, 246: 0, 247: 1, 248: 1, 249: 0, 250: 0, 251: 1, 252: 1, 253: 1, 254: 1, 255: 1, 256: 0, 257: 0, 258: 0, 259: 1, 260: 0, 261: 0, 262: 1, 263: 0, 264: 1, 265: 1, 266: 1, 267: 0, 268: 0, 269: 0, 270: 0, 271: 1, 272: 1, 273: 0, 274: 1, 275: 1, 276: 0, 277: 0, 278: 1, 279: 0, 280: 1, 281: 1, 282: 1, 283: 1, 284: 0, 285: 0, 286: 1, 287: 1, 288: 0, 289: 1, 290: 0, 291: 0, 292: 0, 293: 0, 294: 0, 295: 1, 296: 1, 297: 0, 298: 0, 299: 1, 300: 0, 301: 0, 302: 1, 303: 0, 304: 1, 305: 1, 306: 0, 307: 0, 308: 0, 309: 1, 310: 0, 311: 0, 312: 0, 313: 1, 314: 1, 315: 0, 316: 1, 317: 1, 318: 1, 319: 0, 320: 0, 321: 0, 322: 0, 323: 1, 324: 1, 325: 0, 326: 0, 327: 0, 328: 1, 329: 0, 330: 0, 331: 0, 332: 0, 333: 1, 334: 0, 335: 0, 336: 1, 337: 1, 338: 1, 339: 0, 340: 0, 341: 1, 342: 1, 343: 1, 344: 0, 345: 0, 346: 0, 347: 1, 348: 1, 349: 1, 350: 0, 351: 1, 352: 0, 353: 0, 354: 0, 355: 0, 356: 0, 357: 1, 358: 0, 359: 1, 360: 1, 361: 0, 362: 1, 363: 1, 364: 1, 365: 1, 366: 1, 367: 0, 368: 1, 369: 1, 370: 0, 371: 1, 372: 0, 373: 1, 374: 1, 375: 0, 376: 0, 377: 0, 378: 0, 379: 0, 380: 0, 381: 0, 382: 1, 383: 0, 384: 0, 385: 0, 386: 1, 387: 0, 388: 0, 389: 0, 390: 1, 391: 0, 392: 1, 393: 0, 394: 0, 395: 0, 396: 0, 397: 0, 398: 0, 399: 1, 400: 1, 401: 0, 402: 1, 403: 0, 404: 0, 405: 0, 406: 1, 407: 0, 408: 1, 409: 0, 410: 1, 411: 1, 412: 0, 413: 1, 414: 1, 415: 1, 416: 1, 417: 0, 418: 0, 419: 1, 420: 0, 421: 1, 422: 0, 423: 1, 424: 0, 425: 1, 426: 0, 427: 0, 428: 0, 429: 0, 430: 1, 431: 1, 432: 0, 433: 1, 434: 1, 435: 0, 436: 1, 437: 0, 438: 0, 439: 1, 440: 0, 441: 1, 442: 1, 443: 1, 444: 1, 445: 0, 446: 0, 447: 1, 448: 1, 449: 0, 450: 1, 451: 0, 452: 1, 453: 0, 454: 0, 455: 1, 456: 1, 457: 0, 458: 0, 459: 0, 460: 1, 461: 0, 462: 0, 463: 1, 464: 1, 465: 1, 466: 1, 467: 0, 468: 0, 469: 0, 470: 1, 471: 1, 472: 0, 473: 0, 474: 1, 475: 0, 476: 1, 477: 1, 478: 0, 479: 0, 480: 0, 481: 1, 482: 0, 483: 0, 484: 0, 485: 0, 486: 1, 487: 1, 488: 1, 489: 0, 490: 1, 491: 1, 492: 1, 493: 1, 494: 0, 495: 1, 496: 1, 497: 1, 498: 1, 499: 1, 500: 1, 501: 0, 502: 0, 503: 1, 504: 1, 505: 0, 506: 1, 507: 0, 508: 1, 509: 1, 510: 0, 511: 1, 512: 0, 513: 1, 514: 1, 515: 0, 516: 1, 517: 1, 518: 1, 519: 1, 520: 0, 521: 0, 522: 0, 523: 1, 524: 0, 525: 0, 526: 1, 527: 0, 528: 1, 529: 0, 530: 1, 531: 0, 532: 0, 533: 0, 534: 1, 535: 0, 536: 0, 537: 1, 538: 0, 539: 0, 540: 0, 541: 1, 542: 0, 543: 0, 544: 0, 545: 1, 546: 1, 547: 1, 548: 1, 549: 0, 550: 1, 551: 0, 552: 1, 553: 1, 554: 0, 555: 1, 556: 0, 557: 0, 558: 1, 559: 0, 560: 0, 561: 1, 562: 0, 563: 1, 564: 0, 565: 0, 566: 0, 567: 0, 568: 0, 569: 0, 570: 1, 571: 0, 572: 0, 573: 1, 574: 0, 575: 1, 576: 1, 577: 1, 578: 0, 579: 0, 580: 1, 581: 0, 582: 0, 583: 1, 584: 1, 585: 1, 586: 1, 587: 1, 588: 1, 589: 1, 590: 1, 591: 1, 592: 0, 593: 0, 594: 1, 595: 0, 596: 1, 597: 0, 598: 1, 599: 1, 600: 1, 601: 0, 602: 1, 603: 1, 604: 0, 605: 0, 606: 0, 607: 1, 608: 1, 609: 0, 610: 0, 611: 1, 612: 1, 613: 1, 614: 1, 615: 1, 616: 1, 617: 0, 618: 1, 619: 1, 620: 1, 621: 1, 622: 1, 623: 0, 624: 0, 625: 1, 626: 0, 627: 0, 628: 1, 629: 1, 630: 1, 631: 0, 632: 1, 633: 0, 634: 1, 635: 1, 636: 1, 637: 1, 638: 0, 639: 1, 640: 1, 641: 1, 642: 1, 643: 1, 644: 1, 645: 1, 646: 1, 647: 1, 648: 1, 649: 0, 650: 1, 651: 1, 652: 0, 653: 1, 654: 1, 655: 1, 656: 1, 657: 1, 658: 1, 659: 1, 660: 1, 661: 0, 662: 1, 663: 1, 664: 1, 665: 0, 666: 1, 667: 1, 668: 0, 669: 1, 670: 1, 671: 1, 672: 1, 673: 0, 674: 1, 675: 1, 676: 1, 677: 1, 678: 1, 679: 0, 680: 1, 681: 0, 682: 0, 683: 1, 684: 1, 685: 1, 686: 0, 687: 1, 688: 1, 689: 0, 690: 1, 691: 1, 692: 0, 693: 1, 694: 1, 695: 1, 696: 0, 697: 1, 698: 0, 699: 1, 700: 1, 701: 0, 702: 1, 703: 1, 704: 1, 705: 1, 706: 1, 707: 1, 708: 0, 709: 1, 710: 0, 711: 1, 712: 0, 713: 1, 714: 0, 715: 1, 716: 1, 717: 1, 718: 1, 719: 1, 720: 0, 721: 0, 722: 0, 723: 1, 724: 1, 725: 0, 726: 1, 727: 1, 728: 0, 729: 1, 730: 1, 731: 1, 732: 1, 733: 1, 734: 1, 735: 0, 736: 1, 737: 1, 738: 1, 739: 1, 740: 1, 741: 1, 742: 1, 743: 1, 744: 0, 745: 1, 746: 1, 747: 1, 748: 1, 749: 0, 750: 1, 751: 1, 752: 0, 753: 1, 754: 0, 755: 0, 756: 0, 757: 0, 758: 1, 759: 1, 760: 1, 761: 1, 762: 1, 763: 1, 764: 0, 765: 1, 766: 0, 767: 0, 768: 0, 769: 1, 770: 1, 771: 0, 772: 0, 773: 1, 774: 0, 775: 1, 776: 0, 777: 1, 778: 0, 779: 1, 780: 1, 781: 0, 782: 0, 783: 1, 784: 1, 785: 0, 786: 1, 787: 0, 788: 0, 789: 1, 790: 1, 791: 1, 792: 0, 793: 1, 794: 0, 795: 1, 796: 1, 797: 1, 798: 1, 799: 1, 800: 1}
-2395.0
-2165.0
dealing G5.txt
device 0 start to train
[n] 200 [C] 1154 weight 800
con_list_range [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200]
average_loss tensor(-2373.9365, device='cuda:0', grad_fn=<DivBackward0>) best_loss inf
Epoch 0 Epoch time:  3.2988646030426025 current loss tensor(-2351.4614, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2374.3018, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2373.9365, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1 Epoch time:  2.8952391147613525 current loss tensor(-2351.7783, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2374.6636, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2374.3018, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2 Epoch time:  2.879847288131714 current loss tensor(-2352.0918, device='cuda:0', grad_fn=<SumBackward0>)
average_loss 0.8874120712280273 current loss tensor(-377.0508, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  0.8947293758392334 current loss tensor(-377.0724, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  0.8874473571777344 current loss tensor(-377.0936, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  0.8893516063690186 current loss tensor(-377.1146, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  0.8930478096008301 current loss tensor(-377.1353, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  0.9218356609344482 current loss tensor(-377.1558, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  0.9033553600311279 current loss tensor(-377.1761, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  0.9054200649261475 current loss tensor(-377.1961, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  0.9144608974456787 current loss tensor(-377.2159, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  0.9257586002349854 current loss tensor(-377.2355, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  0.8881676197052002 current loss tensor(-377.2549, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  0.8881494998931885 current loss tensor(-377.2740, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  0.8899435997009277 current loss tensor(-377.2929, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  0.8855462074279785 current loss tensor(-377.3116, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  0.8956351280212402 current loss tensor(-377.3300, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  0.8963882923126221 current loss tensor(-377.3483, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  0.9232947826385498 current loss tensor(-377.3663, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  0.9270126819610596 current loss tensor(-377.3842, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  0.8924660682678223 current loss tensor(-377.4018, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  0.891596794128418 current loss tensor(-377.4193, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  0.9099414348602295 current loss tensor(-377.4365, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  0.9140405654907227 current loss tensor(-377.4536, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  0.8963127136230469 current loss tensor(-377.4705, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  0.8911473751068115 current loss tensor(-377.4871, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  0.9053363800048828 current loss tensor(-377.5037, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  0.9199891090393066 current loss tensor(-377.5201, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  0.8871548175811768 current loss tensor(-377.5363, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  0.890233039855957 current loss tensor(-377.5523, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  0.8891322612762451 current loss tensor(-377.5681, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  0.885594367980957 current loss tensor(-377.5839, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  0.88625168800354 current loss tensor(-377.5994, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  0.8931403160095215 current loss tensor(-377.6148, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  0.8976502418518066 current loss tensor(-377.6301, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  0.9262490272521973 current loss tensor(-377.6451, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  0.9279983043670654 current loss tensor(-377.6600, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  0.8947324752807617 current loss tensor(-377.6747, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  0.8924188613891602 current loss tensor(-377.6893, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  0.9312348365783691 current loss tensor(-377.7038, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  0.9049556255340576 current loss tensor(-377.7181, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  0.9132351875305176 current loss tensor(-377.7322, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  0.9037799835205078 current loss tensor(-377.7463, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  0.927619218826294 current loss tensor(-377.7602, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  0.9296035766601562 current loss tensor(-377.7740, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  0.8885440826416016 current loss tensor(-377.7877, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  0.8864617347717285 current loss tensor(-377.8012, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  0.8870470523834229 current loss tensor(-377.8146, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  0.8851702213287354 current loss tensor(-377.8278, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  0.8878610134124756 current loss tensor(-377.8410, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  0.9146285057067871 current loss tensor(-377.8540, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  0.8880257606506348 current loss tensor(-377.8669, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  0.8808975219726562 current loss tensor(-377.8798, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  0.8900206089019775 current loss tensor(-377.8925, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  0.8982124328613281 current loss tensor(-377.9051, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  0.9271259307861328 current loss tensor(-377.9177, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  0.9257707595825195 current loss tensor(-377.9302, device='cuda:2', grad_fn=<SumBackward0>)
dealing G5.txt
device 2 start to train
[n] 200 [C] 1231 weight 800
con_list_range [401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600]
Epoch 0 Epoch time:  3.2498435974121094 current loss tensor(-2375.6826, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.7384891510009766 current loss tensor(-2376.0513, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.8282790184020996 current loss tensor(-2376.4165, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.856011152267456 current loss tensor(-2376.7788, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.836085557937622 current loss tensor(-2377.1377, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.1993162631988525 current loss tensor(-2377.4941, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.7616212368011475 current loss tensor(-2377.8469, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.8019185066223145 current loss tensor(-2378.1968, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 8 Epoch time: 0.7152819633483887 current loss tensor(-322.9722, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  0.7169044017791748 current loss tensor(-322.9714, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  0.7147994041442871 current loss tensor(-322.9706, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  0.7180302143096924 current loss tensor(-322.9696, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  0.7416656017303467 current loss tensor(-322.9685, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  0.7293891906738281 current loss tensor(-322.9673, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  0.7280890941619873 current loss tensor(-322.9660, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  0.7388288974761963 current loss tensor(-322.9646, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  0.747295618057251 current loss tensor(-322.9631, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  0.7123584747314453 current loss tensor(-322.9615, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  0.7122905254364014 current loss tensor(-322.9598, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  0.7140111923217773 current loss tensor(-322.9581, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  0.7187058925628662 current loss tensor(-322.9563, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  0.7165000438690186 current loss tensor(-322.9544, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  0.7220041751861572 current loss tensor(-322.9525, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  0.7474288940429688 current loss tensor(-322.9504, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  0.7508366107940674 current loss tensor(-322.9482, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  0.7147605419158936 current loss tensor(-322.9460, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  0.7204039096832275 current loss tensor(-322.9437, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  0.7297439575195312 current loss tensor(-322.9413, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  0.7354826927185059 current loss tensor(-322.9390, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  0.7217843532562256 current loss tensor(-322.9365, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  0.7153668403625488 current loss tensor(-322.9340, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  0.7329823970794678 current loss tensor(-322.9314, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  0.7424190044403076 current loss tensor(-322.9288, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  0.7111258506774902 current loss tensor(-322.9261, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  0.7160537242889404 current loss tensor(-322.9234, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  0.7136545181274414 current loss tensor(-322.9207, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  0.7127370834350586 current loss tensor(-322.9180, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  0.70949387550354 current loss tensor(-322.9152, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  0.7199611663818359 current loss tensor(-322.9124, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  0.7218406200408936 current loss tensor(-322.9095, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  0.7522358894348145 current loss tensor(-322.9067, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  0.7478229999542236 current loss tensor(-322.9038, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  0.7178540229797363 current loss tensor(-322.9008, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  0.717597246170044 current loss tensor(-322.8978, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  0.753760576248169 current loss tensor(-322.8948, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  0.7289683818817139 current loss tensor(-322.8917, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  0.7392961978912354 current loss tensor(-322.8885, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  0.7323043346405029 current loss tensor(-322.8854, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  0.751258373260498 current loss tensor(-322.8823, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  0.7506780624389648 current loss tensor(-322.8791, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  0.7124617099761963 current loss tensor(-322.8758, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  0.7097105979919434 current loss tensor(-322.8725, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  0.7136688232421875 current loss tensor(-322.8692, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  0.7151246070861816 current loss tensor(-322.8659, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  0.7131736278533936 current loss tensor(-322.8625, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  0.7313361167907715 current loss tensor(-322.8591, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  0.7134044170379639 current loss tensor(-322.8558, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  0.7132973670959473 current loss tensor(-322.8525, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  0.7157082557678223 current loss tensor(-322.8491, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  0.7218868732452393 current loss tensor(-322.8458, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  0.7505044937133789 current loss tensor(-322.8425, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  0.7461378574371338 current loss tensor(-322.8391, device='cuda:3', grad_fn=<SumBackward0>)
dealing G5.txt
device 3 start to train
[n] 200 [C] 1157 weight 800
con_list_range [601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800]
Epoch 0 Epoch time:  3.2257564067840576 current loss tensor(-2349.0361, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.7045724391937256 current loss tensor(-2349.4653, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.943362236022949 current loss tensor(-2349.8914, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.7359142303466797 current loss tensor(-2350.3140, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.8229618072509766 current loss tensor(-2350.7339, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  2.777327060699463 current loss tensor(-2351.1504, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.773719549179077 current loss tensor(-2351.5637, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.796792984008789 current loss tensor(-2351.9736, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  2.7982897758483887 current loss tensor(-2352.3804, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  Epoch time:  0.9948794841766357 current loss tensor(-483.6043, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  1.0009486675262451 current loss tensor(-483.6713, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  0.9972524642944336 current loss tensor(-483.7378, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  1.0006890296936035 current loss tensor(-483.8037, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  1.0323631763458252 current loss tensor(-483.8690, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  1.020507574081421 current loss tensor(-483.9335, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  1.0181171894073486 current loss tensor(-483.9975, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  1.0323030948638916 current loss tensor(-484.0609, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  1.0428781509399414 current loss tensor(-484.1237, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  0.9967849254608154 current loss tensor(-484.1860, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  0.9992446899414062 current loss tensor(-484.2477, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  0.9990019798278809 current loss tensor(-484.3089, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  0.9961860179901123 current loss tensor(-484.3695, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  1.0041799545288086 current loss tensor(-484.4294, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  1.0076708793640137 current loss tensor(-484.4889, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  1.039757251739502 current loss tensor(-484.5478, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  1.0438499450683594 current loss tensor(-484.6062, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  1.0107183456420898 current loss tensor(-484.6639, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  1.0077800750732422 current loss tensor(-484.7213, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  1.0036828517913818 current loss tensor(-484.7780, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  1.0307152271270752 current loss tensor(-484.8342, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  1.0102577209472656 current loss tensor(-484.8900, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  1.0001466274261475 current loss tensor(-484.9451, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  1.0260884761810303 current loss tensor(-484.9998, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  1.0342011451721191 current loss tensor(-485.0540, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  0.9962983131408691 current loss tensor(-485.1077, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  0.9967870712280273 current loss tensor(-485.1608, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  1.000518560409546 current loss tensor(-485.2135, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  0.9953231811523438 current loss tensor(-485.2657, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  0.9977035522460938 current loss tensor(-485.3174, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  1.0099384784698486 current loss tensor(-485.3686, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  1.0029609203338623 current loss tensor(-485.4193, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  1.0432164669036865 current loss tensor(-485.4695, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  1.0372133255004883 current loss tensor(-485.5193, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  1.007016658782959 current loss tensor(-485.5687, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  1.001943588256836 current loss tensor(-485.6176, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  1.045983076095581 current loss tensor(-485.6660, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  1.016195297241211 current loss tensor(-485.7139, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  1.028698205947876 current loss tensor(-485.7614, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  1.0161564350128174 current loss tensor(-485.8085, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  1.0434050559997559 current loss tensor(-485.8551, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  1.0404822826385498 current loss tensor(-485.9013, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  0.9978013038635254 current loss tensor(-485.9470, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  0.9950282573699951 current loss tensor(-485.9923, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  1.0016305446624756 current loss tensor(-486.0371, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  0.9966998100280762 current loss tensor(-486.0815, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  0.9934122562408447 current loss tensor(-486.1255, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  1.022625207901001 current loss tensor(-486.1689, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  0.9976375102996826 current loss tensor(-486.2119, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  0.996525764465332 current loss tensor(-486.2545, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  1.1375935077667236 current loss tensor(-486.2966, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  1.0054905414581299 current loss tensor(-486.3385, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  1.047015905380249 current loss tensor(-486.3799, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  1.0422413349151611 current loss tensor(-486.4211, device='cuda:1', grad_fn=<SumBackward0>)
dealing G5.txt
device 1 start to train
[n] 200 [C] 1235 weight 800
con_list_range [201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400]
Epoch 0 Epoch time:  3.2962255477905273 current loss tensor(-2419.5652, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.8054003715515137 current loss tensor(-2419.9114, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.8845036029815674 current loss tensor(-2420.2542, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.9180381298065186 current loss tensor(-2420.5935, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.9620392322540283 current loss tensor(-2420.9297, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  2.8426127433776855 current loss tensor(-2421.2627, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.9363057613372803 current loss tensor(-2421.5925, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.8331398963928223 current loss tensor(-2421.9187, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  2.8520967960357666 current loss tensor(-2422.2415, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 9 tensor(-2375.0222, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2374.6636, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3 Epoch time:  2.8493218421936035 current loss tensor(-2352.4028, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2375.3779, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.0222, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4 Epoch time:  2.9841012954711914 current loss tensor(-2352.7107, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2375.7307, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.3779, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5 Epoch time:  3.175673007965088 current loss tensor(-2353.0156, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.0801, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2375.7307, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6 Epoch time:  2.858990430831909 current loss tensor(-2353.3179, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.4263, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.0801, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7 Epoch time:  2.838590145111084 current loss tensor(-2353.6167, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2376.7695, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.4263, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8 Epoch time:  2.8403725624084473 current loss tensor(-2353.9126, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.1089, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2376.7695, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9 Epoch time:  2.922774314880371 current loss tensor(-2354.2051, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.4448, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.1089, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10 Epoch time:  2.929926633834839 current loss tensor(-2354.4941, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2377.7773, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.4448, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11 Epoch time:  2.8730952739715576 current loss tensor(-2354.7800, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.1064, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2377.7773, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12 Epoch time:  2.852372407913208 current loss tensor(-2355.0625, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.4321, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.1064, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13 Epoch time:  2.9721295833587646 current loss tensor(-2355.3416, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2378.7539, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.4321, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14 Epoch time:  2.8495185375213623 current loss tensor(-2355.6172, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.0725, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2378.7539, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15 Epoch time:  2.8505988121032715 current loss tensor(-2355.8896, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.3877, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.0725, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16 Epoch time:  2.848621368408203 current loss tensor(-2356.1589, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2379.6992, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.3877, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17 Epoch time:  2.875155210494995 current loss tensor(-2356.4248, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.0068, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2379.6992, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18 Epoch time:  2.900142192840576 current loss tensor(-2356.6868, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.3110, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.0068, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19 Epoch time:  2.942394733428955 current loss tensor(-2356.9458, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.6113, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.3110, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20 Epoch time:  2.895578384399414 current loss tensor(-2357.2014, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2380.9084, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.6113, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21 Epoch time:  2.9650816917419434 current loss tensor(-2357.4536, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.2021, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2380.9084, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22 Epoch time:  2.859177827835083 current loss tensor(-2357.7026, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.4919, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.2021, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23 Epoch time:  2.863288402557373 current loss tensor(-2357.9482, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2381.7783, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.4919, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24 Epoch time:  2.8509891033172607 current loss tensor(-2358.1904, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.0608, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2381.7783, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25 Epoch time:  2.848601818084717 current loss tensor(-2358.4292, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.3396, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.0608, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26 Epoch time:  2.9274277687072754 current loss tensor(-2358.6646, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.6150, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.3396, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27 Epoch time:  2.8456544876098633 current loss tensor(-2358.8965, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2382.8867, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.6150, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28 Epoch time:  2.986102342605591 current loss tensor(-2359.1248, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.1548, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2382.8867, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29 Epoch time:  2.9354069232940674 current loss tensor(-2359.3501, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.4194, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.1548, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30 Epoch time:  2.8499197959899902 current loss tensor(-2359.5718, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.6802, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.4194, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31 Epoch time:  2.8479228019714355 current loss tensor(-2359.7903, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2383.9375, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.6802, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32 Epoch time:  2.853037118911743 current loss tensor(-2360.0054, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.1909, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2383.9375, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33 Epoch time:  2.8493266105651855 current loss tensor(-2360.2173, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.4409, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.1909, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34 Epoch time:  2.846691370010376 current loss tensor(-2360.4258, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.6877, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.4409, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35 Epoch time:  2.849378824234009 current loss tensor(-2360.6313, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2384.9307, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.6877, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36 Epoch time:  2.97322154045105 current loss tensor(-2360.8333, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.1702, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2384.9307, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37 Epoch time:  2.8445537090301514 current loss tensor(-2361.0320, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.4062, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.1702, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38 Epoch time:  2.88971209526062 current loss tensor(-2361.2275, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.6384, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.4062, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39 Epoch time:  2.9219095706939697 current loss tensor(-2361.4197, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2385.8677, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.6384, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40 Epoch time:  2.8473494052886963 current loss tensor(-2361.6089, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.0935, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2385.8677, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41 Epoch time:  2.8432083129882812 current loss tensor(-2361.7947, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.3157, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.0935, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42 Epoch time:  2.848505973815918 current loss tensor(-2361.9775, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.5347, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.3157, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43 Epoch time:  2.9601352214813232 current loss tensor(-2362.1572, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.7505, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.5347, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44 Epoch time:  2.8642821311950684 current loss tensor(-2362.3340, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2386.9624, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.7505, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45 Epoch time:  2.854855537414551 current loss tensor(-2362.5073, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.1711, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2386.9624, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46 Epoch time:  2.9074180126190186 current loss tensor(-2362.6777, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.3767, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.1711, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47 Epoch time:  2.903621196746826 current loss tensor(-2362.8455, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.5791, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.3767, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48 Epoch time:  2.8483428955078125 current loss tensor(-2363.0103, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.7781, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.5791, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49 Epoch time:  2.9336671829223633 current loss tensor(-2363.1719, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2387.9736, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.7781, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 50 Epoch time:  2.847506523132324 current loss tensor(-2363.3303, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.1660, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2387.9736, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 51 Epoch time:  2.849977493286133 current loss tensor(-2363.4858, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.3557, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.1660, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 52 Epoch time:  2.852877616882324 current loss tensor(-2363.6387, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.5420, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.3557, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 53 Epoch time:  2.845310926437378 current loss tensor(-2363.7886, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.7251, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.5420, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 54 Epoch time:  2.8583920001983643 current loss tensor(-2363.9360, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2388.9050, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.7251, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 55 Epoch time:  2.9277641773223877 current loss tensor(-2364.0806, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.0820, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2388.9050, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 56 Epoch time:  2.988703727722168 current loss tensor(-2364.2222, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.2559, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.0820, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 57 Epoch time:  2.8892135620117188 current loss tensor(-2364.3608, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.4268, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.2559, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 58 Epoch time:  3.156038999557495 current loss tensor(-2364.4971, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.5950, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.4268, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 59 Epoch time:  3.2717814445495605 current loss tensor(-2364.6309, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.7600, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.5950, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 60 Epoch time:  2.8552191257476807 current loss tensor(-2364.7620, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2389.9221, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.7600, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 61 Epoch time:  2.8628852367401123 current loss tensor(-2364.8901, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.0815, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2389.9221, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 62 Epoch time:  2.855288028717041 current loss tensor(-2365.0161, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.2378, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.0815, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 63 Epoch time:  2.845101833343506 current loss tensor(-2365.1394, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.3916, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.2378, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 64 Epoch time:  2.913621425628662 current loss tensor(-2365.2603, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.5422, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.3916, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 65 Epoch time:  2.8526206016540527 current loss tensor(-2365.3784, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.6904, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.5422, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 66 Epoch time:  2.8938348293304443 current loss  2.8282899856567383 current loss tensor(-2378.5435, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  2.9709036350250244 current loss tensor(-2378.8862, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.7757253646850586 current loss tensor(-2379.2261, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.8532605171203613 current loss tensor(-2379.5623, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.8231008052825928 current loss tensor(-2379.8955, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.843391180038452 current loss tensor(-2380.2249, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.8335723876953125 current loss tensor(-2380.5510, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.8477277755737305 current loss tensor(-2380.8735, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.8308191299438477 current loss tensor(-2381.1929, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.8378093242645264 current loss tensor(-2381.5083, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.950037717819214 current loss tensor(-2381.8203, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.788816213607788 current loss tensor(-2382.1284, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.877093553543091 current loss tensor(-2382.4326, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  2.8917195796966553 current loss tensor(-2382.7339, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  2.8390707969665527 current loss tensor(-2383.0312, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.837486505508423 current loss tensor(-2383.3252, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.8344156742095947 current loss tensor(-2383.6157, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.846233606338501 current loss tensor(-2383.9023, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.9755640029907227 current loss tensor(-2384.1853, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.7860476970672607 current loss tensor(-2384.4648, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.845383405685425 current loss tensor(-2384.7412, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.834963798522949 current loss tensor(-2385.0139, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.8780953884124756 current loss tensor(-2385.2832, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.8344626426696777 current loss tensor(-2385.5486, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.8490402698516846 current loss tensor(-2385.8103, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.8310670852661133 current loss tensor(-2386.0686, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.8266332149505615 current loss tensor(-2386.3232, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.837327718734741 current loss tensor(-2386.5742, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.959670305252075 current loss tensor(-2386.8220, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.8406941890716553 current loss tensor(-2387.0662, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.8822619915008545 current loss tensor(-2387.3069, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.847076654434204 current loss tensor(-2387.5442, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.8746390342712402 current loss tensor(-2387.7783, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.8375532627105713 current loss tensor(-2388.0090, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.835559844970703 current loss tensor(-2388.2361, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.8363711833953857 current loss tensor(-2388.4600, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.8529305458068848 current loss tensor(-2388.6807, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.837096691131592 current loss tensor(-2388.8975, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  2.9544286727905273 current loss tensor(-2389.1111, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.7898244857788086 current loss tensor(-2389.3213, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  2.8887088298797607 current loss tensor(-2389.5283, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  2.842302083969116 current loss tensor(-2389.7319, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  2.8746285438537598 current loss tensor(-2389.9321, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.8321645259857178 current loss tensor(-2390.1294, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.837390661239624 current loss tensor(-2390.3237, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.8410284519195557 current loss tensor(-2390.5146, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.8360378742218018 current loss tensor(-2390.7026, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.9725723266601562 current loss tensor(-2390.8872, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  2.7932305335998535 current loss tensor(-2391.0691, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.8396427631378174 current loss tensor(-2391.2478, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  2.8650083541870117 current loss tensor(-2391.4233, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  2.8742318153381348 current loss tensor(-2391.5962, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  2.8773860931396484 current loss tensor(-2391.7659, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.840831756591797 current loss tensor(-2391.9326, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  2.840623140335083 current loss tensor(-2392.0967, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.8363442420959473 current loss tensor(-2392.2578, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.961174488067627 current loss tensor(-2392.4163, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.7836062908172607 current loss tensor(-2392.5718, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.879347324371338 current loss tensor(-2392.7249, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.8393402099609375 current loss tensor(-2392.8752, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.854118585586548 current loss tensor(-2393.0227, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.84000825881958 current loss tensor(-2393.1677, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.8666999340057373 current loss tensor(-2393.3101, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.844102144241333 current loss tensor(-2393.4500, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.8371527194976807 current loss tensor(-2393.5874, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.8346762657165527 current loss tensor(-2393.7222, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.9476630687713623 current loss tensor(-2393.8545, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.785513401031494 current loss tensor(-2393.9844, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.8342959880828857 current loss tensor(-2394.1121, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.8697733879089355 current loss tensor(-2394.2373, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.8438398838043213 current loss tensor(-2394.3599, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.8432111740112305 current loss tensor(-2394.4805, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.7869598865509033 current loss tensor(-2352.7834, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.957520008087158 current loss tensor(-2353.1826, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.7819578647613525 current loss tensor(-2353.5781, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.8134877681732178 current loss tensor(-2353.9702, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.818993330001831 current loss tensor(-2354.3584, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.8183116912841797 current loss tensor(-2354.7427, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.81584095954895 current loss tensor(-2355.1235, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.8124632835388184 current loss tensor(-2355.5010, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.808781147003174 current loss tensor(-2355.8740, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.8028404712677 current loss tensor(-2356.2432, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.8137078285217285 current loss tensor(-2356.6086, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.9839112758636475 current loss tensor(-2356.9707, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  2.772190570831299 current loss tensor(-2357.3286, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  2.8097803592681885 current loss tensor(-2357.6829, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.80912184715271 current loss tensor(-2358.0334, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.8058738708496094 current loss tensor(-2358.3801, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.812175750732422 current loss tensor(-2358.7227, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.813016891479492 current loss tensor(-2359.0610, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.827780246734619 current loss tensor(-2359.3960, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.812762975692749 current loss tensor(-2359.7268, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.9360060691833496 current loss tensor(-2360.0537, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.8070738315582275 current loss tensor(-2360.3767, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.8110435009002686 current loss tensor(-2360.6958, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.8456711769104004 current loss tensor(-2361.0110, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.8095617294311523 current loss tensor(-2361.3225, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.8027987480163574 current loss tensor(-2361.6299, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.808946371078491 current loss tensor(-2361.9341, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.813645601272583 current loss tensor(-2362.2339, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.8086154460906982 current loss tensor(-2362.5303, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.9412150382995605 current loss tensor(-2362.8228, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.7596099376678467 current loss tensor(-2363.1118, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.8339035511016846 current loss tensor(-2363.3970, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.8093249797821045 current loss tensor(-2363.6782, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.8078854084014893 current loss tensor(-2363.9561, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.8118298053741455 current loss tensor(-2364.2305, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.8163864612579346 current loss tensor(-2364.5010, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.8071446418762207 current loss tensor(-2364.7676, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  2.80898380279541 current loss tensor(-2365.0308, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.9510560035705566 current loss tensor(-2365.2903, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  2.7572531700134277 current loss tensor(-2365.5464, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  2.8172614574432373 current loss tensor(-2365.7993, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  2.8417325019836426 current loss tensor(-2366.0483, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.810788631439209 current loss tensor(-2366.2939, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.808708429336548 current loss tensor(-2366.5364, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.8069419860839844 current loss tensor(-2366.7754, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.801703691482544 current loss tensor(-2367.0105, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.8198916912078857 current loss tensor(-2367.2427, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  2.8090813159942627 current loss tensor(-2367.4712, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.936493396759033 current loss tensor(-2367.6963, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.155691146850586 current loss tensor(-2367.9180, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.271829605102539 current loss tensor(-2368.1367, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  2.78739070892334 current loss tensor(-2368.3521, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.7929799556732178 current loss tensor(-2368.5640, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  2.7971646785736084 current loss tensor(-2368.7727, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.794722557067871 current loss tensor(-2368.9783, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.806112289428711 current loss tensor(-2369.1807, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.7932779788970947 current loss tensor(-2369.3799, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.8213436603546143 current loss tensor(-2369.5762, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.915731906890869 current loss tensor(-2369.7695, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.7568793296813965 current loss tensor(-2369.9597, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.8016726970672607 current loss tensor(-2370.1470, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.8362317085266113 current loss tensor(-2370.3313, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.797924518585205 current loss tensor(-2370.5127, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.8107945919036865 current loss tensor(-2370.6914, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.804487705230713 current loss tensor(-2370.8674, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.796687602996826 current loss tensor(-2371.0403, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.798185348510742 current loss tensor(-2371.2104, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.93636417388916 current loss tensor(-2371.3782, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.754950523376465 current loss tensor(-2371.5427, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.793328046798706 current loss tensor(-2371.7048, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.79687762260437 current loss tensor(-2371.8645, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.7931602001190186 current loss tensor(-2372.0212, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.801431894302368 Epoch time:  2.836268186569214 current loss tensor(-2422.5605, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.930634021759033 current loss tensor(-2422.8765, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.9481310844421387 current loss tensor(-2423.1890, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.834852457046509 current loss tensor(-2423.4978, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.9693796634674072 current loss tensor(-2423.8032, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.8521480560302734 current loss tensor(-2424.1050, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.850834846496582 current loss tensor(-2424.4033, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.8492066860198975 current loss tensor(-2424.6982, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.873461961746216 current loss tensor(-2424.9893, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.846642017364502 current loss tensor(-2425.2769, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.9056735038757324 current loss tensor(-2425.5605, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.941025733947754 current loss tensor(-2425.8408, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.010244131088257 current loss tensor(-2426.1177, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  2.8560309410095215 current loss tensor(-2426.3911, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.8631932735443115 current loss tensor(-2426.6606, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.854954957962036 current loss tensor(-2426.9268, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.8471529483795166 current loss tensor(-2427.1890, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.849254846572876 current loss tensor(-2427.4475, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.920262336730957 current loss tensor(-2427.7026, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.9887173175811768 current loss tensor(-2427.9541, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.845491886138916 current loss tensor(-2428.2017, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.9356203079223633 current loss tensor(-2428.4458, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.848346471786499 current loss tensor(-2428.6860, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.852325677871704 current loss tensor(-2428.9229, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.854912042617798 current loss tensor(-2429.1558, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.844458818435669 current loss tensor(-2429.3853, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.8447682857513428 current loss tensor(-2429.6111, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.9753801822662354 current loss tensor(-2429.8330, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.840564727783203 current loss tensor(-2430.0520, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.85341215133667 current loss tensor(-2430.2671, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.9182844161987305 current loss tensor(-2430.4785, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.887805461883545 current loss tensor(-2430.6870, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.8462352752685547 current loss tensor(-2430.8918, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.846830368041992 current loss tensor(-2431.0933, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.9596798419952393 current loss tensor(-2431.2915, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.8628311157226562 current loss tensor(-2431.4858, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.8550002574920654 current loss tensor(-2431.6772, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  2.851012945175171 current loss tensor(-2431.8650, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.9070417881011963 current loss tensor(-2432.0496, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  2.9017016887664795 current loss tensor(-2432.2310, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  2.8503224849700928 current loss tensor(-2432.4092, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  2.9282405376434326 current loss tensor(-2432.5837, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.8507657051086426 current loss tensor(-2432.7554, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.851792335510254 current loss tensor(-2432.9238, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.8464066982269287 current loss tensor(-2433.0889, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.8576815128326416 current loss tensor(-2433.2507, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.8558154106140137 current loss tensor(-2433.4097, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.059133529663086 current loss tensor(-2433.5654, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.860297441482544 current loss tensor(-2433.7185, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  2.876007318496704 current loss tensor(-2433.8687, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  2.9423208236694336 current loss tensor(-2434.0159, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  2.9460790157318115 current loss tensor(-2434.1599, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.8615872859954834 current loss tensor(-2434.3015, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  2.855055570602417 current loss tensor(-2434.4399, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.8456459045410156 current loss tensor(-2434.5757, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.8475182056427 current loss tensor(-2434.7087, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.917570114135742 current loss tensor(-2434.8389, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.8928003311157227 current loss tensor(-2434.9663, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.855637311935425 current loss tensor(-2435.0911, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.978440761566162 current loss tensor(-2435.2134, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.8532602787017822 current loss tensor(-2435.3330, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.914372444152832 current loss tensor(-2435.4502, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.8482987880706787 current loss tensor(-2435.5649, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.8820505142211914 current loss tensor(-2435.6775, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.8496317863464355 current loss tensor(-2435.7874, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.8558270931243896 current loss tensor(-2435.8950, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.89227294921875 current loss tensor(-2436., device='cuda:1', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.8588428497314453 current loss tensor(-2436.1030, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.884338855743408 current loss tensor(-2436.2036, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.8533949851989746 current loss tensor(-2436.3020, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.9879376888275146 current loss tensor(-2436.3982, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.8498520851135254 current loss tensor(-2436.4922, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  tensor(-2365.4946, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.8359, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.6904, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 67 Epoch time:  2.867555856704712 current loss tensor(-2365.6079, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2390.9788, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.8359, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 68 Epoch time:  2.966163158416748 current loss tensor(-2365.7190, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.1189, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2390.9788, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 69 Epoch time:  2.922396183013916 current loss tensor(-2365.8276, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.2566, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.1189, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 70 Epoch time:  2.8442535400390625 current loss tensor(-2365.9343, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.3916, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.2566, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 71 Epoch time:  2.8493359088897705 current loss tensor(-2366.0386, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.5242, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.3916, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 72 Epoch time:  2.882425546646118 current loss tensor(-2366.1406, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.6543, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.5242, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 73 Epoch time:  2.8506083488464355 current loss tensor(-2366.2405, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.7820, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.6543, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 74 Epoch time:  2.895937919616699 current loss tensor(-2366.3379, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2391.9072, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.7820, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 75 Epoch time:  2.848146677017212 current loss tensor(-2366.4336, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.0298, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2391.9072, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 76 Epoch time:  2.8866660594940186 current loss tensor(-2366.5269, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.1504, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.0298, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 77 Epoch time:  2.856325387954712 current loss tensor(-2366.6182, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.2686, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.1504, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 78 Epoch time:  2.8530709743499756 current loss tensor(-2366.7073, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.3843, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.2686, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 79 Epoch time:  2.9862308502197266 current loss tensor(-2366.7944, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.4980, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.3843, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 80 Epoch time:  2.8512728214263916 current loss tensor(-2366.8794, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.6094, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.4980, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 81 Epoch time:  2.8485794067382812 current loss tensor(-2366.9629, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.7183, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.6094, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 82 Epoch time:  3.3384716510772705 current loss tensor(-2367.0439, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.8252, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.7183, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 83 Epoch time:  3.130446672439575 current loss tensor(-2367.1233, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2392.9297, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.8252, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 84 Epoch time:  2.8511159420013428 current loss tensor(-2367.2007, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.0327, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2392.9297, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 85 Epoch time:  2.880997896194458 current loss tensor(-2367.2764, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.1331, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.0327, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 86 Epoch time:  2.85131573677063 current loss tensor(-2367.3503, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.2314, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.1331, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 87 Epoch time:  2.919870376586914 current loss tensor(-2367.4221, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.3279, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.2314, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 88 Epoch time:  2.8649864196777344 current loss tensor(-2367.4924, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.4221, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.3279, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 89 Epoch time:  3.2892093658447266 current loss tensor(-2367.5608, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.5149, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.4221, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 90 Epoch time:  3.245025396347046 current loss tensor(-2367.6277, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.6052, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.5149, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 91 Epoch time:  3.238330125808716 current loss tensor(-2367.6926, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.6938, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.6052, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 92 Epoch time:  3.2487967014312744 current loss tensor(-2367.7561, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.7803, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.6938, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 93 Epoch time:  3.2463886737823486 current loss tensor(-2367.8179, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.8652, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.7803, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 94 Epoch time:  3.2565219402313232 current loss tensor(-2367.8779, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2393.9482, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.8652, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 95 Epoch time:  3.2193243503570557 current loss tensor(-2367.9370, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2394.0295, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2393.9482, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 96 Epoch time:  2.8510537147521973 current loss tensor(-2367.9939, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2394.1091, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2394.0295, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 97 Epoch time:  2.9200825691223145 current loss tensor(-2368.0496, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2394.1870, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2394.1091, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 98 Epoch time:  2.8506128787994385 current loss tensor(-2368.1035, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2394.2629, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2394.1870, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 99 Epoch time:  2.9859395027160645 current loss tensor(-2368.1565, device='cuda:0', grad_fn=<SumBackward0>)
best_out [0.43993875 0.56528187 0.47609964 0.42942703 0.44076103 0.44248763
 0.5185922  0.5321314  0.42105055 0.5213049  0.5100916  0.45832655
 0.517699   0.5268911  0.52435565 0.46630418 0.49844974 0.5071492
 0.51328176 0.5792619  0.4593103  0.49417043 0.49765477 0.41044286
 0.5540111  0.49337173 0.45650658 0.51849264 0.51784337 0.48082128
 0.5223007  0.5323645  0.55251217 0.45400724 0.47726798 0.3877557
 0.543572   0.5516525  0.5761136  0.45673248 0.44247717 0.47785664
 0.46471193 0.47882074 0.49787793 0.4883362  0.5212477  0.48449385
 0.484648   0.49552488 0.4940991  0.45686153 0.5447456  0.5168392
 0.46541342 0.5779018  0.44289985 0.41003728 0.5627068  0.53279656
 0.5021115  0.51299083 0.545594   0.58580106 0.44973248 0.5751703
 0.42122847 0.49642333 0.49877635 0.4558004  0.46620265 0.5252094
 0.46555054 0.60167146 0.4401939  0.5609118  0.5182062  0.48558602
 0.52553046 0.5155593  0.50914156 0.46416622 0.50387657 0.4917356
 0.5616033  0.46610135 0.48889527 0.45843086 0.4417592  0.56415874
 0.3964638  0.49223554 0.41188377 0.4199716  0.4942145  0.48628563
 0.51883864 0.49060455 0.497839   0.47663888 0.50825286 0.45894632
 0.50344485 0.55158496 0.46625903 0.5126411  0.48257494 0.48338526
 0.5063839  0.5361137  0.44435188 0.3828582  0.483817   0.38714045
 0.42425752 0.53345317 0.4616028  0.4834886  0.48352915 0.46381408
 0.44408408 0.47661442 0.5312778  0.4209148  0.46276164 0.5294821
 0.46540177 0.46025977 0.4838932  0.5189103  0.45897213 0.50242734
 0.4868685  0.57761014 0.48394987 0.47706598 0.5502684  0.59553885
 0.4553631  0.5427861  0.4926071  0.4942863  0.5408589  0.47709236
 0.5572427  0.522029   0.4996907  0.48339063 0.43629462 0.41659802
 0.5078026  0.44817945 0.46650687 0.49895412 0.4769093  0.48975593
 0.45967203 0.5466997  0.47628924 0.4591192  0.5004445  0.5190407
 0.5483087  0.4557405  0.50820124 0.45961732 0.490093   0.47304648
 0.4623513  0.49656096 0.5316516  0.44077605 0.5401272  0.52944005
 0.51590735 0.52674514 0.48676476 0.468042   0.56188154 0.55604017
 0.4271546  0.44859326 0.5728522  0.50790405 0.47560063 0.55414015
 0.45543242 0.4566559  0.39240867 0.5033237  0.52614456 0.53971344
 0.495136   0.5306244  0.47552007 0.47021317 0.5255954  0.471158
 0.53501546 0.5065017  0.49199873 0.56145436 0.45173636 0.4373422
 0.46998236 0.44723395 0.53534144 0.5065052  0.4602916  0.52821547
 0.46147344 0.4841498  0.49633303 0.44935092 0.51831555 0.43822432
 0.44658282 0.41732043 0.50140774 0.47949848 0.48499122 0.4608556
 0.49986365 0.42985877 0.46460024 0.45991006 0.48739398 0.48732728
 0.50438964 0.50169814 0.5722354  0.45589727 0.51278806 0.4549101
 0.3603056  0.39640766 0.45587704 0.53623337 0.51328915 0.45134237
 0.4956098  0.5028103  0.48881033 0.49917728 0.4487655  0.49848333
 0.50832427 0.53595966 0.44970238 0.54338527 0.5253816  0.4479874
 0.5317576  0.48297247 0.47215635 0.460901   0.47135156 0.38713595
 0.557647   0.49476954 0.51411664 0.5145564  0.49493903 0.49664503
 0.4729013  0.6017385  0.3847549  0.48889607 0.4923605  0.46132183
 0.559165   0.5055887  0.5128532  0.52588135 0.4881817  0.5447987
 0.5522253  0.5244772  0.4871276  0.47866446 0.50560343 0.4995492
 0.5375233  0.49579045 0.5121048  0.52785623 0.49815333 0.5393964
 0.48013908 0.484307   0.4423936  0.4970968  0.5221487  0.44694096
 0.5026222  0.4705326  0.4911815  0.5260843  0.4930971  0.4705988
 0.46887305 0.4447354  0.5245569  0.5128728  0.5321722  0.5478008
 0.42707756 0.47033155 0.54301363 0.4874985  0.4494171  0.46890807
 0.44736108 0.40484092 0.47355455 0.5094051  0.5224084  0.5266943
 0.5412019  0.5088914  0.4614803  0.42753667 0.46255833 0.47960424
 0.49110207 0.4834218  0.48735762 0.47722763 0.48687777 0.4324889
 0.51258904 0.50652623 0.46394843 0.5208244  0.52834386 0.53080404
 0.5432345  0.5064435  0.47322652 0.5456905  0.51270825 0.4928991
 0.5066475  0.43776056 0.5865371  0.5155867  0.50421506 0.5468218
 0.48670596 0.4555546  0.5312805  0.4037178  0.46574637 0.47714892
 0.44642386 0.48159385 0.47691834 0.48416278 0.5640429  0.53662074
 0.53337896 0.5032768  0.50759375 0.46224502 0.50913846 0.47767535
 0.4581611  0.43029544 0.44949356 0.5408689  0.54783    0.43851593
 0.49813822 0.50343007 0.48682794 0.45787966 0.512811   0.48070285
 0.5595148  0.524654   0.465292   0.47168234 0.52668077 0.50718683
 0.48087826 0.5725682  0.46285695 0.4642598  0.42460802 0.50229335
 0.5097867  0.5586964  0.44686154 0.5014824  0.5070341  0.47871372
 0.53181064 0.4511714  0.5278205  0.5145806  0.5082636  0.5323634
 0.41014725 0.4500527  0.43079263 0.44937557 0.50946444 0.55703795
 0.46089104 0.5006489  0.5270023  0.46526974 0.46586275 0.5060842
 0.5068951  0.4609975  0.43546608 0.48314863 0.53454924 0.48391694
 0.44535506 0.47715443 0.44709876 0.44955334 0.5751642  0.43046638
 0.46719897 0.48537207 0.50611806 0.493012   0.466572   0.47351596
 0.5238202  0.48042315 0.43823242 0.42159215 0.3983399  0.55116683
 0.47432262 0.47382113 0.4345125  0.4592929  0.4565333  0.5070458
 0.4387673  0.4728957  0.47203705 0.52114505 0.41901198 0.4592598
 0.48171002 0.47901836 0.5395107  0.49866936 0.471555   0.49310282
 0.4777084  0.43301988 0.52932996 0.51310194 0.47931972 0.49792734
 0.5477818  0.5616786  0.49603403 0.4823423  0.36990988 0.5183216
 0.4973801  0.44478157 0.5210959  0.47825423 0.48399448 0.5059695
 0.44591725 0.55603063 0.54057056 0.53651255 0.44907877 0.50922775
 0.53062093 0.45821086 0.5151937  0.5129088  0.5271081  0.47247115
 0.46237904 0.47252846 0.48619708 0.47220746 0.4635882  0.4545922
 0.4218914  0.42231855 0.5302536  0.54065156 0.50657135 0.4412668
 0.5197875  0.43922156 0.48265335 0.40775776 0.51640224 0.5108698
 0.476766   0.53296137 0.46637818 0.4119589  0.49534523 0.44574925
 0.50515896 0.38868865 0.45311633 0.5239072  0.48201448 0.5691997
 0.46303073 0.5495481  0.46603626 0.45526218 0.4766402  0.4645141
 0.46128765 0.4652753  0.43736073 0.43909767 0.4821621  0.45927057
 0.5148122  0.50019044 0.5092495  0.4101902  0.49305332 0.5164377
 0.4089829  0.50256974 0.49338317 0.48974568 0.44846714 0.48243952
 0.5290682  0.48673132 0.48734042 0.4984803  0.53640383 0.5295896
 0.47865474 0.5113062  0.43614057 0.40480348 0.5095625  0.4314288
 0.43910784 0.4332073  0.46303308 0.4599236  0.44215226 0.54497874
 0.55242944 0.47967613 0.49737933 0.5260255  0.5479904  0.44484812
 0.49745077 0.52197033 0.4693186  0.4561154  0.46489546 0.46386197
 0.50137603 0.4173762  0.44918475 0.49949285 0.48113108 0.45227155
 0.48448122 0.42468745 0.49507767 0.5422637  0.4325716  0.527705
 0.46022907 0.45191443 0.4729408  0.47783047 0.4956406  0.4664953
 0.45194855 0.55808634 0.5230371  0.49584156 0.4989971  0.49949297
 0.42169794 0.4348289  0.50577545 0.47963494 0.4925172  0.49244514
 0.4248929  0.47251937 0.43007642 0.39811152 0.45175827 0.4352471
 0.47034094 0.54514503 0.44308916 0.50166035 0.52435917 0.4628888
 0.4343583  0.5502707  0.48591763 0.44138536 0.4097219  0.48217916
 0.50178415 0.4817845  0.3925328  0.5171092  0.5013259  0.38584882
 0.46745527 0.40595537 0.45702484 0.47715685 0.48490688 0.47667062
 0.5876777  0.46570066 0.4788432  0.5033923  0.46561167 0.40158084
 0.45649526 0.46601254 0.5064124  0.46731827 0.41041398 0.44820327
 0.44252965 0.46415323 0.4483515  0.44795865 0.48701617 0.56054103
 0.39813754 0.39359322 0.5076885  0.4305687  0.4598353  0.45959118
 0.4793775  0.39642593 0.37096483 0.391869   0.5656276  0.4974181
 0.4376916  0.50590205 0.46862432 0.51769364 0.43755695 0.52492625
 0.4036351  0.41432518 0.48175982 0.42673695 0.4927478  0.46153378
 0.4613612  0.46050546 0.4373264  0.49102578 0.5766638  0.50692314
 0.47100425 0.56938463 0.47978106 0.45363542 0.5105059  0.46550888
 0.5043893  0.47045538 0.4445748  0.46949553 0.48753682 0.5132425
 0.5285471  0.4351967  0.41536832 0.42702982 0.46330163 0.44085705
 0.3999959  0.45984328 0.45775083 0.4319336  0.4495863  0.363729
 0.52425265 0.49955252 0.45914719 0.5588615  0.48042178 0.41950947
 0.48212418 0.45671043 0.51119393 0.41749173 0.4478338  0.3918925
 0.4788784  0.59242195 0.45496613 0.4871405  0.49087512 0.42568097
 0.44764587 0.4582167  0.49588758 0.43003267 0.4138497  0.4376319
 0.45579267 0.39081293 0.44328228 0.49401337 0.4417446  0.45738024
 0.43205816 0.53576    0.45595446 0.4849706  0.47687972 0.53484434
 0.365913   0.48488873 0.5320123  0.48704782 0.54652125 0.40339595
 0.49411604 0.43492034 0.4928118  0.45847073 0.46633315 0.3935635
 0.5225215  0.44707483 0.48238024 0.47336152 0.39687458 0.4313149
 0.47849074 0.5059569  0.47046012 0.48007292 0.5670723  0.52639216
 0.42021164 0.42861313 0.5269858  0.4988741  0.47730675 0.4701315
 0.5698863  0.53077686 0.48111916 0.47078335 0.5066986  0.44595885
 0.4659177  0.39822417 0.48346362 0.36544165 0.52703005 0.52226126
 0.42972225 0.44935203 0.4822956  0.51990277 0.49766278 0.5105035
 0.41314244 0.49399173 0.458014   0.5098953  0.48863482 0.45069066
 0.4316833  0.47857925 0.43061134 0.49284175 0.4657682  0.4475342
 0.43437347 0.4912563 ]
info_input_total 800 weights 800 total_C 19176
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
-9699
res {1: 1, 2: 1, 3: 0, 4: 0, 5: 0, 6: 1, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 1, 15: 0, 16: 0, 17: 1, 18: 1, 19: 0, 20: 1, 21: 0, 22: 0, 23: 1, 24: 0, 25: 1, 26: 1, 27: 0, 28: 1, 29: 0, 30: 0, 31: 0, 32: 0, 33: 1, 34: 0, 35: 0, 36: 0, 37: 1, 38: 0, 39: 0, 40: 1, 41: 0, 42: 1, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 1, 50: 1, 51: 0, 52: 1, 53: 0, 54: 0, 55: 1, 56: 1, 57: 1, 58: 1, 59: 0, 60: 1, 61: 1, 62: 1, 63: 0, 64: 1, 65: 1, 66: 0, 67: 1, 68: 0, 69: 1, 70: 0, 71: 0, 72: 0, 73: 1, 74: 0, 75: 1, 76: 1, 77: 1, 78: 1, 79: 0, 80: 1, 81: 1, 82: 0, 83: 1, 84: 0, 85: 0, 86: 0, 87: 0, 88: 1, 89: 0, 90: 1, 91: 1, 92: 0, 93: 1, 94: 1, 95: 1, 96: 0, 97: 1, 98: 0, 99: 0, 100: 1, 101: 1, 102: 1, 103: 1, 104: 1, 105: 0, 106: 1, 107: 1, 108: 0, 109: 1, 110: 0, 111: 1, 112: 0, 113: 0, 114: 0, 115: 0, 116: 1, 117: 0, 118: 0, 119: 1, 120: 1, 121: 0, 122: 1, 123: 0, 124: 1, 125: 1, 126: 0, 127: 0, 128: 0, 129: 0, 130: 1, 131: 1, 132: 0, 133: 1, 134: 1, 135: 0, 136: 1, 137: 1, 138: 0, 139: 1, 140: 0, 141: 1, 142: 0, 143: 1, 144: 1, 145: 0, 146: 0, 147: 1, 148: 0, 149: 1, 150: 0, 151: 1, 152: 0, 153: 0, 154: 1, 155: 1, 156: 1, 157: 1, 158: 0, 159: 0, 160: 0, 161: 0, 162: 1, 163: 1, 164: 0, 165: 1, 166: 0, 167: 0, 168: 1, 169: 1, 170: 0, 171: 1, 172: 1, 173: 1, 174: 0, 175: 0, 176: 1, 177: 1, 178: 0, 179: 0, 180: 0, 181: 1, 182: 1, 183: 0, 184: 0, 185: 0, 186: 0, 187: 1, 188: 1, 189: 0, 190: 0, 191: 1, 192: 1, 193: 0, 194: 1, 195: 0, 196: 1, 197: 0, 198: 1, 199: 0, 200: 1, 201: 0, 202: 1, 203: 0, 204: 1, 205: 1, 206: 0, 207: 0, 208: 1, 209: 0, 210: 1, 211: 1, 212: 1, 213: 0, 214: 1, 215: 0, 216: 1, 217: 1, 218: 0, 219: 0, 220: 0, 221: 0, 222: 1, 223: 0, 224: 1, 225: 1, 226: 1, 227: 1, 228: 0, 229: 0, 230: 1, 231: 0, 232: 0, 233: 1, 234: 0, 235: 1, 236: 0, 237: 0, 238: 0, 239: 0, 240: 0, 241: 0, 242: 1, 243: 0, 244: 1, 245: 0, 246: 0, 247: 1, 248: 1, 249: 1, 250: 1, 251: 1, 252: 1, 253: 1, 254: 1, 255: 1, 256: 0, 257: 1, 258: 0, 259: 1, 260: 0, 261: 0, 262: 1, 263: 0, 264: 1, 265: 1, 266: 1, 267: 0, 268: 1, 269: 0, 270: 1, 271: 1, 272: 1, 273: 0, 274: 1, 275: 1, 276: 0, 277: 0, 278: 1, 279: 0, 280: 1, 281: 1, 282: 0, 283: 1, 284: 0, 285: 0, 286: 1, 287: 1, 288: 1, 289: 1, 290: 0, 291: 0, 292: 0, 293: 1, 294: 0, 295: 1, 296: 1, 297: 0, 298: 0, 299: 0, 300: 0, 301: 0, 302: 1, 303: 0, 304: 1, 305: 0, 306: 0, 307: 0, 308: 0, 309: 1, 310: 0, 311: 0, 312: 1, 313: 1, 314: 1, 315: 0, 316: 0, 317: 1, 318: 0, 319: 0, 320: 0, 321: 0, 322: 0, 323: 1, 324: 1, 325: 0, 326: 1, 327: 0, 328: 1, 329: 0, 330: 0, 331: 0, 332: 1, 333: 1, 334: 0, 335: 0, 336: 1, 337: 1, 338: 1, 339: 1, 340: 1, 341: 0, 342: 1, 343: 1, 344: 0, 345: 0, 346: 1, 347: 1, 348: 1, 349: 0, 350: 1, 351: 1, 352: 0, 353: 0, 354: 0, 355: 0, 356: 0, 357: 1, 358: 0, 359: 1, 360: 1, 361: 0, 362: 1, 363: 1, 364: 1, 365: 1, 366: 1, 367: 1, 368: 0, 369: 1, 370: 0, 371: 1, 372: 0, 373: 1, 374: 1, 375: 1, 376: 1, 377: 0, 378: 0, 379: 0, 380: 0, 381: 1, 382: 0, 383: 0, 384: 0, 385: 0, 386: 1, 387: 0, 388: 1, 389: 0, 390: 1, 391: 0, 392: 1, 393: 0, 394: 0, 395: 0, 396: 0, 397: 1, 398: 0, 399: 1, 400: 1, 401: 0, 402: 1, 403: 1, 404: 1, 405: 0, 406: 1, 407: 0, 408: 1, 409: 1, 410: 1, 411: 1, 412: 1, 413: 0, 414: 1, 415: 1, 416: 1, 417: 1, 418: 0, 419: 1, 420: 1, 421: 1, 422: 0, 423: 0, 424: 1, 425: 1, 426: 0, 427: 1, 428: 0, 429: 0, 430: 1, 431: 1, 432: 0, 433: 0, 434: 1, 435: 0, 436: 1, 437: 0, 438: 0, 439: 1, 440: 0, 441: 0, 442: 0, 443: 1, 444: 1, 445: 0, 446: 0, 447: 1, 448: 1, 449: 0, 450: 1, 451: 0, 452: 1, 453: 0, 454: 0, 455: 1, 456: 1, 457: 1, 458: 1, 459: 0, 460: 0, 461: 0, 462: 0, 463: 1, 464: 1, 465: 0, 466: 0, 467: 0, 468: 0, 469: 0, 470: 1, 471: 0, 472: 0, 473: 0, 474: 1, 475: 0, 476: 1, 477: 1, 478: 0, 479: 0, 480: 1, 481: 1, 482: 0, 483: 0, 484: 0, 485: 0, 486: 0, 487: 1, 488: 1, 489: 0, 490: 1, 491: 1, 492: 1, 493: 1, 494: 0, 495: 1, 496: 0, 497: 1, 498: 0, 499: 1, 500: 0, 501: 1, 502: 0, 503: 1, 504: 0, 505: 0, 506: 1, 507: 0, 508: 1, 509: 1, 510: 0, 511: 1, 512: 0, 513: 1, 514: 0, 515: 0, 516: 1, 517: 1, 518: 0, 519: 0, 520: 0, 521: 0, 522: 0, 523: 1, 524: 1, 525: 0, 526: 0, 527: 0, 528: 0, 529: 0, 530: 1, 531: 0, 532: 0, 533: 0, 534: 1, 535: 0, 536: 0, 537: 1, 538: 0, 539: 0, 540: 0, 541: 0, 542: 0, 543: 0, 544: 0, 545: 0, 546: 1, 547: 1, 548: 1, 549: 0, 550: 1, 551: 0, 552: 1, 553: 1, 554: 0, 555: 1, 556: 0, 557: 1, 558: 1, 559: 0, 560: 0, 561: 1, 562: 0, 563: 1, 564: 1, 565: 0, 566: 0, 567: 0, 568: 0, 569: 0, 570: 1, 571: 0, 572: 0, 573: 1, 574: 0, 575: 0, 576: 1, 577: 1, 578: 1, 579: 0, 580: 0, 581: 0, 582: 0, 583: 0, 584: 1, 585: 0, 586: 0, 587: 1, 588: 1, 589: 0, 590: 1, 591: 1, 592: 0, 593: 1, 594: 1, 595: 1, 596: 1, 597: 0, 598: 1, 599: 1, 600: 1, 601: 0, 602: 0, 603: 1, 604: 0, 605: 1, 606: 1, 607: 1, 608: 1, 609: 0, 610: 0, 611: 1, 612: 1, 613: 0, 614: 1, 615: 0, 616: 1, 617: 0, 618: 0, 619: 1, 620: 1, 621: 1, 622: 1, 623: 0, 624: 1, 625: 0, 626: 0, 627: 0, 628: 1, 629: 0, 630: 1, 631: 0, 632: 0, 633: 0, 634: 0, 635: 1, 636: 1, 637: 1, 638: 0, 639: 1, 640: 0, 641: 1, 642: 0, 643: 0, 644: 1, 645: 1, 646: 1, 647: 1, 648: 1, 649: 1, 650: 0, 651: 1, 652: 0, 653: 0, 654: 0, 655: 1, 656: 0, 657: 0, 658: 1, 659: 0, 660: 1, 661: 0, 662: 1, 663: 1, 664: 1, 665: 0, 666: 1, 667: 1, 668: 0, 669: 1, 670: 1, 671: 0, 672: 1, 673: 0, 674: 1, 675: 1, 676: 1, 677: 1, 678: 0, 679: 0, 680: 1, 681: 0, 682: 0, 683: 0, 684: 1, 685: 0, 686: 0, 687: 0, 688: 1, 689: 0, 690: 1, 691: 1, 692: 0, 693: 1, 694: 0, 695: 1, 696: 0, 697: 1, 698: 0, 699: 1, 700: 0, 701: 0, 702: 1, 703: 1, 704: 0, 705: 0, 706: 1, 707: 0, 708: 0, 709: 1, 710: 1, 711: 1, 712: 0, 713: 1, 714: 1, 715: 1, 716: 1, 717: 1, 718: 1, 719: 0, 720: 0, 721: 0, 722: 0, 723: 1, 724: 0, 725: 0, 726: 0, 727: 1, 728: 0, 729: 1, 730: 1, 731: 1, 732: 1, 733: 0, 734: 1, 735: 0, 736: 1, 737: 0, 738: 0, 739: 1, 740: 0, 741: 1, 742: 1, 743: 1, 744: 0, 745: 1, 746: 0, 747: 1, 748: 0, 749: 0, 750: 0, 751: 1, 752: 0, 753: 1, 754: 0, 755: 1, 756: 0, 757: 0, 758: 1, 759: 0, 760: 0, 761: 1, 762: 1, 763: 0, 764: 1, 765: 1, 766: 0, 767: 1, 768: 0, 769: 1, 770: 0, 771: 0, 772: 0, 773: 0, 774: 0, 775: 1, 776: 0, 777: 1, 778: 1, 779: 0, 780: 1, 781: 0, 782: 0, 783: 1, 784: 0, 785: 0, 786: 0, 787: 0, 788: 0, 789: 1, 790: 1, 791: 1, 792: 0, 793: 0, 794: 0, 795: 0, 796: 1, 797: 0, 798: 1, 799: 1, 800: 1}
-9699.0
-8621.0
dealing G24.txt
device 0 start to train
[n] 500 [C] 1220 weight 2000
con_list_range [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 499, 500]
average_loss tensor(-2496.3623, device='cuda:0', grad_fn=<DivBackward0>) best_loss inf
Epoch 0 Epoch time:  3.706912040710449 current loss tensor(-2503.9897, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.4746, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.3623, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1 Epoch time:  3.2983765602111816 current loss tensor(-2504.0864, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.5845, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.4746, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2 Epoch time:  3.189850091934204 current loss tensor(-2504.1807, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.6921, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.5845, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3 Epoch time:  3.196267604827881 current loss tensor(-2504.2727, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.7971, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.6921, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4 Epoch time:  3.3302206993103027 current loss tensor(-2504.3623, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.8994, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.7971, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5 Epoch time:  3.270746946334839 current loss tensor(-2504.4492, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2496.9995, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.8994, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6 Epoch time:  3.3064866065979004 current loss tensor(-2504.5342, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.0969, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2496.9995, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7 Epoch time:  3.211886167526245 current loss tensor(-2504.6167, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.1919, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.0969, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8 Epoch time:  3.235788106918335 current loss tensor(-2504.6968, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.2842, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.1919, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9 Epoch time:  3.234097719192505 current loss tensor(-2504.7744, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.3740, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.2842, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10 Epoch time:  3.2035117149353027 current loss tensor(-2504.8501, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.4614, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.3740, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11 Epoch time:  3.319028854370117 current loss tensor(-2504.9226, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.5461, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.4614, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12 Epoch time:  3.28493332862854 current loss tensor(-2504.9937, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.6282, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.5461, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13 Epoch time:  3.215975761413574 current loss tensor(-2505.0618, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.7080, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.6282, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14 Epoch time:  3.2605016231536865 current loss tensor(-2505.1279, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.7856, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.7080, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15 Epoch time:  3.2074646949768066 current loss tensor(-2505.1919, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.8608, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.7856, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16 Epoch time:  3.2114005088806152 current loss tensor(-2505.2539, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2497.9331, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.8608, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17 Epoch time:  3.2574288845062256 current loss tensor(-2505.3135, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.0034, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2497.9331, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18 Epoch time:  3.3497912883758545 current loss tensor(-2505.3711, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.0718, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.0034, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19 Epoch time:  3.223853826522827 current loss tensor(-2505.4265, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.1372, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.0718, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20 Epoch time:  3.2253167629241943 current loss tensor(-2505.4800, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.2012, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.1372, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21 Epoch time:  3.3214333057403564 current loss tensor(-2505.5317, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.2627, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.2012, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22 Epoch time:  3.224057674407959 current loss 2.832226037979126 current loss tensor(-2394.5986, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.8441786766052246 current loss tensor(-2394.7146, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  3.379275321960449 current loss tensor(-2394.8286, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.824303388595581 current loss tensor(-2394.9399, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.8811964988708496 current loss tensor(-2395.0493, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.8420655727386475 current loss tensor(-2395.1567, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.865382432937622 current loss tensor(-2395.2617, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.8385605812072754 current loss tensor(-2395.3647, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.8799123764038086 current loss tensor(-2395.4658, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.8773491382598877 current loss tensor(-2395.5647, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.918581962585449 current loss tensor(-2395.6621, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.9110219478607178 current loss tensor(-2395.7568, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  3.038206100463867 current loss tensor(-2395.8501, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.912003517150879 current loss tensor(-2395.9412, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.951021909713745 current loss tensor(-2396.0308, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.9250388145446777 current loss tensor(-2396.1182, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.873530387878418 current loss tensor(-2396.2041, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.8356199264526367 current loss tensor(-2396.2881, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.879099130630493 current loss tensor(-2396.3706, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.8383636474609375 current loss tensor(-2396.4512, device='cuda:2', grad_fn=<SumBackward0>)
dealing G24.txt
device 2 start to train
[n] 500 [C] 1300 weight 2000
con_list_range [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500]
Epoch 0 Epoch time:  3.5159335136413574 current loss tensor(-2504.6189, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.094095230102539 current loss tensor(-2504.7295, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.197488307952881 current loss tensor(-2504.8379, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.2001752853393555 current loss tensor(-2504.9434, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.2015838623046875 current loss tensor(-2505.0466, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.202348232269287 current loss tensor(-2505.1470, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.3813061714172363 current loss tensor(-2505.2451, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.1584908962249756 current loss tensor(-2505.3408, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.2017557621002197 current loss tensor(-2505.4333, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.257282018661499 current loss tensor(-2505.5239, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.194722890853882 current loss tensor(-2505.6113, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.204957962036133 current loss tensor(-2505.6968, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.2307300567626953 current loss tensor(-2505.7793, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.187227249145508 current loss tensor(-2505.8594, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.3221728801727295 current loss tensor(-2505.9370, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.1977086067199707 current loss tensor(-2506.0122, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.182523488998413 current loss tensor(-2506.0850, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.204327344894409 current loss tensor(-2506.1553, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.245476722717285 current loss tensor(-2506.2236, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.22636079788208 current loss tensor(-2506.2896, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.231243371963501 current loss tensor(-2506.3530, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.192150115966797 current loss tensor(-2506.4146, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.190828800201416 current loss tensor(-2506.4739, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.351184368133545 current loss tensor(-2506.5312, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.1763248443603516 current loss tensor(-2506.5864, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.2127976417541504 current loss tensor(-2372.1758, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.8026793003082275 current loss tensor(-2372.3274, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.844937324523926 current loss tensor(-2372.4766, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.8373966217041016 current loss tensor(-2372.6228, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.932866334915161 current loss tensor(-2372.7671, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.7557220458984375 current loss tensor(-2372.9087, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.8018805980682373 current loss tensor(-2373.0479, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.842163324356079 current loss tensor(-2373.1846, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.881392002105713 current loss tensor(-2373.3188, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.8893496990203857 current loss tensor(-2373.4512, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.8737270832061768 current loss tensor(-2373.5811, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.8783161640167236 current loss tensor(-2373.7085, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.8820064067840576 current loss tensor(-2373.8340, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.882659673690796 current loss tensor(-2373.9568, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  3.0298984050750732 current loss tensor(-2374.0776, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.8407299518585205 current loss tensor(-2374.1968, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.8116958141326904 current loss tensor(-2374.3135, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.8431994915008545 current loss tensor(-2374.4282, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.7975244522094727 current loss tensor(-2374.5405, device='cuda:3', grad_fn=<SumBackward0>)
dealing G24.txt
device 3 start to train
[n] 500 [C] 1230 weight 2000
con_list_range [1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000]
Epoch 0 Epoch time:  3.704591751098633 current loss tensor(-2486.9331, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.044020414352417 current loss tensor(-2487.0635, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.143810749053955 current loss tensor(-2487.1909, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.181018114089966 current loss tensor(-2487.3159, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.2090067863464355 current loss tensor(-2487.4387, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.213268280029297 current loss tensor(-2487.5583, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.2112011909484863 current loss tensor(-2487.6758, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.164411783218384 current loss tensor(-2487.7905, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.331160545349121 current loss tensor(-2487.9028, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.1227757930755615 current loss tensor(-2488.0120, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.2506484985351562 current loss tensor(-2488.1187, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.176481246948242 current loss tensor(-2488.2229, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.1885838508605957 current loss tensor(-2488.3242, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.1414921283721924 current loss tensor(-2488.4231, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.214247941970825 current loss tensor(-2488.5190, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.1426119804382324 current loss tensor(-2488.6125, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.1622424125671387 current loss tensor(-2488.7036, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.3287882804870605 current loss tensor(-2488.7917, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.127370834350586 current loss tensor(-2488.8774, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.189140558242798 current loss tensor(-2488.9607, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.1777498722076416 current loss tensor(-2489.0413, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.187127113342285 current loss tensor(-2489.1196, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.152883529663086 current loss tensor(-2489.1953, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.1872177124023438 current loss tensor(-2489.2688, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.190171957015991 current loss tensor(-2489.3401, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.3383827209472656 current loss tensor(-2489.4092, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.114215850830078 current loss 2.8476169109344482 current loss tensor(-2436.5840, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.8471782207489014 current loss tensor(-2436.6736, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.9821622371673584 current loss tensor(-2436.7612, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.9389827251434326 current loss tensor(-2436.8467, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.8551011085510254 current loss tensor(-2436.9302, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.8800811767578125 current loss tensor(-2437.0117, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.8501622676849365 current loss tensor(-2437.0911, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.9259114265441895 current loss tensor(-2437.1685, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.888637065887451 current loss tensor(-2437.2444, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  3.102511405944824 current loss tensor(-2437.3184, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.970587730407715 current loss tensor(-2437.3901, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.977313756942749 current loss tensor(-2437.4604, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.9721152782440186 current loss tensor(-2437.5288, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.9597387313842773 current loss tensor(-2437.5952, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.989621639251709 current loss tensor(-2437.6606, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.937988758087158 current loss tensor(-2437.7236, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.8594634532928467 current loss tensor(-2437.7854, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.9104421138763428 current loss tensor(-2437.8452, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.985821008682251 current loss tensor(-2437.9038, device='cuda:1', grad_fn=<SumBackward0>)
dealing G24.txt
device 1 start to train
[n] 500 [C] 1240 weight 2000
con_list_range [501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]
Epoch 0 Epoch time:  3.5952961444854736 current loss tensor(-2489.9075, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  3.105889081954956 current loss tensor(-2490.0195, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  3.2197775840759277 current loss tensor(-2490.1292, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  3.2046287059783936 current loss tensor(-2490.2361, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  3.346254587173462 current loss tensor(-2490.3408, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  3.1637911796569824 current loss tensor(-2490.4431, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  3.2709927558898926 current loss tensor(-2490.5427, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  3.2907943725585938 current loss tensor(-2490.6399, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  3.243499755859375 current loss tensor(-2490.7344, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  3.218517780303955 current loss tensor(-2490.8264, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  3.2353975772857666 current loss tensor(-2490.9160, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  3.2158243656158447 current loss tensor(-2491.0029, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  3.401279926300049 current loss tensor(-2491.0874, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  3.183056592941284 current loss tensor(-2491.1692, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  3.2688181400299072 current loss tensor(-2491.2485, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  3.225153923034668 current loss tensor(-2491.3257, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  3.227046251296997 current loss tensor(-2491.4001, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  3.2157981395721436 current loss tensor(-2491.4722, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  3.270458459854126 current loss tensor(-2491.5420, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  3.2956748008728027 current loss tensor(-2491.6096, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  3.214165687561035 current loss tensor(-2491.6753, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  3.358541250228882 current loss tensor(-2491.7383, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  3.166212558746338 current loss tensor(-2491.7993, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  3.2281079292297363 current loss tensor(-2491.8579, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  3.2741613388061523 current loss tensor(-2491.9150, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  3.23629093170166 current loss tensor(-2491.9702, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.2485227584838867 current loss tensor(-2492.0234, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.2688751220703125 current loss tensor(-2492.0747, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.228644609451294 current loss tensor(-2492.1240, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.226001262664795 current loss tensor(-2492.1721, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.3907015323638916 current loss tensor(-2505.5815, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.3220, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.2627, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23 Epoch time:  3.302097797393799 current loss tensor(-2505.6296, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.3794, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.3220, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24 Epoch time:  3.240917444229126 current loss tensor(-2505.6758, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.4351, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.3794, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25 Epoch time:  3.2451295852661133 current loss tensor(-2505.7202, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.4885, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.4351, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26 Epoch time:  3.359778642654419 current loss tensor(-2505.7634, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.5405, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.4885, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27 Epoch time:  3.22979736328125 current loss tensor(-2505.8052, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.5906, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.5405, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28 Epoch time:  3.2300243377685547 current loss tensor(-2505.8452, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.6389, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.5906, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29 Epoch time:  3.2789154052734375 current loss tensor(-2505.8838, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.6860, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.6389, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30 Epoch time:  3.310006618499756 current loss tensor(-2505.9214, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.7314, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.6860, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31 Epoch time:  3.291511058807373 current loss tensor(-2505.9575, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.7754, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.7314, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32 Epoch time:  3.236807346343994 current loss tensor(-2505.9927, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.8179, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.7754, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33 Epoch time:  3.232956647872925 current loss tensor(-2506.0266, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.8589, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.8179, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34 Epoch time:  3.288029432296753 current loss tensor(-2506.0596, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.8989, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.8589, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35 Epoch time:  3.8848960399627686 current loss tensor(-2506.0913, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.9377, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.8989, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36 Epoch time:  3.751474380493164 current loss tensor(-2506.1226, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2498.9756, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.9377, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37 Epoch time:  3.7577810287475586 current loss tensor(-2506.1528, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.0117, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2498.9756, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38 Epoch time:  3.741511344909668 current loss tensor(-2506.1824, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.0474, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.0117, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39 Epoch time:  3.750906467437744 current loss tensor(-2506.2109, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.0820, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.0474, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40 Epoch time:  3.7450106143951416 current loss tensor(-2506.2393, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.1157, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.0820, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41 Epoch time:  3.742764949798584 current loss tensor(-2506.2666, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.1484, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.1157, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42 Epoch time:  3.679966449737549 current loss tensor(-2506.2935, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.1802, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.1484, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43 Epoch time:  3.3579702377319336 current loss tensor(-2506.3198, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.2117, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.1802, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44 Epoch time:  3.223032236099243 current loss tensor(-2506.3457, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.2419, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.2117, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45 Epoch time:  3.228316307067871 current loss tensor(-2506.3711, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.2717, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.2419, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46 Epoch time:  3.316575765609741 current loss tensor(-2506.3955, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3008, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.2717, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47 Epoch time:  3.2289059162139893 current loss tensor(-2506.4202, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3293, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3008, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48 Epoch time:  3.2371819019317627 current loss tensor(-2506.4443, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3574, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3293, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49 Epoch time:  3.30096435546875 current loss tensor(-2506.4683, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.3848, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3574, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 50 Epoch time:  3.2216570377349854 current loss tensor(-2506.4917, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4119, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.3848, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 51 Epoch time:  3.2459073066711426 current loss tensor(-2506.5151, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4385, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4119, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 52 Epoch time:  3.381117820739746 current loss tensor(-2506.5383, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4646, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4385, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 53 Epoch time:  3.226762533187866 current loss tensor(-2506.5613, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.4905, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4646, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 54 Epoch time:  3.226445436477661 current loss tensor(-2506.5840, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5156, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.4905, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 55 Epoch time:  3.2298614978790283 current loss tensor(-2506.6064, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5408, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5156, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 56 Epoch time:  3.301434278488159 current loss tensor(-2506.6289, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5654, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5408, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 57 Epoch time:  3.291559934616089 current loss tensor(-2506.6509, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.5896, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5654, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 58 Epoch time:  3.2616827487945557 current loss tensor(-2506.6731, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6138, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.5896, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 59 Epoch time:  3.227433204650879 current loss tensor(-2506.6953, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6377, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6138, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 60 Epoch time:  3.2584800720214844 current loss tensor(-2506.7168, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6611, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6377, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 61 Epoch time:  3.341949224472046 current loss tensor(-2506.7388, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.6846, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6611, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 62 Epoch time:  3.223172664642334 current loss tensor(-2506.7603, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.7075, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.6846, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 63 Epoch time:  3.2378199100494385 current loss tensor(-2506.7817, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.7305, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.7075, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 64 Epoch time:  3.29026198387146 current loss tensor(-2506.8032, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.7534, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.7305, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 65 Epoch time:  3.5605859756469727 current loss tensor(-2506.8247, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.7756, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.7534, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 66 Epoch time:  3.2800979614257812 current loss tensor(-2506.8459, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.7983, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.7756, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 67 Epoch time:  3.226931095123291 current loss tensor(-2506.8672, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.8203, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.7983, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 68 Epoch time:  3.262733221054077 current loss tensor(-2506.8884, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.8425, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.8203, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 69 Epoch time:  3.348560094833374 current loss tensor(-2506.9097, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.8643, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.8425, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 70 Epoch time:  3.223395586013794 current loss tensor(-2506.9307, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.8862, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.8643, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 71 Epoch time:  3.2301454544067383 current loss tensor(-2506.9517, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.9080, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.8862, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 72 Epoch time:  3.229959487915039 current loss tensor(-2506.9727, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.9297, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.9080, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 73 Epoch time:  3.3269262313842773 current loss tensor(-2506.9937, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.9512, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.9297, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 74 Epoch time:  3.303619146347046 current loss tensor(-2507.0146, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.9727, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.9512, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 75 Epoch time:  3.225274085998535 current loss tensor(-2507.0356, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2499.9941, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.9727, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 76 Epoch time:  3.226449728012085 current loss tensor(-2507.0566, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.0151, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2499.9941, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 77 Epoch time:  3.2649457454681396 current loss tensor(-2507.0771, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.0366, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.0151, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 78 Epoch time:  3.341571569442749 current loss tensor(-2507.0981, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.0581, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.0366, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 79 Epoch time:  3.2224552631378174 current loss tensor(-2507.1189, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.0791, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.0581, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 80 Epoch time:  3.219996929168701 current loss tensor(-2507.1396, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.1001, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.0791, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 81 Epoch time:  3.228316068649292 current loss tensor(-2507.1606, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.1211, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.1001, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 82 Epoch time:  3.249534845352173 current loss tensor(-2507.1812, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.1423, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.1211, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 83 Epoch time:  3.358682870864868 current loss tensor(-2507.2021, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.1633, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.1423, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 84 Epoch time:  3.2213938236236572 current loss tensor(-2507.2227, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.1843, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.1633, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 85 Epoch time:  3.2261877059936523 current loss tensor(-2507.2437, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.2051, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.1843, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 86 Epoch time:  current loss tensor(-2506.6399, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  3.243834972381592 current loss tensor(-2506.6914, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.252535581588745 current loss tensor(-2506.7412, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.2077367305755615 current loss tensor(-2506.7896, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.210500478744507 current loss tensor(-2506.8359, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.2563321590423584 current loss tensor(-2506.8809, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.3292315006256104 current loss tensor(-2506.9243, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.162766933441162 current loss tensor(-2506.9663, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.208754777908325 current loss tensor(-2507.0068, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.2154312133789062 current loss tensor(-2507.0464, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.4139816761016846 current loss tensor(-2507.0845, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.3402247428894043 current loss tensor(-2507.1216, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.315871238708496 current loss tensor(-2507.1575, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.3445308208465576 current loss tensor(-2507.1921, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.361609697341919 current loss tensor(-2507.2258, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.4350337982177734 current loss tensor(-2507.2588, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.330652952194214 current loss tensor(-2507.2908, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.3345582485198975 current loss tensor(-2507.3220, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.241565704345703 current loss tensor(-2507.3525, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.2601516246795654 current loss tensor(-2507.3821, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.2111246585845947 current loss tensor(-2507.4109, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.2107222080230713 current loss tensor(-2507.4392, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.203704833984375 current loss tensor(-2507.4670, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.2260053157806396 current loss tensor(-2507.4941, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.3517539501190186 current loss tensor(-2507.5210, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.151508331298828 current loss tensor(-2507.5469, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.199444055557251 current loss tensor(-2507.5728, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.229311943054199 current loss tensor(-2507.5979, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.256204843521118 current loss tensor(-2507.6226, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.2219173908233643 current loss tensor(-2507.6475, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.179922103881836 current loss tensor(-2507.6714, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.211474657058716 current loss tensor(-2507.6951, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.3078227043151855 current loss tensor(-2507.7185, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.15000057220459 current loss tensor(-2507.7417, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.2413203716278076 current loss tensor(-2507.7642, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.173185110092163 current loss tensor(-2507.7871, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.2326433658599854 current loss tensor(-2507.8091, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.248965263366699 current loss tensor(-2507.8315, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.196094512939453 current loss tensor(-2507.8535, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.246723175048828 current loss tensor(-2507.8750, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.578390598297119 current loss tensor(-2507.8967, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.27197527885437 current loss tensor(-2507.9180, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  3.1571881771087646 current loss tensor(-2507.9395, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  3.202828884124756 current loss tensor(-2507.9604, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  3.2492196559906006 current loss tensor(-2507.9814, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  3.2501039505004883 current loss tensor(-2508.0020, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  3.216968297958374 current loss tensor(-2508.0229, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  3.235273599624634 current loss tensor(-2508.0432, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  3.1991682052612305 current loss tensor(-2508.0640, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  3.3252570629119873 current loss tensor(-2508.0842, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  3.170691728591919 current loss tensor(-2508.1045, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  3.2222859859466553 current loss tensor(-2508.1250, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  3.205350875854492 current loss tensor(-2508.1450, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  3.251986026763916 current loss tensor(-2508.1655, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  3.239381790161133 current loss tensor(-2508.1855, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  3.2096645832061768 current loss tensor(-2508.2056, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  3.2314000129699707 current loss tensor(-2508.2251, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  3.219420909881592 current loss tensor(-2508.2451, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  3.3625190258026123 current loss tensor(-2508.2651, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  3.253791570663452 current loss tensor(-2508.2852, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  3.1772100925445557 current loss tensor(-2508.3047, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  3.217798948287964 current loss tensor(-2508.3247, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  3.2505948543548584 current loss tensor(-2508.3445, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  3.2396137714385986 current loss tensor(-2508.3643, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  3.226172685623169 current loss tensor(-2508.3838, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  3.219224214553833 current loss tensor(-2508.4038, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  3.2090463638305664 current loss tensor(-2508.4233, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  3.215982437133789 current loss tensor(-2508.4431, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  3.3281798362731934 current loss tensor(-2508.4629, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  3.1533522605895996 current loss tensor(-2508.4827, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  3.225309371948242 current loss tensor(-2508.5024, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  3.24432635307312 current loss tensor(-2508.5220, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  3.1991701126098633 current loss tensor(-2489.4761, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  3.1859610080718994 current loss tensor(-2489.5408, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  3.2102932929992676 current loss tensor(-2489.6035, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  3.2628445625305176 current loss tensor(-2489.6643, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  3.221918821334839 current loss tensor(-2489.7231, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.1471588611602783 current loss tensor(-2489.7803, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.166645050048828 current loss tensor(-2489.8357, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.186332941055298 current loss tensor(-2489.8892, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.3321375846862793 current loss tensor(-2489.9414, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.249333620071411 current loss tensor(-2489.9917, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.3035871982574463 current loss tensor(-2490.0405, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.3011879920959473 current loss tensor(-2490.0879, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.302839994430542 current loss tensor(-2490.1338, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.288635492324829 current loss tensor(-2490.1787, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.3178374767303467 current loss tensor(-2490.2222, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.31436824798584 current loss tensor(-2490.2646, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.308610677719116 current loss tensor(-2490.3057, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.370833396911621 current loss tensor(-2490.3457, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.2088849544525146 current loss tensor(-2490.3845, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.2101385593414307 current loss tensor(-2490.4226, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.2501416206359863 current loss tensor(-2490.4597, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.1909661293029785 current loss tensor(-2490.4958, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.225248336791992 current loss tensor(-2490.5310, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.23917555809021 current loss tensor(-2490.5654, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.1856508255004883 current loss tensor(-2490.5991, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.337491750717163 current loss tensor(-2490.6323, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.1365575790405273 current loss tensor(-2490.6646, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.236265182495117 current loss tensor(-2490.6963, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.221126079559326 current loss tensor(-2490.7275, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.229292631149292 current loss tensor(-2490.7583, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.281874179840088 current loss tensor(-2490.7883, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.1900203227996826 current loss tensor(-2490.8179, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.1970181465148926 current loss tensor(-2490.8469, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.205467462539673 current loss tensor(-2490.8755, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.3328394889831543 current loss tensor(-2490.9038, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.171722173690796 current loss tensor(-2490.9316, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.229252815246582 current loss tensor(-2490.9590, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.2183380126953125 current loss tensor(-2490.9858, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.2311832904815674 current loss tensor(-2491.0125, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.2304799556732178 current loss tensor(-2491.0391, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.1873741149902344 current loss tensor(-2491.0652, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  3.189967632293701 current loss tensor(-2491.0913, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  3.3541293144226074 current loss tensor(-2491.1167, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  3.1301920413970947 current loss tensor(-2491.1421, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  3.2332522869110107 current loss tensor(-2491.1675, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  3.228379011154175 current loss tensor(-2491.1924, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  3.219630479812622 current loss tensor(-2491.2173, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  3.2311182022094727 current loss tensor(-2491.2419, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  3.182793617248535 current loss tensor(-2491.2666, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  3.18023681640625 current loss tensor(-2491.2910, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  3.239720344543457 current loss tensor(-2491.3154, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  3.341925859451294 current loss tensor(-2491.3394, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  3.137251138687134 current loss tensor(-2491.3635, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  3.223661184310913 current loss tensor(-2491.3877, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  3.260495662689209 current loss tensor(-2491.4116, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  3.1894521713256836 current loss tensor(-2491.4353, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  3.2213385105133057 current loss tensor(-2491.4592, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  3.2378945350646973 current loss tensor(-2491.4832, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  3.187972068786621 current loss tensor(-2491.5068, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  3.201594114303589 current loss tensor(-2491.5303, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  3.2517051696777344 current loss tensor(-2491.5540, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  3.340930938720703 current loss tensor(-2491.5776, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  3.135493516921997 current loss tensor(-2491.6011, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  3.229438066482544 current loss tensor(-2491.6248, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  3.2245912551879883 current loss tensor(-2491.6484, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  3.226306200027466 current loss tensor(-2491.6719, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  3.159452199935913 current loss tensor(-2491.6958, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  3.221419095993042 current loss tensor(-2491.7192, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  3.195744276046753 current loss tensor(-2491.7429, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  3.3536393642425537 current loss tensor(-2491.7668, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  3.2333943843841553 current loss tensor(-2491.7905, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  3.1992125511169434 current loss tensor(-2491.8142, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  3.230375289916992 current loss 3.3318381309509277 current loss tensor(-2507.2642, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.2266, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.2051, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 87 Epoch time:  3.241879463195801 current loss tensor(-2507.2852, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.2471, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.2266, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 88 Epoch time:  3.235365390777588 current loss tensor(-2507.3057, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.2681, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.2471, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 89 Epoch time:  3.2303266525268555 current loss tensor(-2507.3262, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.2891, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.2681, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 90 Epoch time:  3.2246623039245605 current loss tensor(-2507.3472, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.3101, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.2891, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 91 Epoch time:  3.296196699142456 current loss tensor(-2507.3677, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.3311, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.3101, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 92 Epoch time:  3.2393760681152344 current loss tensor(-2507.3887, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.3521, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.3311, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 93 Epoch time:  3.271984577178955 current loss tensor(-2507.4094, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.3730, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.3521, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 94 Epoch time:  3.2317593097686768 current loss tensor(-2507.4302, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.3943, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.3730, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 95 Epoch time:  3.3602306842803955 current loss tensor(-2507.4512, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.4150, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.3943, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 96 Epoch time:  3.2183642387390137 current loss tensor(-2507.4722, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.4360, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.4150, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 97 Epoch time:  3.2399816513061523 current loss tensor(-2507.4927, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.4573, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.4360, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 98 Epoch time:  3.227898120880127 current loss tensor(-2507.5137, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-2500.4785, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-2500.4573, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 99 Epoch time:  3.2264997959136963 current loss tensor(-2507.5347, device='cuda:0', grad_fn=<SumBackward0>)
best_out [0.46794415 0.5536527  0.44220415 ... 0.4708391  0.39614448 0.4768409 ]
info_input_total 2000 weights 2000 total_C 19990
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
-10087
res {1: 1, 2: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 1, 16: 1, 17: 1, 18: 0, 19: 1, 20: 1, 21: 1, 22: 0, 23: 1, 24: 1, 25: 0, 26: 1, 27: 0, 28: 1, 29: 1, 30: 1, 31: 0, 32: 1, 33: 1, 34: 0, 35: 0, 36: 1, 37: 1, 38: 1, 39: 0, 40: 0, 41: 0, 42: 0, 43: 1, 44: 0, 45: 1, 46: 0, 47: 0, 48: 0, 49: 0, 50: 1, 51: 1, 52: 0, 53: 1, 54: 0, 55: 1, 56: 0, 57: 0, 58: 1, 59: 0, 60: 0, 61: 0, 62: 1, 63: 0, 64: 0, 65: 0, 66: 1, 67: 0, 68: 0, 69: 1, 70: 0, 71: 0, 72: 0, 73: 1, 74: 0, 75: 1, 76: 0, 77: 0, 78: 1, 79: 1, 80: 0, 81: 1, 82: 1, 83: 1, 84: 0, 85: 1, 86: 0, 87: 0, 88: 0, 89: 0, 90: 1, 91: 1, 92: 0, 93: 0, 94: 1, 95: 0, 96: 0, 97: 0, 98: 0, 99: 0, 100: 0, 101: 1, 102: 0, 103: 0, 104: 1, 105: 0, 106: 0, 107: 1, 108: 0, 109: 1, 110: 0, 111: 0, 112: 1, 113: 0, 114: 1, 115: 0, 116: 1, 117: 1, 118: 0, 119: 1, 120: 1, 121: 1, 122: 1, 123: 0, 124: 1, 125: 0, 126: 0, 127: 0, 128: 0, 129: 1, 130: 1, 131: 0, 132: 0, 133: 0, 134: 1, 135: 0, 136: 0, 137: 1, 138: 0, 139: 0, 140: 0, 141: 0, 142: 0, 143: 0, 144: 1, 145: 1, 146: 1, 147: 0, 148: 0, 149: 0, 150: 0, 151: 0, 152: 1, 153: 1, 154: 0, 155: 1, 156: 1, 157: 1, 158: 0, 159: 0, 160: 1, 161: 1, 162: 0, 163: 0, 164: 0, 165: 0, 166: 0, 167: 0, 168: 1, 169: 0, 170: 1, 171: 1, 172: 1, 173: 0, 174: 1, 175: 0, 176: 1, 177: 0, 178: 0, 179: 1, 180: 1, 181: 0, 182: 0, 183: 0, 184: 0, 185: 1, 186: 1, 187: 1, 188: 0, 189: 1, 190: 1, 191: 0, 192: 1, 193: 0, 194: 0, 195: 0, 196: 0, 197: 1, 198: 1, 199: 0, 200: 0, 201: 0, 202: 0, 203: 1, 204: 1, 205: 0, 206: 1, 207: 1, 208: 0, 209: 1, 210: 0, 211: 0, 212: 0, 213: 1, 214: 1, 215: 1, 216: 1, 217: 1, 218: 0, 219: 1, 220: 1, 221: 1, 222: 0, 223: 1, 224: 0, 225: 0, 226: 0, 227: 0, 228: 1, 229: 0, 230: 1, 231: 0, 232: 0, 233: 1, 234: 1, 235: 0, 236: 0, 237: 1, 238: 1, 239: 0, 240: 0, 241: 1, 242: 0, 243: 0, 244: 0, 245: 1, 246: 0, 247: 0, 248: 1, 249: 1, 250: 0, 251: 1, 252: 1, 253: 1, 254: 1, 255: 1, 256: 0, 257: 0, 258: 1, 259: 1, 260: 0, 261: 0, 262: 0, 263: 0, 264: 0, 265: 0, 266: 0, 267: 1, 268: 0, 269: 0, 270: 0, 271: 0, 272: 0, 273: 1, 274: 0, 275: 1, 276: 0, 277: 1, 278: 1, 279: 1, 280: 1, 281: 1, 282: 0, 283: 0, 284: 1, 285: 1, 286: 0, 287: 1, 288: 0, 289: 0, 290: 1, 291: 0, 292: 1, 293: 0, 294: 0, 295: 1, 296: 1, 297: 1, 298: 0, 299: 1, 300: 0, 301: 0, 302: 0, 303: 1, 304: 1, 305: 0, 306: 0, 307: 1, 308: 1, 309: 0, 310: 0, 311: 1, 312: 1, 313: 1, 314: 0, 315: 0, 316: 1, 317: 0, 318: 1, 319: 0, 320: 0, 321: 0, 322: 0, 323: 1, 324: 0, 325: 0, 326: 0, 327: 1, 328: 1, 329: 0, 330: 0, 331: 1, 332: 1, 333: 1, 334: 1, 335: 1, 336: 1, 337: 1, 338: 1, 339: 0, 340: 1, 341: 0, 342: 1, 343: 0, 344: 0, 345: 0, 346: 1, 347: 0, 348: 1, 349: 1, 350: 0, 351: 1, 352: 1, 353: 0, 354: 0, 355: 1, 356: 1, 357: 0, 358: 0, 359: 0, 360: 1, 361: 1, 362: 0, 363: 1, 364: 0, 365: 1, 366: 1, 367: 1, 368: 0, 369: 0, 370: 0, 371: 1, 372: 0, 373: 1, 374: 0, 375: 1, 376: 0, 377: 0, 378: 0, 379: 0, 380: 1, 381: 0, 382: 0, 383: 1, 384: 0, 385: 1, 386: 1, 387: 1, 388: 1, 389: 1, 390: 1, 391: 0, 392: 0, 393: 1, 394: 0, 395: 1, 396: 0, 397: 1, 398: 1, 399: 0, 400: 1, 401: 1, 402: 0, 403: 1, 404: 1, 405: 1, 406: 0, 407: 1, 408: 0, 409: 1, 410: 1, 411: 1, 412: 1, 413: 1, 414: 0, 415: 1, 416: 0, 417: 0, 418: 1, 419: 1, 420: 0, 421: 0, 422: 0, 423: 1, 424: 1, 425: 0, 426: 1, 427: 1, 428: 1, 429: 1, 430: 1, 431: 1, 432: 1, 433: 0, 434: 0, 435: 1, 436: 1, 437: 1, 438: 1, 439: 0, 440: 1, 441: 0, 442: 0, 443: 0, 444: 1, 445: 1, 446: 0, 447: 1, 448: 1, 449: 1, 450: 0, 451: 0, 452: 0, 453: 1, 454: 0, 455: 1, 456: 1, 457: 1, 458: 1, 459: 0, 460: 1, 461: 1, 462: 1, 463: 1, 464: 0, 465: 1, 466: 1, 467: 0, 468: 0, 469: 0, 470: 0, 471: 0, 472: 1, 473: 1, 474: 1, 475: 1, 476: 0, 477: 1, 478: 0, 479: 1, 480: 0, 481: 1, 482: 0, 483: 1, 484: 1, 485: 1, 486: 0, 487: 0, 488: 1, 489: 1, 490: 1, 491: 1, 492: 0, 493: 0, 494: 1, 495: 1, 496: 1, 497: 1, 498: 0, 499: 1, 500: 0, 501: 1, 502: 0, 503: 1, 504: 0, 505: 0, 506: 1, 507: 0, 508: 1, 509: 1, 510: 0, 511: 0, 512: 0, 513: 1, 514: 0, 515: 0, 516: 1, 517: 1, 518: 0, 519: 0, 520: 0, 521: 1, 522: 0, 523: 1, 524: 1, 525: 1, 526: 0, 527: 0, 528: 0, 529: 1, 530: 1, 531: 0, 532: 0, 533: 0, 534: 1, 535: 0, 536: 0, 537: 1, 538: 0, 539: 0, 540: 1, 541: 0, 542: 0, 543: 0, 544: 0, 545: 0, 546: 1, 547: 1, 548: 1, 549: 0, 550: 1, 551: 0, 552: 1, 553: 1, 554: 0, 555: 1, 556: 1, 557: 1, 558: 1, 559: 0, 560: 0, 561: 1, 562: 0, 563: 1, 564: 0, 565: 0, 566: 0, 567: 0, 568: 0, 569: 0, 570: 1, 571: 0, 572: 0, 573: 1, 574: 0, 575: 0, 576: 1, 577: 1, 578: 1, 579: 0, 580: 0, 581: 0, 582: 0, 583: 0, 584: 1, 585: 0, 586: 0, 587: 1, 588: 1, 589: 0, 590: 1, 591: 1, 592: 0, 593: 0, 594: 1, 595: 1, 596: 1, 597: 0, 598: 1, 599: 1, 600: 1, 601: 1, 602: 0, 603: 1, 604: 0, 605: 1, 606: 1, 607: 1, 608: 1, 609: 1, 610: 0, 611: 1, 612: 1, 613: 0, 614: 1, 615: 1, 616: 1, 617: 0, 618: 0, 619: 1, 620: 1, 621: 1, 622: 1, 623: 0, 624: 1, 625: 0, 626: 0, 627: 0, 628: 1, 629: 0, 630: 0, 631: 0, 632: 1, 633: 0, 634: 0, 635: 1, 636: 1, 637: 1, 638: 0, 639: 1, 640: 0, 641: 1, 642: 0, 643: 0, 644: 1, 645: 1, 646: 1, 647: 1, 648: 1, 649: 1, 650: 0, 651: 1, 652: 0, 653: 1, 654: 0, 655: 1, 656: 1, 657: 1, 658: 1, 659: 0, 660: 1, 661: 0, 662: 1, 663: 0, 664: 1, 665: 0, 666: 1, 667: 1, 668: 1, 669: 1, 670: 1, 671: 1, 672: 1, 673: 0, 674: 1, 675: 1, 676: 1, 677: 1, 678: 0, 679: 0, 680: 1, 681: 0, 682: 0, 683: 0, 684: 1, 685: 0, 686: 0, 687: 0, 688: 1, 689: 0, 690: 1, 691: 1, 692: 0, 693: 0, 694: 1, 695: 1, 696: 0, 697: 1, 698: 0, 699: 1, 700: 0, 701: 0, 702: 1, 703: 1, 704: 0, 705: 0, 706: 1, 707: 1, 708: 0, 709: 1, 710: 1, 711: 1, 712: 0, 713: 1, 714: 1, 715: 1, 716: 0, 717: 1, 718: 1, 719: 1, 720: 1, 721: 0, 722: 0, 723: 1, 724: 0, 725: 0, 726: 1, 727: 1, 728: 0, 729: 1, 730: 1, 731: 1, 732: 1, 733: 0, 734: 1, 735: 0, 736: 1, 737: 1, 738: 0, 739: 1, 740: 0, 741: 1, 742: 1, 743: 1, 744: 0, 745: 1, 746: 0, 747: 1, 748: 0, 749: 0, 750: 0, 751: 1, 752: 0, 753: 1, 754: 0, 755: 1, 756: 0, 757: 0, 758: 0, 759: 0, 760: 0, 761: 1, 762: 1, 763: 1, 764: 1, 765: 0, 766: 0, 767: 0, 768: 0, 769: 1, 770: 0, 771: 0, 772: 0, 773: 0, 774: 0, 775: 1, 776: 0, 777: 1, 778: 1, 779: 0, 780: 1, 781: 0, 782: 0, 783: 1, 784: 0, 785: 0, 786: 0, 787: 0, 788: 0, 789: 1, 790: 1, 791: 1, 792: 0, 793: 1, 794: 0, 795: 1, 796: 1, 797: 0, 798: 1, 799: 1, 800: 1, 801: 1, 802: 1, 803: 0, 804: 0, 805: 1, 806: 0, 807: 1, 808: 0, 809: 0, 810: 1, 811: 0, 812: 0, 813: 0, 814: 1, 815: 1, 816: 1, 817: 0, 818: 0, 819: 1, 820: 1, 821: 1, 822: 0, 823: 0, 824: 0, 825: 1, 826: 0, 827: 0, 828: 0, 829: 0, 830: 0, 831: 1, 832: 1, 833: 0, 834: 0, 835: 1, 836: 1, 837: 0, 838: 0, 839: 0, 840: 0, 841: 0, 842: 1, 843: 1, 844: 1, 845: 1, 846: 0, 847: 1, 848: 1, 849: 1, 850: 0, 851: 0, 852: 0, 853: 0, 854: 0, 855: 0, 856: 0, 857: 1, 858: 0, 859: 1, 860: 0, 861: 0, 862: 1, 863: 0, 864: 1, 865: 0, 866: 0, 867: 1, 868: 0, 869: 0, 870: 1, 871: 0, 872: 1, 873: 0, 874: 0, 875: 0, 876: 1, 877: 1, 878: 0, 879: 0, 880: 1, 881: 1, 882: 0, 883: 1, 884: 0, 885: 1, 886: 0, 887: 0, 888: 0, 889: 0, 890: 1, 891: 1, 892: 1, 893: 1, 894: 1, 895: 0, 896: 1, 897: 0, 898: 1, 899: 1, 900: 1, 901: 1, 902: 1, 903: 0, 904: 1, 905: 0, 906: 1, 907: 0, 908: 0, 909: 0, 910: 1, 911: 0, 912: 1, 913: 0, 914: 0, 915: 0, 916: 0, 917: 0, 918: 1, 919: 0, 920: 1, 921: 0, 922: 1, 923: 0, 924: 1, 925: 0, 926: 0, 927: 1, 928: 0, 929: 1, 930: 0, 931: 0, 932: 1, 933: 0, 934: 1, 935: 1, 936: 1, 937: 1, 938: 0, 939: 0, 940: 1, 941: 0, 942: 1, 943: 1, 944: 0, 945: 1, 946: 0, 947: 0, 948: 1, 949: 0, 950: 1, 951: 1, 952: 1, 953: 0, 954: 1, 955: 1, 956: 0, 957: 0, 958: 0, 959: 1, 960: 1, 961: 1, 962: 1, 963: 0, 964: 1, 965: 0, 966: 1, 967: 1, 968: 1, 969: 0, 970: 1, 971: 0, 972: 1, 973: 0, 974: 1, 975: 1, 976: 0, 977: 0, 978: 0, 979: 0, 980: 1, 981: 1, 982: 0, 983: 1, 984: 1, 985: 1, 986: 0, 987: 0, 988: 0, 989: 0, 990: 0, 991: 0, 992: 1, 993: 1, 994: 1, 995: 0, 996: 1, 997: 0, 998: 0, 999: 0, 1000: 1, 1001: 0, 1002: 0, 1003: 1, 1004: 0, 1005: 0, 1006: 1, 1007: 0, 1008: 0, 1009: 1, 1010: 0, 1011: 0, 1012: 0, 1013: 0, 1014: 0, 1015: 1, 1016: 0, 1017: 0, 1018: 0, 1019: 0, 1020: 1, 1021: 1, 1022: 0, 1023: 0, 1024: 0, 1025: 1, 1026: 0, 1027: 1, 1028: 0, 1029: 0, 1030: 0, 1031: 0, 1032: 0, 1033: 1, 1034: 1, 1035: 1, 1036: 0, 1037: 0, 1038: 0, 1039: 0, 1040: 1, 1041: 1, 1042: 1, 1043: 1, 1044: 1, 1045: 1, 1046: 0, 1047: 1, 1048: 1, 1049: 0, 1050: 1, 1051: 0, 1052: 1, 1053: 0, 1054: 1, 1055: 0, 1056: 1, 1057: 1, 1058: 0, 1059: 1, 1060: 1, 1061: 0, 1062: 0, 1063: 1, 1064: 0, 1065: 0, 1066: 0, 1067: 1, 1068: 0, 1069: 0, 1070: 1, 1071: 1, 1072: 1, 1073: 1, 1074: 1, 1075: 1, 1076: 1, 1077: 0, 1078: 1, 1079: 1, 1080: 1, 1081: 1, 1082: 1, 1083: 1, 1084: 0, 1085: 1, 1086: 0, 1087: 1, 1088: 1, 1089: 0, 1090: 0, 1091: 0, 1092: 0, 1093: 0, 1094: 0, 1095: 1, 1096: 0, 1097: 0, 1098: 1, 1099: 1, 1100: 1, 1101: 1, 1102: 0, 1103: 0, 1104: 0, 1105: 1, 1106: 0, 1107: 1, 1108: 0, 1109: 1, 1110: 0, 1111: 1, 1112: 1, 1113: 1, 1114: 1, 1115: 0, 1116: 1, 1117: 0, 1118: 0, 1119: 0, 1120: 0, 1121: 0, 1122: 1, 1123: 1, 1124: 1, 1125: 1, 1126: 1, 1127: 1, 1128: 0, 1129: 1, 1130: 0, 1131: 0, 1132: 1, 1133: 1, 1134: 1, 1135: 1, 1136: 1, 1137: 0, 1138: 1, 1139: 1, 1140: 0, 1141: 0, 1142: 1, 1143: 0, 1144: 1, 1145: 1, 1146: 0, 1147: 1, 1148: 0, 1149: 1, 1150: 0, 1151: 0, 1152: 0, 1153: 1, 1154: 0, 1155: 1, 1156: 1, 1157: 0, 1158: 0, 1159: 0, 1160: 1, 1161: 0, 1162: 1, 1163: 0, 1164: 0, 1165: 1, 1166: 0, 1167: 0, 1168: 0, 1169: 0, 1170: 1, 1171: 1, 1172: 0, 1173: 0, 1174: 0, 1175: 1, 1176: 1, 1177: 1, 1178: 0, 1179: 0, 1180: 0, 1181: 1, 1182: 0, 1183: 0, 1184: 1, 1185: 1, 1186: 0, 1187: 0, 1188: 1, 1189: 0, 1190: 0, 1191: 0, 1192: 0, 1193: 0, 1194: 0, 1195: 1, 1196: 1, 1197: 1, 1198: 1, 1199: 0, 1200: 0, 1201: 0, 1202: 1, 1203: 0, 1204: 1, 1205: 0, 1206: 0, 1207: 0, 1208: 0, 1209: 0, 1210: 0, 1211: 0, 1212: 0, 1213: 1, 1214: 1, 1215: 1, 1216: 0, 1217: 0, 1218: 1, 1219: 1, 1220: 0, 1221: 1, 1222: 0, 1223: 1, 1224: 1, 1225: 0, 1226: 1, 1227: 1, 1228: 0, 1229: 0, 1230: 1, 1231: 0, 1232: 1, 1233: 1, 1234: 0, 1235: 0, 1236: 0, 1237: 1, 1238: 1, 1239: 1, 1240: 0, 1241: 1, 1242: 0, 1243: 0, 1244: 0, 1245: 1, 1246: 0, 1247: 0, 1248: 0, 1249: 0, 1250: 0, 1251: 0, 1252: 0, 1253: 0, 1254: 1, 1255: 0, 1256: 1, 1257: 1, 1258: 1, 1259: 1, 1260: 0, 1261: 1, 1262: 1, 1263: 0, 1264: 1, 1265: 0, 1266: 1, 1267: 0, 1268: 1, 1269: 1, 1270: 0, 1271: 0, 1272: 0, 1273: 1, 1274: 0, 1275: 0, 1276: 0, 1277: 0, 1278: 0, 1279: 0, 1280: 1, 1281: 1, 1282: 0, 1283: 1, 1284: 1, 1285: 1, 1286: 0, 1287: 0, 1288: 1, 1289: 0, 1290: 0, 1291: 1, 1292: 1, 1293: 1, 1294: 1, 1295: 0, 1296: 0, 1297: 0, 1298: 0, 1299: 0, 1300: 1, 1301: 0, 1302: 1, 1303: 0, 1304: 1, 1305: 1, 1306: 1, 1307: 0, 1308: 1, 1309: 0, 1310: 1, 1311: 0, 1312: 1, 1313: 0, 1314: 1, 1315: 0, 1316: 1, 1317: 1, 1318: 0, 1319: 1, 1320: 0, 1321: 0, 1322: 0, 1323: 0, 1324: 1, 1325: 1, 1326: 1, 1327: 1, 1328: 1, 1329: 0, 1330: 0, 1331: 0, 1332: 1, 1333: 0, 1334: 1, 1335: 0, 1336: 0, 1337: 0, 1338: 1, 1339: 0, 1340: 0, 1341: 1, 1342: 0, 1343: 0, 1344: 0, 1345: 0, 1346: 1, 1347: 1, 1348: 1, 1349: 1, 1350: 0, 1351: 1, 1352: 0, 1353: 0, 1354: 0, 1355: 0, 1356: 1, 1357: 1, 1358: 0, 1359: 0, 1360: 1, 1361: 1, 1362: 1, 1363: 1, 1364: 1, 1365: 0, 1366: 0, 1367: 1, 1368: 0, 1369: 1, 1370: 0, 1371: 0, 1372: 0, 1373: 1, 1374: 0, 1375: 0, 1376: 0, 1377: 1, 1378: 0, 1379: 0, 1380: 1, 1381: 0, 1382: 1, 1383: 0, 1384: 1, 1385: 0, 1386: 0, 1387: 0, 1388: 0, 1389: 1, 1390: 0, 1391: 0, 1392: 1, 1393: 1, 1394: 1, 1395: 0, 1396: 1, 1397: 0, 1398: 0, 1399: 1, 1400: 0, 1401: 0, 1402: 1, 1403: 1, 1404: 1, 1405: 0, 1406: 0, 1407: 0, 1408: 1, 1409: 0, 1410: 1, 1411: 1, 1412: 0, 1413: 1, 1414: 0, 1415: 0, 1416: 0, 1417: 1, 1418: 1, 1419: 0, 1420: 1, 1421: 0, 1422: 0, 1423: 1, 1424: 0, 1425: 1, 1426: 0, 1427: 1, 1428: 0, 1429: 1, 1430: 1, 1431: 1, 1432: 0, 1433: 1, 1434: 0, 1435: 0, 1436: 1, 1437: 0, 1438: 0, 1439: 0, 1440: 1, 1441: 1, 1442: 1, 1443: 1, 1444: 0, 1445: 0, 1446: 1, 1447: 0, 1448: 1, 1449: 0, 1450: 1, 1451: 0, 1452: 0, 1453: 1, 1454: 1, 1455: 0, 1456: 1, 1457: 0, 1458: 1, 1459: 0, 1460: 0, 1461: 0, 1462: 0, 1463: 1, 1464: 1, 1465: 1, 1466: 1, 1467: 1, 1468: 1, 1469: 0, 1470: 1, 1471: 0, 1472: 0, 1473: 1, 1474: 0, 1475: 0, 1476: 0, 1477: 0, 1478: 1, 1479: 1, 1480: 1, 1481: 1, 1482: 1, 1483: 0, 1484: 1, 1485: 0, 1486: 1, 1487: 1, 1488: 1, 1489: 0, 1490: 0, 1491: 0, 1492: 1, 1493: 0, 1494: 0, 1495: 0, 1496: 1, 1497: 0, 1498: 1, 1499: 1, 1500: 1, 1501: 0, 1502: 0, 1503: 0, 1504: 0, 1505: 1, 1506: 1, 1507: 1, 1508: 1, 1509: 1, 1510: 0, 1511: 0, 1512: 0, 1513: 0, 1514: 0, 1515: 1, 1516: 1, 1517: 0, 1518: 0, 1519: 0, 1520: 0, 1521: 1, 1522: 1, 1523: 1, 1524: 0, 1525: 0, 1526: 1, 1527: 1, 1528: 0, 1529: 0, 1530: 0, 1531: 0, 1532: 0, 1533: 0, 1534: 0, 1535: 1, 1536: 0, 1537: 1, 1538: 0, 1539: 0, 1540: 0, 1541: 0, 1542: 0, 1543: 1, 1544: 0, 1545: 1, 1546: 1, 1547: 1, 1548: 0, 1549: 1, 1550: 0, 1551: 0, 1552: 0, 1553: 0, 1554: 1, 1555: 1, 1556: 0, 1557: 0, 1558: 0, 1559: 1, 1560: 0, 1561: 0, 1562: 0, 1563: 1, 1564: 0, 1565: 0, 1566: 1, 1567: 1, 1568: 0, 1569: 1, 1570: 0, 1571: 1, 1572: 0, 1573: 0, 1574: 1, 1575: 1, 1576: 1, 1577: 0, 1578: 1, 1579: 0, 1580: 1, 1581: 1, 1582: 1, 1583: 1, 1584: 0, 1585: 0, 1586: 1, 1587: 1, 1588: 1, 1589: 1, 1590: 1, 1591: 0, 1592: 1, 1593: 0, 1594: 1, 1595: 1, 1596: 0, 1597: 1, 1598: 0, 1599: 1, 1600: 0, 1601: 1, 1602: 0, 1603: 0, 1604: 1, 1605: 0, 1606: 0, 1607: 0, 1608: 1, 1609: 1, 1610: 1, 1611: 0, 1612: 1, 1613: 0, 1614: 0, 1615: 0, 1616: 1, 1617: 1, 1618: 0, 1619: 0, 1620: 0, 1621: 0, 1622: 1, 1623: 0, 1624: 0, 1625: 0, 1626: 1, 1627: 0, 1628: 0, 1629: 0, 1630: 1, 1631: 1, 1632: 0, 1633: 1, 1634: 1, 1635: 0, 1636: 1, 1637: 0, 1638: 0, 1639: 1, 1640: 0, 1641: 0, 1642: 0, 1643: 1, 1644: 0, 1645: 0, 1646: 1, 1647: 0, 1648: 0, 1649: 1, 1650: 1, 1651: 1, 1652: 1, 1653: 1, 1654: 1, 1655: 0, 1656: 1, 1657: 1, 1658: 1, 1659: 1, 1660: 0, 1661: 0, 1662: 1, 1663: 0, 1664: 1, 1665: 0, 1666: 1, 1667: 0, 1668: 0, 1669: 0, 1670: 0, 1671: 1, 1672: 1, 1673: 0, 1674: 1, 1675: 1, 1676: 1, 1677: 0, 1678: 0, 1679: 1, 1680: 1, 1681: 0, 1682: 0, 1683: 0, 1684: 0, 1685: 0, 1686: 0, 1687: 1, 1688: 1, 1689: 0, 1690: 1, 1691: 0, 1692: 0, 1693: 1, 1694: 1, 1695: 1, 1696: 1, 1697: 0, 1698: 1, 1699: 1, 1700: 0, 1701: 0, 1702: 1, 1703: 0, 1704: 1, 1705: 0, 1706: 0, 1707: 0, 1708: 0, 1709: 1, 1710: 1, 1711: 0, 1712: 1, 1713: 0, 1714: 1, 1715: 0, 1716: 0, 1717: 1, 1718: 0, 1719: 1, 1720: 1, 1721: 1, 1722: 0, 1723: 0, 1724: 0, 1725: 0, 1726: 0, 1727: 0, 1728: 1, 1729: 1, 1730: 0, 1731: 1, 1732: 0, 1733: 1, 1734: 1, 1735: 0, 1736: 0, 1737: 1, 1738: 1, 1739: 0, 1740: 1, 1741: 0, 1742: 0, 1743: 1, 1744: 1, 1745: 1, 1746: 0, 1747: 1, 1748: 1, 1749: 0, 1750: 1, 1751: 1, 1752: 0, 1753: 0, 1754: 0, 1755: 0, 1756: 1, 1757: 1, 1758: 0, 1759: 0, 1760: 1, 1761: 1, 1762: 0, 1763: 1, 1764: 0, 1765: 0, 1766: 0, 1767: 0, 1768: 1, 1769: 1, 1770: 0, 1771: 0, 1772: 0, 1773: 0, 1774: 0, 1775: 0, 1776: 0, 1777: 0, 1778: 1, 1779: 1, 1780: 1, 1781: 1, 1782: 0, 1783: 1, 1784: 1, 1785: 0, 1786: 1, 1787: 1, 1788: 0, 1789: 0, 1790: 0, 1791: 1, 1792: 0, 1793: 1, 1794: 0, 1795: 0, 1796: 1, 1797: 1, 1798: 0, 1799: 0, 1800: 0, 1801: 0, 1802: 1, 1803: 1, 1804: 1, 1805: 1, 1806: 0, 1807: 1, 1808: 0, 1809: 1, 1810: 1, 1811: 1, 1812: 1, 1813: 1, 1814: 1, 1815: 0, 1816: 1, 1817: 0, 1818: 0, 1819: 0, 1820: 1, 1821: 1, 1822: 0, 1823: 1, 1824: 0, 1825: 1, 1826: 1, 1827: 1, 1828: 1, 1829: 0, 1830: 0, 1831: 0, 1832: 1, 1833: 1, 1834: 1, 1835: 0, 1836: 0, 1837: 1, 1838: 1, 1839: 0, 1840: 1, 1841: 0, 1842: 0, 1843: 1, 1844: 0, 1845: 1, 1846: 0, 1847: 1, 1848: 0, 1849: 0, 1850: 1, 1851: 0, 1852: 1, 1853: 1, 1854: 0, 1855: 1, 1856: 0, 1857: 0, 1858: 1, 1859: 1, 1860: 0, 1861: 1, 1862: 0, 1863: 1, 1864: 1, 1865: 0, 1866: 0, 1867: 1, 1868: 0, 1869: 0, 1870: 0, 1871: 1, 1872: 0, 1873: 0, 1874: 1, 1875: 0, 1876: 0, 1877: 0, 1878: 0, 1879: 0, 1880: 1, 1881: 1, 1882: 1, 1883: 1, 1884: 0, 1885: 0, 1886: 1, 1887: 0, 1888: 0, 1889: 1, 1890: 0, 1891: 0, 1892: 0, 1893: 0, 1894: 0, 1895: 1, 1896: 1, 1897: 1, 1898: 1, 1899: 0, 1900: 1, 1901: 1, 1902: 1, 1903: 1, 1904: 0, 1905: 1, 1906: 1, 1907: 0, 1908: 0, 1909: 1, 1910: 1, 1911: 0, 1912: 0, 1913: 1, 1914: 0, 1915: 0, 1916: 0, 1917: 1, 1918: 1, 1919: 1, 1920: 0, 1921: 0, 1922: 1, 1923: 0, 1924: 1, 1925: 1, 1926: 0, 1927: 0, 1928: 1, 1929: 0, 1930: 0, 1931: 0, 1932: 1, 1933: 0, 1934: 0, 1935: 0, 1936: 0, 1937: 0, 1938: 1, 1939: 0, 1940: 0, 1941: 0, 1942: 1, 1943: 0, 1944: 1, 1945: 1, 1946: 1, 1947: 0, 1948: 1, 1949: 1, 1950: 0, 1951: 1, 1952: 1, 1953: 1, 1954: 1, 1955: 0, 1956: 0, 1957: 0, 1958: 1, 1959: 1, 1960: 1, 1961: 0, 1962: 1, 1963: 0, 1964: 1, 1965: 0, 1966: 0, 1967: 0, 1968: 1, 1969: 0, 1970: 0, 1971: 1, 1972: 1, 1973: 1, 1974: 0, 1975: 0, 1976: 0, 1977: 1, 1978: 1, 1979: 1, 1980: 1, 1981: 1, 1982: 1, 1983: 0, 1984: 1, 1985: 0, 1986: 1, 1987: 1, 1988: 1, 1989: 1, 1990: 1, 1991: 1, 1992: 1, 1993: 0, 1994: 0, 1995: 1, 1996: 1, 1997: 0, 1998: 1, 1999: 0, 2000: 1}tensor(-2492.2183, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  3.188145875930786 current loss tensor(-2492.2632, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  3.318763494491577 current loss tensor(-2492.3066, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  3.2029829025268555 current loss tensor(-2492.3484, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  3.2347588539123535 current loss tensor(-2492.3887, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  3.357330322265625 current loss tensor(-2492.4282, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  3.3688242435455322 current loss tensor(-2492.4663, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  3.358146905899048 current loss tensor(-2492.5034, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  3.4876301288604736 current loss tensor(-2492.5388, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  3.365997791290283 current loss tensor(-2492.5737, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  3.3662898540496826 current loss tensor(-2492.6074, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  3.3679709434509277 current loss tensor(-2492.6404, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  3.36153244972229 current loss tensor(-2492.6724, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  3.2994511127471924 current loss tensor(-2492.7034, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  3.292466163635254 current loss tensor(-2492.7339, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  3.2136218547821045 current loss tensor(-2492.7632, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  3.364063024520874 current loss tensor(-2492.7922, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  3.191854238510132 current loss tensor(-2492.8203, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  3.2286527156829834 current loss tensor(-2492.8479, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  3.2324025630950928 current loss tensor(-2492.8750, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  3.294548511505127 current loss tensor(-2492.9014, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  3.2157678604125977 current loss tensor(-2492.9275, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  3.256401777267456 current loss tensor(-2492.9531, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  3.2948455810546875 current loss tensor(-2492.9780, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  3.218294143676758 current loss tensor(-2493.0027, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  3.234321117401123 current loss tensor(-2493.0269, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  3.336662769317627 current loss tensor(-2493.0508, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  3.1857492923736572 current loss tensor(-2493.0742, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  3.3443338871002197 current loss tensor(-2493.0974, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.213636636734009 current loss tensor(-2493.1206, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.217888593673706 current loss tensor(-2493.1431, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  3.257148504257202 current loss tensor(-2493.1653, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  3.2885687351226807 current loss tensor(-2493.1875, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  3.2155590057373047 current loss tensor(-2493.2095, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  3.3469464778900146 current loss tensor(-2493.2310, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  3.2372689247131348 current loss tensor(-2493.2524, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  3.2864737510681152 current loss tensor(-2493.2739, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  3.288041830062866 current loss tensor(-2493.2949, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  3.2335915565490723 current loss tensor(-2493.3159, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  3.2497470378875732 current loss tensor(-2493.3369, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  3.2794277667999268 current loss tensor(-2493.3577, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  3.2274606227874756 current loss tensor(-2493.3784, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  3.2259373664855957 current loss tensor(-2493.3987, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  3.3711907863616943 current loss tensor(-2493.4189, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  3.1843042373657227 current loss tensor(-2493.4395, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  3.293874979019165 current loss tensor(-2493.4595, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  3.2234368324279785 current loss tensor(-2493.4800, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  3.233097553253174 current loss tensor(-2493.4998, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  3.262423515319824 current loss tensor(-2493.5200, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  3.2823987007141113 current loss tensor(-2493.5398, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  3.228062152862549 current loss tensor(-2493.5598, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  3.214262008666992 current loss tensor(-2493.5796, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  3.23111629486084 current loss tensor(-2493.5994, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  3.42273211479187 current loss tensor(-2493.6191, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  3.181009531021118 current loss tensor(-2493.6389, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  3.2267110347747803 current loss tensor(-2493.6587, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  3.221914291381836 current loss tensor(-2493.6782, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  3.2992658615112305 current loss tensor(-2493.6982, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  3.2395339012145996 current loss tensor(-2493.7178, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  3.232274055480957 current loss tensor(-2493.7375, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  3.2220687866210938 current loss tensor(-2493.7573, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  3.3342480659484863 current loss tensor(-2493.7771, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  3.1889755725860596 current loss tensor(-2493.7969, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  3.233832359313965 current loss tensor(-2493.8167, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  3.2830872535705566 current loss tensor(-2493.8364, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  3.231484889984131 current loss tensor(-2493.8564, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  3.2917966842651367 current loss tensor(-2493.8760, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  3.2157299518585205 current loss tensor(-2493.8960, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  3.238858938217163 current loss tensor(-2493.9160, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  3.2293879985809326 current loss tensor(-2493.9358, device='cuda:1', grad_fn=<SumBackward0>)
dealing G55.txt
device 1 start to train
[n] 1250 [C] 777 weight 5000
con_list_range 
-10087.0
-9997.0
dealing G55.txt
device 0 start to train
[n] 1250 [C] 781 weight 5000
con_list_range [1, 3, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 135, 137, 138, 141, 142, 143, 144, 146, 147, 149, 151, 153, 155, 156, 157, 159, 160, 163, 165, 166, 168, 169, 171, 173, 174, 175, 176, 178, 179, 180, 181, 182, 186, 187, 189, 190, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 205, 206, 207, 208, 210, 212, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 226, 227, 229, 230, 231, 232, 235, 236, 237, 238, 240, 242, 244, 248, 249, 250, 251, 252, 253, 254, 256, 257, 260, 263, 267, 268, 269, 272, 273, 274, 275, 278, 281, 284, 285, 286, 288, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 315, 316, 319, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 353, 354, 355, 356, 358, 361, 364, 365, 366, 368, 369, 371, 372, 374, 376, 377, 378, 379, 380, 381, 382, 384, 385, 387, 388, 390, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 425, 428, 429, 432, 433, 434, 436, 437, 438, 441, 444, 445, 446, 447, 448, 450, 453, 455, 456, 457, 458, 460, 462, 463, 464, 465, 466, 467, 468, 469, 471, 474, 476, 477, 479, 480, 481, 482, 483, 484, 485, 487, 488, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 507, 508, 509, 511, 512, 513, 515, 516, 517, 518, 521, 523, 524, 526, 527, 528, 529, 530, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 544, 546, 548, 549, 550, 551, 552, 554, 556, 557, 558, 559, 560, 562, 563, 564, 565, 566, 567, 570, 573, 574, 575, 576, 577, 578, 580, 581, 582, 584, 585, 586, 588, 589, 591, 592, 593, 595, 596, 598, 599, 600, 601, 603, 604, 608, 609, 610, 612, 613, 614, 617, 618, 620, 621, 622, 623, 625, 627, 628, 629, 630, 631, 633, 635, 636, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 650, 652, 653, 655, 656, 657, 658, 659, 660, 661, 662, 668, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 686, 688, 690, 692, 695, 696, 697, 698, 701, 702, 703, 704, 706, 708, 709, 710, 711, 712, 713, 715, 716, 717, 718, 719, 721, 722, 723, 724, 725, 726, 727, 728, 731, 732, 734, 737, 738, 739, 740, 741, 742, 746, 748, 749, 751, 752, 753, 755, 757, 758, 760, 761, 762, 763, 764, 765, 766, 769, 770, 771, 772, 773, 776, 777, 778, 779, 780, 781, 782, 783, 786, 788, 789, 790, 792, 793, 794, 796, 797, 798, 799, 800, 801, 803, 804, 805, 806, 808, 809, 810, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 828, 832, 833, 835, 836, 837, 838, 840, 841, 842, 843, 844, 845, 846, 848, 850, 852, 855, 856, 858, 859, 860, 862, 863, 864, 865, 866, 867, 869, 870, 872, 874, 875, 876, 878, 879, 880, 885, 886, 887, 889, 890, 891, 893, 895, 897, 898, 900, 901, 902, 903, 904, 906, 908, 909, 910, 913, 914, 915, 917, 918, 920, 922, 924, 926, 927, 928, 929, 931, 933, 934, 936, 937, 938, 939, 940, 941, 943, 944, 946, 947, 948, 950, 953, 954, 956, 957, 958, 960, 962, 963, 964, 966, 967, 968, 969, 970, 972, 975, 976, 977, 978, 979, 983, 984, 986, 987, 988, 991, 992, 993, 995, 996, 997, 999, 1000, 1002, 1003, 1005, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1025, 1028, 1029, 1031, 1034, 1036, 1037, 1038, 1040, 1041, 1042, 1045, 1046, 1047, 1048, 1049, 1050, 1053, 1054, 1055, 1057, 1059, 1061, 1062, 1063, 1066, 1068, 1069, 1070, 1071, 1072, 1073, 1075, 1076, 1077, 1078, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1095, 1097, 1098, 1099, 1100, 1101, 1104, 1105, 1107, 1109, 1110, 1111, 1112, 1115, 1116, 1118, 1120, 1121, 1122, 1124, 1126, 1127, 1129, 1130, 1131, 1132, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1144, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1164, 1165, 1167, 1168, 1170, 1172, 1173, 1174, 1175, 1176, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1196, 1197, 1199, 1200, 1202, 1203, 1204, 1205, 1206, 1208, 1209, 1210, 1213, 1215, 1217, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1229, 1230, 1231, 1232, 1233, 1235, 1236, 1238, 1239, 1240, 1242, 1243, 1244, 1246, 1247, 1248, 1249, 1250]
average_loss tensor(-1325.0254, device='cuda:0', grad_fn=<DivBackward0>) best_loss inf
Epoch 0 Epoch time:  3.0282540321350098 current loss tensor(-1326.2549, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1325.6914, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1325.0254, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1 Epoch time:  2.5861992835998535 current loss tensor(-1326.9297, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1326.3564, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1325.6914, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2 Epoch time:  2.520772695541382 current loss tensor(-1327.6040, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1327.0212, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1326.3564, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3 Epoch time:  2.5078816413879395 current loss tensor(-1328.2776, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1327.6851, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1327.0212, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4 Epoch time:  2.5232107639312744 current loss tensor(-1328.9504, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1328.3483, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1327.6851, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5 Epoch time:  2.530334234237671 current loss tensor(-1329.6226, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1329.0107, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1328.3483, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6 Epoch time:  2.5268900394439697 current loss tensor(-1330.2939, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1329.6726, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1329.0107, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7 Epoch time:  2.5323307514190674 current loss tensor(-1330.9648, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1330.3337, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1329.6726, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8 Epoch time:  2.5380489826202393 current loss tensor(-1331.6348, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1330.9941, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1330.3337, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9 Epoch time:  2.5242013931274414 current loss tensor(-1332.3040, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1331.6537, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1330.9941, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10 Epoch time:  2.6523942947387695 current loss tensor(-1332.9725, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1332.3125, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1331.6537, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11 Epoch time:  2.6415393352508545 current loss tensor(-1333.6401, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1332.9706, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1332.3125, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12 Epoch time:  2.5281684398651123 current loss tensor(-1334.3069, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1333.6277, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1332.9706, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13 Epoch time:  2.521233320236206 current loss tensor(-2491.8379, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  3.2184314727783203 current loss tensor(-2491.8618, device='cuda:3', grad_fn=<SumBackward0>)
dealing G55.txt
device 3 start to train
[n] 1250 [C] 784 weight 5000
con_list_range [3751, 3754, 3755, 3756, 3757, 3758, 3759, 3761, 3762, 3763, 3764, 3765, 3766, 3768, 3769, 3771, 3772, 3774, 3775, 3776, 3777, 3780, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3790, 3791, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3814, 3815, 3817, 3819, 3821, 3822, 3824, 3825, 3828, 3829, 3830, 3832, 3834, 3835, 3836, 3838, 3840, 3841, 3843, 3845, 3846, 3848, 3849, 3850, 3852, 3853, 3856, 3858, 3859, 3860, 3861, 3862, 3865, 3867, 3868, 3869, 3870, 3871, 3872, 3873, 3876, 3877, 3878, 3880, 3881, 3882, 3883, 3885, 3886, 3887, 3888, 3889, 3890, 3891, 3893, 3894, 3895, 3896, 3897, 3898, 3899, 3900, 3902, 3903, 3904, 3905, 3906, 3907, 3908, 3909, 3912, 3914, 3917, 3918, 3919, 3921, 3922, 3923, 3925, 3928, 3929, 3930, 3931, 3932, 3936, 3937, 3938, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3948, 3949, 3950, 3951, 3952, 3956, 3957, 3958, 3959, 3962, 3966, 3967, 3968, 3969, 3970, 3972, 3973, 3974, 3979, 3980, 3981, 3982, 3984, 3985, 3986, 3988, 3991, 3995, 3997, 3998, 3999, 4001, 4002, 4005, 4006, 4007, 4008, 4010, 4011, 4012, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4024, 4026, 4027, 4028, 4031, 4032, 4033, 4034, 4035, 4038, 4039, 4040, 4042, 4045, 4046, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4056, 4057, 4059, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4070, 4071, 4073, 4074, 4076, 4077, 4078, 4081, 4082, 4083, 4085, 4089, 4090, 4091, 4092, 4093, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4114, 4116, 4117, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4128, 4130, 4131, 4132, 4134, 4135, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4147, 4149, 4151, 4153, 4155, 4156, 4158, 4159, 4160, 4161, 4162, 4163, 4165, 4169, 4170, 4172, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4182, 4185, 4189, 4190, 4191, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4206, 4207, 4208, 4210, 4211, 4212, 4213, 4219, 4220, 4221, 4223, 4224, 4225, 4227, 4228, 4229, 4230, 4232, 4233, 4235, 4236, 4237, 4238, 4239, 4241, 4242, 4244, 4245, 4246, 4247, 4250, 4251, 4252, 4255, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4265, 4267, 4269, 4271, 4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4284, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4297, 4300, 4301, 4302, 4303, 4304, 4306, 4307, 4308, 4311, 4312, 4313, 4314, 4315, 4319, 4322, 4323, 4325, 4326, 4328, 4330, 4331, 4332, 4333, 4335, 4336, 4337, 4338, 4339, 4340, 4341, 4342, 4343, 4346, 4347, 4348, 4349, 4350, 4351, 4352, 4353, 4354, 4355, 4356, 4357, 4358, 4359, 4360, 4362, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4374, 4376, 4377, 4383, 4385, 4386, 4387, 4388, 4390, 4392, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4402, 4404, 4405, 4406, 4407, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4417, 4418, 4419, 4423, 4424, 4425, 4426, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4441, 4442, 4444, 4445, 4446, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4469, 4471, 4472, 4473, 4475, 4477, 4478, 4479, 4482, 4483, 4484, 4485, 4487, 4488, 4489, 4490, 4492, 4495, 4496, 4497, 4500, 4501, 4504, 4506, 4507, 4509, 4510, 4511, 4512, 4514, 4516, 4518, 4519, 4520, 4521, 4522, 4523, 4524, 4526, 4527, 4528, 4530, 4532, 4534, 4535, 4536, 4537, 4539, 4540, 4541, 4542, 4543, 4545, 4549, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4560, 4562, 4563, 4564, 4565, 4566, 4567, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4581, 4582, 4583, 4584, 4585, 4586, 4587, 4588, 4591, 4592, 4593, 4595, 4596, 4597, 4598, 4600, 4601, 4602, 4604, 4605, 4606, 4608, 4609, 4610, 4611, 4612, 4613, 4614, 4616, 4617, 4618, 4619, 4620, 4622, 4623, 4624, 4625, 4626, 4628, 4629, 4630, 4632, 4634, 4635, 4636, 4637, 4640, 4641, 4642, 4643, 4644, 4645, 4646, 4647, 4648, 4650, 4653, 4654, 4655, 4656, 4657, 4658, 4659, 4661, 4663, 4666, 4669, 4673, 4674, 4675, 4676, 4678, 4679, 4680, 4681, 4683, 4685, 4686, 4687, 4689, 4690, 4691, 4692, 4694, 4695, 4697, 4698, 4699, 4701, 4703, 4706, 4708, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4719, 4720, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4738, 4740, 4742, 4744, 4745, 4746, 4747, 4748, 4749, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4764, 4766, 4768, 4769, 4770, 4771, 4772, 4774, 4777, 4778, 4779, 4780, 4782, 4784, 4786, 4788, 4789, 4790, 4791, 4792, 4793, 4795, 4796, 4799, 4800, 4801, 4802, 4803, 4804, 4805, 4806, 4808, 4809, 4811, 4816, 4817, 4820, 4821, 4824, 4826, 4828, 4829, 4830, 4831, 4834, 4836, 4837, 4838, 4839, 4840, 4842, 4843, 4844, 4847, 4848, 4849, 4851, 4854, 4855, 4856, 4857, 4858, 4859, 4860, 4861, 4862, 4864, 4865, 4866, 4867, 4868, 4869, 4870, 4871, 4872, 4873, 4874, 4875, 4876, 4877, 4879, 4880, 4881, 4884, 4885, 4887, 4889, 4890, 4894, 4896, 4898, 4899, 4900, 4901, 4902, 4905, 4906, 4907, 4908, 4909, 4910, 4911, 4912, 4913, 4914, 4915, 4916, 4917, 4919, 4920, 4921, 4923, 4924, 4925, 4926, 4927, 4928, 4929, 4930, 4931, 4932, 4934, 4935, 4936, 4937, 4938, 4940, 4941, 4942, 4943, 4944, 4945, 4947, 4948, 4949, 4952, 4953, 4954, 4955, 4956, 4957, 4959, 4960, 4961, 4963, 4967, 4968, 4969, 4970, 4971, 4974, 4977, 4978, 4979, 4981, 4984, 4985, 4986, 4988, 4989, 4991, 4992, 4993, 4994, 4995, 4997, 4998, 4999, 5000]
Epoch 0 Epoch time:  3.010204315185547 current loss tensor(-1313.7043, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.5749237537384033 current loss tensor(-1314.3719, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.4294700622558594 current loss tensor(-1315.0388, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.4930763244628906 current loss tensor(-1315.7052, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.4774527549743652 current loss tensor(-1316.3708, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  2.490811586380005 current loss tensor(-1317.0359, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.5119986534118652 current loss tensor(-1317.7002, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.531160593032837 current loss tensor(-1318.3638, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  2.528235673904419 current loss tensor(-1319.0266, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  2.5023581981658936 current loss tensor(-1319.6888, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.518287181854248 current loss tensor(-1320.3503, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.4951729774475098 current loss tensor(-1321.0110, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.4966020584106445 current loss tensor(-1321.6711, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.509429693222046 current loss tensor(-1322.3302, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.549292802810669 current loss tensor(-1322.9888, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.480905055999756 current loss tensor(-1323.6464, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.486963987350464 current loss tensor(-1324.3032, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.5119481086730957 current loss tensor(-1324.9592, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.6324758529663086 current loss tensor(-1325.6144, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.4560179710388184 current loss tensor(-1326.2688, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.533501386642456 current loss tensor(-1326.9222, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  2.541107416152954 current loss tensor(-1327.5748, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  2.515021324157715 current losstensor(-2508.5417, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  3.2185330390930176 current loss tensor(-2508.5615, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  3.206125020980835 current loss tensor(-2508.5813, device='cuda:2', grad_fn=<SumBackward0>)
dealing G55.txt
device 2 start to train
[n] 1250 [C] 783 weight 5000
con_list_range [2502, 2505, 2506, 2507, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2527, 2528, 2529, 2530, 2531, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2546, 2547, 2548, 2550, 2551, 2552, 2553, 2554, 2555, 2557, 2558, 2559, 2560, 2562, 2563, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2578, 2579, 2580, 2581, 2583, 2586, 2587, 2590, 2592, 2593, 2594, 2595, 2596, 2600, 2602, 2603, 2604, 2605, 2607, 2608, 2612, 2615, 2616, 2617, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2629, 2630, 2631, 2632, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2656, 2657, 2659, 2661, 2662, 2663, 2664, 2667, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2677, 2678, 2679, 2680, 2682, 2685, 2686, 2687, 2689, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2699, 2700, 2701, 2703, 2706, 2707, 2708, 2709, 2710, 2712, 2713, 2716, 2717, 2718, 2719, 2720, 2722, 2723, 2725, 2726, 2727, 2729, 2731, 2733, 2734, 2735, 2736, 2739, 2741, 2742, 2743, 2744, 2745, 2748, 2750, 2751, 2752, 2753, 2755, 2757, 2758, 2760, 2762, 2763, 2764, 2765, 2766, 2767, 2769, 2771, 2772, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2787, 2788, 2789, 2792, 2794, 2795, 2797, 2798, 2799, 2800, 2801, 2802, 2804, 2805, 2806, 2808, 2809, 2810, 2813, 2814, 2815, 2816, 2818, 2819, 2820, 2822, 2823, 2825, 2826, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2837, 2838, 2839, 2840, 2841, 2842, 2844, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2861, 2862, 2865, 2866, 2867, 2868, 2869, 2870, 2872, 2873, 2874, 2875, 2877, 2878, 2879, 2882, 2883, 2884, 2885, 2886, 2890, 2892, 2894, 2895, 2896, 2897, 2899, 2900, 2901, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2922, 2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2933, 2934, 2935, 2937, 2938, 2941, 2943, 2944, 2946, 2947, 2948, 2949, 2953, 2954, 2955, 2957, 2960, 2961, 2962, 2963, 2964, 2965, 2967, 2968, 2971, 2974, 2976, 2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2992, 2995, 2996, 2997, 2998, 3002, 3004, 3005, 3006, 3007, 3008, 3009, 3011, 3012, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3025, 3026, 3027, 3032, 3033, 3034, 3035, 3036, 3037, 3039, 3040, 3042, 3044, 3045, 3049, 3050, 3051, 3053, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3065, 3068, 3069, 3070, 3072, 3073, 3075, 3076, 3078, 3081, 3082, 3084, 3086, 3088, 3089, 3090, 3091, 3092, 3093, 3095, 3096, 3097, 3098, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3109, 3111, 3112, 3115, 3118, 3119, 3124, 3125, 3128, 3129, 3131, 3132, 3133, 3135, 3137, 3138, 3139, 3140, 3142, 3144, 3147, 3148, 3150, 3151, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3161, 3162, 3163, 3165, 3167, 3168, 3169, 3171, 3172, 3173, 3174, 3176, 3177, 3178, 3179, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3192, 3193, 3194, 3195, 3196, 3198, 3201, 3202, 3205, 3207, 3211, 3214, 3215, 3217, 3218, 3219, 3222, 3223, 3224, 3225, 3226, 3228, 3231, 3232, 3234, 3235, 3236, 3237, 3240, 3241, 3243, 3244, 3246, 3247, 3248, 3250, 3251, 3253, 3256, 3257, 3258, 3259, 3260, 3261, 3263, 3265, 3266, 3268, 3269, 3270, 3271, 3272, 3275, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3286, 3287, 3289, 3290, 3292, 3293, 3294, 3295, 3296, 3298, 3299, 3302, 3304, 3305, 3306, 3308, 3309, 3311, 3312, 3314, 3316, 3317, 3318, 3321, 3324, 3326, 3327, 3328, 3330, 3334, 3335, 3337, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3369, 3370, 3371, 3373, 3374, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3385, 3386, 3387, 3389, 3391, 3392, 3393, 3394, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3409, 3410, 3412, 3414, 3415, 3416, 3418, 3419, 3421, 3422, 3424, 3425, 3426, 3427, 3428, 3432, 3433, 3434, 3436, 3437, 3439, 3442, 3443, 3444, 3446, 3448, 3449, 3450, 3452, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3469, 3471, 3473, 3475, 3477, 3478, 3479, 3481, 3482, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3504, 3505, 3507, 3508, 3509, 3511, 3513, 3514, 3515, 3519, 3520, 3521, 3523, 3524, 3525, 3529, 3530, 3532, 3534, 3535, 3536, 3539, 3540, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3555, 3556, 3557, 3558, 3559, 3565, 3567, 3568, 3569, 3572, 3573, 3575, 3577, 3578, 3583, 3584, 3585, 3586, 3587, 3589, 3590, 3592, 3594, 3595, 3596, 3597, 3598, 3601, 3602, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3617, 3618, 3622, 3624, 3625, 3626, 3627, 3630, 3631, 3633, 3635, 3636, 3637, 3638, 3640, 3641, 3642, 3646, 3647, 3648, 3649, 3650, 3651, 3654, 3655, 3658, 3660, 3662, 3663, 3664, 3665, 3666, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3683, 3684, 3687, 3688, 3689, 3690, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3706, 3713, 3715, 3719, 3720, 3721, 3724, 3726, 3729, 3730, 3732, 3736, 3737, 3739, 3740, 3742, 3744, 3746, 3747, 3749]
Epoch 0 Epoch time:  3.013850212097168 current loss tensor(-1326.2787, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.466594934463501 current loss tensor(-1326.9467, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.535177707672119 current loss tensor(-1327.6139, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.5287904739379883 current loss tensor(-1328.2805, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.5135104656219482 current loss tensor(-1328.9468, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  2.5209836959838867 current loss tensor(-1329.6121, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.500112771987915 current loss tensor(-1330.2767, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.5139753818511963 current loss tensor(-1330.9407, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  2.5172231197357178 current loss tensor(-1331.6040, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  2.5251832008361816 current loss tensor(-1332.2666, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.516615152359009 current loss tensor(-1332.9285, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.6545822620391846 current loss tensor(-1333.5896, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.5072803497314453 current loss tensor(-1334.2500, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.508484125137329 current loss tensor(-1334.9095, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.5203795433044434 current loss tensor(-1335.5682, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.5149755477905273 current loss tensor(-1336.2261, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.521385669708252 current loss tensor(-1336.8831, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.5561437606811523 current loss tensor(-1337.5393, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.5258612632751465 current loss tensor(-1338.1946, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.561861753463745 current loss tensor(-1338.8491, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.5247888565063477 current loss tensor(-1339.5028, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  2.5244319438934326 current loss tensor(-1340.1555, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  2.527724504470825 current loss [1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1261, 1262, 1263, 1264, 1265, 1268, 1269, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1286, 1287, 1289, 1290, 1292, 1293, 1294, 1295, 1296, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1309, 1310, 1311, 1313, 1315, 1316, 1317, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1327, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1340, 1341, 1342, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1354, 1357, 1358, 1359, 1360, 1361, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1371, 1372, 1373, 1375, 1376, 1377, 1378, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1392, 1393, 1394, 1395, 1397, 1398, 1399, 1402, 1403, 1404, 1407, 1409, 1410, 1411, 1412, 1413, 1415, 1416, 1417, 1418, 1419, 1421, 1423, 1424, 1427, 1428, 1429, 1430, 1432, 1433, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1457, 1458, 1459, 1460, 1464, 1465, 1466, 1467, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1513, 1514, 1518, 1520, 1522, 1523, 1526, 1527, 1528, 1529, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1541, 1542, 1543, 1544, 1545, 1548, 1549, 1551, 1552, 1553, 1554, 1556, 1559, 1561, 1562, 1563, 1564, 1565, 1566, 1568, 1569, 1570, 1571, 1572, 1573, 1576, 1578, 1580, 1581, 1583, 1584, 1587, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1609, 1610, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1627, 1628, 1629, 1630, 1631, 1633, 1634, 1636, 1637, 1642, 1643, 1644, 1645, 1647, 1650, 1652, 1653, 1654, 1655, 1656, 1657, 1660, 1661, 1663, 1664, 1665, 1667, 1669, 1670, 1671, 1672, 1673, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1685, 1686, 1687, 1690, 1691, 1692, 1694, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1705, 1706, 1707, 1709, 1710, 1711, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1726, 1728, 1730, 1733, 1734, 1735, 1736, 1737, 1738, 1741, 1742, 1745, 1747, 1748, 1749, 1751, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1764, 1766, 1768, 1769, 1773, 1774, 1775, 1776, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1789, 1790, 1792, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1813, 1816, 1817, 1818, 1819, 1823, 1824, 1826, 1827, 1828, 1829, 1831, 1833, 1834, 1835, 1836, 1837, 1838, 1840, 1841, 1842, 1843, 1844, 1848, 1849, 1851, 1853, 1855, 1856, 1857, 1858, 1861, 1862, 1864, 1866, 1868, 1869, 1871, 1872, 1873, 1874, 1876, 1877, 1878, 1879, 1880, 1881, 1883, 1885, 1886, 1887, 1888, 1889, 1891, 1892, 1893, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1906, 1908, 1909, 1910, 1911, 1912, 1914, 1916, 1917, 1918, 1920, 1921, 1924, 1925, 1926, 1929, 1932, 1933, 1934, 1935, 1938, 1939, 1942, 1943, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1956, 1957, 1958, 1959, 1960, 1962, 1964, 1965, 1966, 1967, 1968, 1970, 1971, 1972, 1974, 1975, 1977, 1978, 1979, 1982, 1983, 1984, 1987, 1988, 1989, 1992, 1994, 1995, 1996, 1997, 2000, 2001, 2004, 2005, 2006, 2010, 2014, 2015, 2016, 2017, 2019, 2020, 2022, 2023, 2026, 2027, 2028, 2029, 2031, 2033, 2034, 2035, 2036, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2056, 2057, 2058, 2059, 2062, 2063, 2066, 2067, 2069, 2071, 2072, 2073, 2075, 2078, 2079, 2080, 2082, 2083, 2085, 2086, 2087, 2088, 2090, 2091, 2092, 2093, 2094, 2096, 2097, 2100, 2101, 2102, 2103, 2104, 2106, 2107, 2108, 2110, 2111, 2113, 2116, 2117, 2118, 2119, 2120, 2121, 2124, 2125, 2127, 2130, 2131, 2133, 2134, 2137, 2140, 2141, 2142, 2143, 2144, 2145, 2148, 2149, 2150, 2153, 2156, 2159, 2161, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2171, 2172, 2174, 2176, 2177, 2179, 2181, 2182, 2184, 2185, 2187, 2188, 2190, 2191, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2201, 2202, 2203, 2204, 2206, 2207, 2209, 2210, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2222, 2223, 2224, 2225, 2226, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2246, 2247, 2248, 2249, 2250, 2252, 2253, 2257, 2258, 2259, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2273, 2276, 2277, 2280, 2281, 2282, 2283, 2284, 2286, 2287, 2288, 2291, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2313, 2317, 2318, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2339, 2340, 2344, 2345, 2346, 2348, 2350, 2351, 2355, 2357, 2358, 2359, 2360, 2362, 2365, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2380, 2381, 2383, 2385, 2386, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2402, 2404, 2405, 2407, 2409, 2410, 2412, 2413, 2414, 2415, 2416, 2417, 2420, 2421, 2423, 2427, 2431, 2432, 2433, 2434, 2436, 2442, 2444, 2445, 2447, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2463, 2464, 2465, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2476, 2478, 2479, 2480, 2481, 2482, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2492, 2493, 2494, 2496, 2497, 2498, 2499, 2500]
Epoch 0 Epoch time:  3.0154175758361816 current loss tensor(-1333.8640, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 1 Epoch time:  2.4773004055023193 current loss tensor(-1334.5171, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 2 Epoch time:  2.557582378387451 current loss tensor(-1335.1694, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 3 Epoch time:  2.557018995285034 current loss tensor(-1335.8213, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 4 Epoch time:  2.5070111751556396 current loss tensor(-1336.4723, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 5 Epoch time:  2.5251574516296387 current loss tensor(-1337.1226, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 6 Epoch time:  2.5265989303588867 current loss tensor(-1337.7722, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 7 Epoch time:  2.5325026512145996 current loss tensor(-1338.4211, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 8 Epoch time:  2.5386962890625 current loss tensor(-1339.0693, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 9 Epoch time:  2.5406789779663086 current loss tensor(-1339.7167, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 10 Epoch time:  2.6735970973968506 current loss tensor(-1340.3633, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 11 Epoch time:  2.5101213455200195 current loss tensor(-1341.0090, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 12 Epoch time:  2.594481945037842 current loss tensor(-1341.6542, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 13 Epoch time:  2.5306501388549805 current loss tensor(-1342.2985, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 14 Epoch time:  2.537912130355835 current loss tensor(-1342.9419, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 15 Epoch time:  2.5295917987823486 current loss tensor(-1343.5846, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 16 Epoch time:  2.521026611328125 current loss tensor(-1344.2263, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 17 Epoch time:  2.591559648513794 current loss tensor(-1344.8673, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 18 Epoch time:  2.5388307571411133 current loss tensor(-1345.5076, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 19 Epoch time:  2.5718486309051514 current loss tensor(-1346.1467, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 20 Epoch time:  2.543961524963379 current loss tensor(-1346.7852, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 21 Epoch time:  2.526041269302368 current loss tensor(-1347.4226, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 22 Epoch time:  2.5696535110473633 current loss tensor(-1348.0592, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.506892442703247 current loss tensor(-1348.6951, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.538443088531494 current loss tensor(-1334.9729, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1334.2842, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1333.6277, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14 Epoch time:  2.529283285140991 current loss tensor(-1335.6379, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1334.9398, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1334.2842, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15 Epoch time:  2.533102512359619 current loss tensor(-1336.3022, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1335.5946, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1334.9398, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16 Epoch time:  2.669473171234131 current loss tensor(-1336.9658, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1336.2485, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1335.5946, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17 Epoch time:  2.5273923873901367 current loss tensor(-1337.6283, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1336.9016, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1336.2485, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18 Epoch time:  2.5763490200042725 current loss tensor(-1338.2900, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1337.5540, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1336.9016, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19 Epoch time:  2.523078203201294 current loss tensor(-1338.9509, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1338.2053, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1337.5540, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20 Epoch time:  2.5303542613983154 current loss tensor(-1339.6106, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1338.8556, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1338.2053, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21 Epoch time:  2.5467047691345215 current loss tensor(-1340.2694, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1339.5051, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1338.8556, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22 Epoch time:  2.5531599521636963 current loss tensor(-1340.9275, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1340.1538, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1339.5051, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23 Epoch time:  2.5335304737091064 current loss tensor(-1341.5844, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1340.8016, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1340.1538, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24 Epoch time:  2.538405656814575 current loss tensor(-1342.2405, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1341.4485, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1340.8016, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25 Epoch time:  2.5360770225524902 current loss tensor(-1342.8956, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1342.0944, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1341.4485, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26 Epoch time:  2.5415735244750977 current loss tensor(-1343.5498, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1342.7394, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1342.0944, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27 Epoch time:  2.631230115890503 current loss tensor(-1344.2031, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1343.3834, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1342.7394, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28 Epoch time:  2.6471288204193115 current loss tensor(-1344.8555, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1344.0266, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1343.3834, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29 Epoch time:  2.5209343433380127 current loss tensor(-1345.5068, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1344.6687, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1344.0266, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30 Epoch time:  2.5137040615081787 current loss tensor(-1346.1572, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1345.3099, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1344.6687, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31 Epoch time:  2.6456778049468994 current loss tensor(-1346.8069, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1345.9501, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1345.3099, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32 Epoch time:  2.5249462127685547 current loss tensor(-1347.4552, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1346.5892, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1345.9501, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33 Epoch time:  2.539768934249878 current loss tensor(-1348.1025, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1347.2273, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1346.5892, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34 Epoch time:  2.5363073348999023 current loss tensor(-1348.7488, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1347.8645, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1347.2273, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35 Epoch time:  2.595256805419922 current loss tensor(-1349.3940, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1348.5005, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1347.8645, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36 Epoch time:  2.535884380340576 current loss tensor(-1350.0381, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1349.1354, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1348.5005, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37 Epoch time:  2.5349924564361572 current loss tensor(-1350.6813, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1349.7693, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1349.1354, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38 Epoch time:  2.5343947410583496 current loss tensor(-1351.3235, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1350.4022, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1349.7693, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39 Epoch time:  2.5331850051879883 current loss tensor(-1351.9644, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1351.0339, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1350.4022, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40 Epoch time:  2.5316622257232666 current loss tensor(-1352.6042, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1351.6646, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1351.0339, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41 Epoch time:  2.536747694015503 current loss tensor(-1353.2429, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1352.2942, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1351.6646, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42 Epoch time:  2.5260009765625 current loss tensor(-1353.8806, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1352.9226, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1352.2942, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43 Epoch time:  2.6072616577148438 current loss tensor(-1354.5173, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1353.5503, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1352.9226, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44 Epoch time:  2.633315324783325 current loss tensor(-1355.1531, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1354.1768, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1353.5503, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45 Epoch time:  2.5295164585113525 current loss tensor(-1355.7875, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1354.8021, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1354.1768, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46 Epoch time:  2.5442986488342285 current loss tensor(-1356.4209, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1355.4265, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1354.8021, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47 Epoch time:  2.5327956676483154 current loss tensor(-1357.0532, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1356.0499, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1355.4265, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48 Epoch time:  2.5353426933288574 current loss tensor(-1357.6847, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1356.6722, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1356.0499, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49 Epoch time:  2.5340383052825928 current loss tensor(-1358.3148, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1357.2935, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1356.6722, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 50 Epoch time:  2.586519479751587 current loss tensor(-1358.9440, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1357.9136, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1357.2935, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 51 Epoch time:  2.6653339862823486 current loss tensor(-1359.5720, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1358.5325, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1357.9136, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 52 Epoch time:  2.541776180267334 current loss tensor(-1360.1990, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1359.1503, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1358.5325, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 53 Epoch time:  2.541597366333008 current loss tensor(-1360.8246, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1359.7670, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1359.1503, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 54 Epoch time:  2.534139394760132 current loss tensor(-1361.4492, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1360.3828, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1359.7670, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 55 Epoch time:  2.537020206451416 current loss tensor(-1362.0728, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1360.9976, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1360.3828, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 56 Epoch time:  2.532360553741455 current loss tensor(-1362.6953, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1361.6112, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1360.9976, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 57 Epoch time:  2.5288171768188477 current loss tensor(-1363.3168, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1362.2239, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1361.6112, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 58 Epoch time:  2.56486177444458 current loss tensor(-1363.9373, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1362.8354, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1362.2239, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 59 Epoch time:  3.2178523540496826 current loss tensor(-1364.5564, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1363.4460, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1362.8354, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 60 Epoch time:  3.1285488605499268 current loss tensor(-1365.1747, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1364.0554, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1363.4460, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 61 Epoch time:  2.6302382946014404 current loss tensor(-1365.7917, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1364.6639, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1364.0554, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 62 Epoch time:  2.5353915691375732 current loss tensor(-1366.4077, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1365.2712, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1364.6639, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 63 Epoch time:  2.6823644638061523 current loss tensor(-1367.0227, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1365.8777, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1365.2712, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 64 Epoch time:  2.543353796005249 current loss tensor(-1367.6365, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1366.4828, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1365.8777, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 65 Epoch time:  2.533628225326538 current loss tensor(-1368.2491, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1367.0870, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1366.4828, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 66 Epoch time:  2.534412384033203 current loss tensor(-1368.8608, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1367.6901, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1367.0870, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 67 Epoch time:  2.5320467948913574 current loss tensor(-1369.4712, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1368.2921, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1367.6901, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 68 Epoch time:  2.653707504272461 current loss tensor(-1370.0807, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1368.8928, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1368.2921, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 69 Epoch time:  2.529738664627075 current loss tensor(-1370.6887, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1369.4927, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1368.8928, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 70 Epoch time:  2.5999677181243896 current loss tensor(-1371.2957, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1370.0913, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1369.4927, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 71 Epoch time:  2.540196657180786 current loss tensor(-1371.9014, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1370.6888, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1370.0913, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 72 Epoch time:  2.5314857959747314 current loss tensor(-1372.5059, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1371.2853, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1370.6888, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 73 Epoch time:  2.5377354621887207 current loss tensor(-1373.1094, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1371.8806, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1371.2853, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 74 Epoch time:  2.5249176025390625 current loss tensor(-1373.7115, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1372.4749, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1371.8806, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 75 Epoch time:  2.534858465194702 current loss tensor(-1374.3127, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1373.0681, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1372.4749, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 76 Epoch time:  2.5268874168395996 current loss tensor(-1374.9126, device='cuda:0', grad_fn=<SumBackward0>)
average_loss tensor(-1373.6600, device='cuda:0', grad_fn=<DivBackward0>) best_loss tensor(-1373.0681, device='cuda:0', grad_fn=<DivBackward0>)
Epoch tensor(-1328.2266, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.5084197521209717 current loss tensor(-1328.8774, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.5173966884613037 current loss tensor(-1329.5276, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.510127544403076 current loss tensor(-1330.1765, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.503680467605591 current loss tensor(-1330.8247, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.512749433517456 current loss tensor(-1331.4718, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.4676411151885986 current loss tensor(-1332.1182, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.4756505489349365 current loss tensor(-1332.7637, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.4905195236206055 current loss tensor(-1333.4080, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.5035624504089355 current loss tensor(-1334.0515, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.550379753112793 current loss tensor(-1334.6940, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.512951135635376 current loss tensor(-1335.3354, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.5347037315368652 current loss tensor(-1335.9761, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.646523952484131 current loss tensor(-1336.6155, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.466595411300659 current loss tensor(-1337.2540, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.525588035583496 current loss tensor(-1337.8911, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.5213656425476074 current loss tensor(-1338.5273, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.5376179218292236 current loss tensor(-1339.1625, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.5290679931640625 current loss tensor(-1339.7965, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.52553653717041 current loss tensor(-1340.4294, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.5208239555358887 current loss tensor(-1341.0614, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.5086312294006348 current loss tensor(-1341.6923, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.4998908042907715 current loss tensor(-1342.3220, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.49676775932312 current loss tensor(-1342.9509, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  2.5126919746398926 current loss tensor(-1343.5786, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.582364320755005 current loss tensor(-1344.2053, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  2.48759388923645 current loss tensor(-1344.8309, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  2.523425817489624 current loss tensor(-1345.4556, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  2.6523237228393555 current loss tensor(-1346.0791, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.4667375087738037 current loss tensor(-1346.7014, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.539863348007202 current loss tensor(-1347.3225, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.5559134483337402 current loss tensor(-1347.9426, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.495136022567749 current loss tensor(-1348.5616, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.5316014289855957 current loss tensor(-1349.1798, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  2.5275492668151855 current loss tensor(-1349.7968, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.5214200019836426 current loss tensor(-1350.4127, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  2.5211191177368164 current loss tensor(-1351.0277, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  3.299314022064209 current loss tensor(-1351.6416, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  3.1365749835968018 current loss tensor(-1352.2545, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.4647133350372314 current loss tensor(-1352.8665, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  2.5030357837677 current loss tensor(-1353.4774, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.5411267280578613 current loss tensor(-1354.0873, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.501441240310669 current loss tensor(-1354.6960, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.5474231243133545 current loss tensor(-1355.3040, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.5153748989105225 current loss tensor(-1355.9106, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.5231287479400635 current loss tensor(-1356.5164, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.5346999168395996 current loss tensor(-1357.1211, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.5414981842041016 current loss tensor(-1357.7247, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.6609947681427 current loss tensor(-1358.3273, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.4645514488220215 current loss tensor(-1358.9286, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.5393214225769043 current loss tensor(-1359.5288, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.5209968090057373 current loss tensor(-1360.1281, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.5364274978637695 current loss tensor(-1360.7263, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.520439863204956 current loss tensor(-1361.3234, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.531432867050171 current loss tensor(-1361.9194, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.5450713634490967 current loss tensor(-1362.5144, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.5296061038970947 current loss tensor(-1363.1082, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.507401466369629 current loss tensor(-1363.7007, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.520725727081299 current loss tensor(-1364.2925, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.512472152709961 current loss tensor(-1364.8831, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.5362708568573 current loss tensor(-1365.4727, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.5391533374786377 current loss tensor(-1366.0610, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.546727180480957 current loss tensor(-1366.6484, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.571235418319702 current loss tensor(-1367.2346, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  3.0074353218078613 current loss tensor(-1367.8199, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.5806267261505127 current loss tensor(-1368.4041, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.459451198577881 current loss tensor(-1368.9873, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.5433945655822754 current loss tensor(-1369.5693, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.5271897315979004 current loss tensor(-1370.1501, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.528531074523926 current loss tensor(-1370.7300, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.5000176429748535 current loss tensor(-1371.3088, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.521509885787964 current loss tensor(-1371.8865, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.493361234664917 current loss tensor(-1340.8074, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 23 Epoch time:  2.5123536586761475 current loss tensor(-1341.4584, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 24 Epoch time:  2.54067063331604 current loss tensor(-1342.1085, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.537405014038086 current loss tensor(-1342.7576, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.51435923576355 current loss tensor(-1343.4058, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.5397753715515137 current loss tensor(-1344.0530, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.668022871017456 current loss tensor(-1344.6992, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.4904861450195312 current loss tensor(-1345.3445, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.5267791748046875 current loss tensor(-1345.9888, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.565141201019287 current loss tensor(-1346.6321, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.572158098220825 current loss tensor(-1347.2743, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.5144171714782715 current loss tensor(-1347.9155, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.5398571491241455 current loss tensor(-1348.5557, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.523404598236084 current loss tensor(-1349.1949, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.593766927719116 current loss tensor(-1349.8330, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.5104563236236572 current loss tensor(-1350.4700, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.5189216136932373 current loss tensor(-1351.1057, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.5342061519622803 current loss tensor(-1351.7404, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.534067392349243 current loss tensor(-1352.3739, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.5254995822906494 current loss tensor(-1353.0063, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.5347654819488525 current loss tensor(-1353.6377, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.635774612426758 current loss tensor(-1354.2681, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.504530191421509 current loss tensor(-1354.8973, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.542208194732666 current loss tensor(-1355.5256, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  2.528857469558716 current loss tensor(-1356.1527, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.542443037033081 current loss tensor(-1356.7789, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  2.539825439453125 current loss tensor(-1357.4041, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  2.5340654850006104 current loss tensor(-1358.0281, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  2.5373117923736572 current loss tensor(-1358.6510, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.5856266021728516 current loss tensor(-1359.2729, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.5782101154327393 current loss tensor(-1359.8936, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.536813259124756 current loss tensor(-1360.5134, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.5466480255126953 current loss tensor(-1361.1321, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.5292229652404785 current loss tensor(-1361.7500, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  2.540642261505127 current loss tensor(-1362.3667, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.5266990661621094 current loss tensor(-1362.9825, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  2.5287137031555176 current loss tensor(-1363.5972, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  2.5570478439331055 current loss tensor(-1364.2109, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  2.574169158935547 current loss tensor(-1364.8236, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.580984115600586 current loss tensor(-1365.4353, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  2.537208080291748 current loss tensor(-1366.0459, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.722472667694092 current loss tensor(-1366.6553, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.497241735458374 current loss tensor(-1367.2639, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.541297435760498 current loss tensor(-1367.8711, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.5323233604431152 current loss tensor(-1368.4772, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.5375704765319824 current loss tensor(-1369.0824, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.5287301540374756 current loss tensor(-1369.6863, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.5799403190612793 current loss tensor(-1370.2891, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.5320041179656982 current loss tensor(-1370.8907, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.58424973487854 current loss tensor(-1371.4913, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.5406956672668457 current loss tensor(-1372.0909, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.524287700653076 current loss tensor(-1372.6895, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.5365371704101562 current loss tensor(-1373.2870, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.5316693782806396 current loss tensor(-1373.8833, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.5315933227539062 current loss tensor(-1374.4788, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.521554708480835 current loss tensor(-1375.0729, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.5445477962493896 current loss tensor(-1375.6658, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.542837619781494 current loss tensor(-1376.2579, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.6596319675445557 current loss tensor(-1376.8489, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.497291088104248 current loss tensor(-1377.4390, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.542165994644165 current loss tensor(-1378.0280, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.5268499851226807 current loss tensor(-1378.6158, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.5522618293762207 current loss tensor(-1379.2026, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.5713603496551514 current loss tensor(-1379.7883, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.533604383468628 current loss tensor(-1380.3730, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.578160285949707 current loss tensor(-1380.9568, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.5870614051818848 current loss tensor(-1381.5393, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.564197301864624 current loss tensor(-1382.1208, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.5189754962921143 current loss tensor(-1382.7012, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.530731201171875 current loss tensor(-1383.2804, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.540259599685669 current loss tensor(-1383.8586, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.5317788124084473 current loss tensor(-1384.4357, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.5807292461395264 current loss tensor(-1349.3301, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 25 Epoch time:  2.5304784774780273 current loss tensor(-1349.9641, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 26 Epoch time:  2.5419845581054688 current loss tensor(-1350.5973, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 27 Epoch time:  2.6596038341522217 current loss tensor(-1351.2295, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 28 Epoch time:  2.51230525970459 current loss tensor(-1351.8608, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 29 Epoch time:  2.596348762512207 current loss tensor(-1352.4915, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 30 Epoch time:  2.5220658779144287 current loss tensor(-1353.1207, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 31 Epoch time:  2.524116039276123 current loss tensor(-1353.7493, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 32 Epoch time:  2.585461139678955 current loss tensor(-1354.3770, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 33 Epoch time:  2.527303457260132 current loss tensor(-1355.0033, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 34 Epoch time:  2.5507543087005615 current loss tensor(-1355.6287, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 35 Epoch time:  2.52874755859375 current loss tensor(-1356.2533, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 36 Epoch time:  2.59254789352417 current loss tensor(-1356.8767, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 37 Epoch time:  2.5421595573425293 current loss tensor(-1357.4994, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 38 Epoch time:  2.526034355163574 current loss tensor(-1358.1208, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 39 Epoch time:  2.543424367904663 current loss tensor(-1358.7415, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 40 Epoch time:  2.531374931335449 current loss tensor(-1359.3610, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 41 Epoch time:  2.533782482147217 current loss tensor(-1359.9794, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 42 Epoch time:  2.5342814922332764 current loss tensor(-1360.5967, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 43 Epoch time:  2.5226552486419678 current loss tensor(-1361.2131, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 44 Epoch time:  2.721897840499878 current loss tensor(-1361.8286, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 45 Epoch time:  2.516690731048584 current loss tensor(-1362.4431, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 46 Epoch time:  2.531372547149658 current loss tensor(-1363.0564, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 47 Epoch time:  2.545252799987793 current loss tensor(-1363.6688, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 48 Epoch time:  2.5308001041412354 current loss tensor(-1364.2802, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 49 Epoch time:  2.537317991256714 current loss tensor(-1364.8905, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 50 Epoch time:  2.536176919937134 current loss tensor(-1365.4998, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 51 Epoch time:  2.583190441131592 current loss tensor(-1366.1077, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 52 Epoch time:  2.587876319885254 current loss tensor(-1366.7146, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 53 Epoch time:  2.5726685523986816 current loss tensor(-1367.3203, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 54 Epoch time:  2.508080005645752 current loss tensor(-1367.9249, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 55 Epoch time:  2.537553071975708 current loss tensor(-1368.5287, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 56 Epoch time:  2.540766477584839 current loss tensor(-1369.1312, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 57 Epoch time:  2.530820846557617 current loss tensor(-1369.7328, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 58 Epoch time:  2.537454128265381 current loss tensor(-1370.3333, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 59 Epoch time:  2.5518064498901367 current loss tensor(-1370.9326, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 60 Epoch time:  2.5959525108337402 current loss tensor(-1371.5311, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 61 Epoch time:  2.71303391456604 current loss tensor(-1372.1284, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 62 Epoch time:  2.514486312866211 current loss tensor(-1372.7246, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 63 Epoch time:  2.5393288135528564 current loss tensor(-1373.3199, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 64 Epoch time:  2.5949409008026123 current loss tensor(-1373.9141, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 65 Epoch time:  2.549189567565918 current loss tensor(-1374.5071, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 66 Epoch time:  2.5401155948638916 current loss tensor(-1375.0992, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 67 Epoch time:  2.5230307579040527 current loss tensor(-1375.6903, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 68 Epoch time:  2.535975456237793 current loss tensor(-1376.2803, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 69 Epoch time:  2.5919525623321533 current loss tensor(-1376.8691, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 70 Epoch time:  2.5352516174316406 current loss tensor(-1377.4570, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 71 Epoch time:  2.600022315979004 current loss tensor(-1378.0438, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 72 Epoch time:  2.539806842803955 current loss tensor(-1378.6296, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 73 Epoch time:  2.523960590362549 current loss tensor(-1379.2141, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 74 Epoch time:  2.5429699420928955 current loss tensor(-1379.7977, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 75 Epoch time:  2.52488374710083 current loss tensor(-1380.3804, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 76 Epoch time:  2.531141996383667 current loss tensor(-1380.9617, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 77 Epoch time:  2.540224552154541 current loss tensor(-1381.5419, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 78 Epoch time:  2.6710994243621826 current loss tensor(-1382.1212, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 79 Epoch time:  2.512617349624634 current loss tensor(-1382.6992, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 80 Epoch time:  2.5325100421905518 current loss tensor(-1383.2762, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 81 Epoch time:  2.5989251136779785 current loss tensor(-1383.8521, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 82 Epoch time:  2.533278226852417 current loss tensor(-1384.4269, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 83 Epoch time:  2.5389833450317383 current loss tensor(-1385.0005, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 84 Epoch time:  2.543766975402832 current loss tensor(-1385.5731, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 85 Epoch time:  2.6312663555145264 current loss tensor(-1386.1447, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 86 Epoch time:  2.512716770172119 current loss tensor(-1386.7151, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 87 Epoch time:  2.595919609069824 current loss tensor(-1387.2845, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 88 Epoch time:  2.5818681716918945 current loss tensor(-1387.8527, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 89 Epoch time:  2.5551047325134277 current loss tensor(-1388.4197, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 90 Epoch time:  2.531569242477417 current loss tensor(-1388.9856, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 91 Epoch time:  2.5610506534576416 current loss tensor(-1389.5504, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 92 Epoch time:  2.511817693710327 current loss tensor(-1390.1141, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 93 Epoch time:  2.6323835849761963 current loss tensor(-1390.6768, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 94 Epoch time:  2.5040156841278076 current loss tensor(-1391.2383, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.5420420169830322 current loss tensor(-1391.7986, device='cuda:1', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.5492444038391113 current loss [rank1]:[E ProcessGroupNCCL.cpp:563] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600040 milliseconds before timing out.
[rank2]:[E ProcessGroupNCCL.cpp:563] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600073 milliseconds before timing out.
[rank3]:[E ProcessGroupNCCL.cpp:563] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600069 milliseconds before timing out.
[rank1]:[E ProcessGroupNCCL.cpp:1537] [PG 0 Rank 1] Timeout at NCCL work: 3281, last enqueued NCCL work: 3281, last completed NCCL work: 3280.
[rank1]:[E ProcessGroupNCCL.cpp:577] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E ProcessGroupNCCL.cpp:583] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
[rank1]:[E ProcessGroupNCCL.cpp:1414] [PG 0 Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600040 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f4d1397a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f4cc38205a2 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7f4cc38253c0 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f4cc382670c in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f4d130b0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f4db5bcaac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x7f4db5c5c850 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 0 Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600040 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f4d1397a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f4cc38205a2 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7f4cc38253c0 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f4cc382670c in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f4d130b0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f4db5bcaac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x7f4db5c5c850 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f4d1397a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe083a9 (0x7f4cc34ab3a9 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xdc253 (0x7f4d130b0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x94ac3 (0x7f4db5bcaac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0x126850 (0x7f4db5c5c850 in /lib/x86_64-linux-gnu/libc.so.6)

tensor(-1385.0114, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.491105794906616 current loss tensor(-1385.5861, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.6758198738098145 current loss tensor(-1386.1597, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.5003933906555176 current loss tensor(-1386.7322, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.5275416374206543 current loss tensor(-1387.3037, device='cuda:2', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.5373148918151855 current loss tensor(-1387.8740, device='cuda:2', grad_fn=<SumBackward0>)
dealing G23.txt
device 2 start to train
[n] 500 [C] 1200 weight 2000
tensor(-1372.4629, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 95 Epoch time:  2.501490354537964 current loss tensor(-1373.0383, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 96 Epoch time:  2.533475637435913 current loss tensor(-1373.6128, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 97 Epoch time:  2.5048370361328125 current loss tensor(-1374.1860, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 98 Epoch time:  2.526890993118286 current loss tensor(-1374.7583, device='cuda:3', grad_fn=<SumBackward0>)
Epoch 99 Epoch time:  2.525193929672241 current loss tensor(-1375.3296, device='cuda:3', grad_fn=<SumBackward0>)
dealing G23.txt
device 3 start to train
[n] 500 [C] 1223 weight 2000
[rank2]:[E ProcessGroupNCCL.cpp:1537] [PG 0 Rank 2] Timeout at NCCL work: 3281, last enqueued NCCL work: 3281, last completed NCCL work: 3280.
[rank2]:[E ProcessGroupNCCL.cpp:577] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E ProcessGroupNCCL.cpp:583] [Rank 2] To avoid data inconsistency, we are taking the entire process down.
[rank2]:[E ProcessGroupNCCL.cpp:1414] [PG 0 Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600073 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f21d1d7a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f2181c205a2 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7f2181c253c0 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f2181c2670c in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f21d14b0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f2273fc4ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x7f2274056850 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 0 Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600073 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f21d1d7a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f2181c205a2 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7f2181c253c0 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f2181c2670c in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f21d14b0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f2273fc4ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x7f2274056850 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f21d1d7a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe083a9 (0x7f21818ab3a9 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xdc253 (0x7f21d14b0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x94ac3 (0x7f2273fc4ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0x126850 (0x7f2274056850 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[E ProcessGroupNCCL.cpp:1537] [PG 0 Rank 3] Timeout at NCCL work: 3281, last enqueued NCCL work: 3281, last completed NCCL work: 3280.
[rank3]:[E ProcessGroupNCCL.cpp:577] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank3]:[E ProcessGroupNCCL.cpp:583] [Rank 3] To avoid data inconsistency, we are taking the entire process down.
[rank3]:[E ProcessGroupNCCL.cpp:1414] [PG 0 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600069 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fd5c557a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fd5754205a2 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7fd5754253c0 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7fd57542670c in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fd5c4cb0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fd6676e0ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x7fd667772850 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 0 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3281, OpType=ALLGATHER, NumelIn=1, NumelOut=4, Timeout(ms)=600000) ran for 600069 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fd5c557a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fd5754205a2 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7fd5754253c0 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7fd57542670c in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fd5c4cb0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fd6676e0ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x7fd667772850 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fd5c557a897 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe083a9 (0x7fd5750ab3a9 in /home/neusha/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xdc253 (0x7fd5c4cb0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x94ac3 (0x7fd6676e0ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0x126850 (0x7fd667772850 in /lib/x86_64-linux-gnu/libc.so.6)

W0622 04:47:57.494000 139948495284032 torch/multiprocessing/spawn.py:145] Terminating process 626657 via signal SIGTERM
W0622 04:47:57.496000 139948495284032 torch/multiprocessing/spawn.py:145] Terminating process 626659 via signal SIGTERM
W0622 04:47:57.496000 139948495284032 torch/multiprocessing/spawn.py:145] Terminating process 626660 via signal SIGTERM
Traceback (most recent call last):
  File "/home/neusha/GNN/HypOp/run_dist.py", line 24, in <module>
    mp.spawn(exp_centralized_for_multi, args=(list(range(params["num_gpus"])), params), nprocs=params["num_gpus"])
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 185, in join
    original_trace = pickle.load(fh)
EOFError: Ran out of input
E0622 04:48:01.267000 140540893419328 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 626408) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/neusha/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
run_dist.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-22_04:48:01
  host      : acesxpu.ucsd.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 626408)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
